10/18/2022 21:38:31 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=10, config_name='microsoft/graphcodebert-base', dev_filename='/raid/cs21mtech12001/Research/Notebooks_Dataset/splitted_data/competition_notebooks_with_atleast_1_medal_and_10_votes/without_summarization/code-with-usm-only-2/valid_dataset.jsonl', do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/raid/cs21mtech12001/Research/CodeBERT/Repository/GraphCodeBERT/code-summarization/output/notebooks/without_summarization/code_with_usm_only_2/checkpoint-best-bleu/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=320, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3, output_dir='/raid/cs21mtech12001/Research/CodeBERT/Repository/GraphCodeBERT/code-summarization/output/notebooks/without_summarization/code_with_usm_only_2', seed=42, test_filename='/raid/cs21mtech12001/Research/Notebooks_Dataset/splitted_data/competition_notebooks_with_atleast_1_medal_and_10_votes/without_summarization/code-with-usm-only-2/test_dataset.jsonl', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
10/18/2022 21:38:40 - INFO - __main__ -   reload model from /raid/cs21mtech12001/Research/CodeBERT/Repository/GraphCodeBERT/code-summarization/output/notebooks/without_summarization/code_with_usm_only_2/checkpoint-best-bleu/pytorch_model.bin
10/18/2022 21:38:45 - INFO - __main__ -   Test file: /raid/cs21mtech12001/Research/Notebooks_Dataset/splitted_data/competition_notebooks_with_atleast_1_medal_and_10_votes/without_summarization/code-with-usm-only-2/valid_dataset.jsonl
  0%|          | 0/1593 [00:00<?, ?it/s]  1%|          | 18/1593 [00:00<00:08, 176.31it/s]  3%|▎         | 44/1593 [00:00<00:06, 222.73it/s]  5%|▍         | 74/1593 [00:00<00:05, 256.36it/s]  6%|▋         | 100/1593 [00:00<00:05, 256.00it/s]  8%|▊         | 126/1593 [00:00<00:05, 256.97it/s] 10%|█         | 163/1593 [00:00<00:04, 289.56it/s] 12%|█▏        | 192/1593 [00:00<00:05, 277.36it/s] 14%|█▍        | 220/1593 [00:00<00:05, 273.95it/s] 16%|█▌        | 248/1593 [00:00<00:04, 272.59it/s] 18%|█▊        | 285/1593 [00:01<00:04, 301.36it/s] 20%|█▉        | 316/1593 [00:01<00:04, 301.66it/s] 22%|██▏       | 352/1593 [00:01<00:03, 318.08it/s] 24%|██▍       | 384/1593 [00:01<00:03, 318.52it/s] 26%|██▌       | 416/1593 [00:01<00:03, 310.87it/s] 28%|██▊       | 448/1593 [00:01<00:03, 293.81it/s] 30%|███       | 478/1593 [00:01<00:03, 292.02it/s] 32%|███▏      | 512/1593 [00:01<00:03, 304.57it/s] 34%|███▍      | 543/1593 [00:01<00:03, 297.56it/s] 36%|███▌      | 573/1593 [00:01<00:03, 295.61it/s] 38%|███▊      | 603/1593 [00:02<00:03, 284.09it/s] 40%|███▉      | 632/1593 [00:02<00:03, 277.87it/s] 41%|████▏     | 660/1593 [00:02<00:03, 277.89it/s] 43%|████▎     | 692/1593 [00:02<00:03, 285.44it/s] 45%|████▌     | 721/1593 [00:02<00:03, 284.27it/s] 47%|████▋     | 755/1593 [00:02<00:02, 297.36it/s] 49%|████▉     | 786/1593 [00:02<00:02, 299.97it/s] 51%|█████▏    | 817/1593 [00:02<00:02, 299.66it/s] 53%|█████▎    | 847/1593 [00:02<00:02, 295.10it/s] 55%|█████▌    | 879/1593 [00:03<00:02, 301.59it/s] 57%|█████▋    | 910/1593 [00:03<00:02, 280.55it/s] 59%|█████▉    | 940/1593 [00:03<00:02, 285.38it/s] 61%|██████    | 972/1593 [00:03<00:02, 291.48it/s] 63%|██████▎   | 1005/1593 [00:03<00:01, 302.10it/s] 65%|██████▌   | 1036/1593 [00:03<00:01, 294.27it/s] 67%|██████▋   | 1066/1593 [00:03<00:01, 291.88it/s] 69%|██████▉   | 1096/1593 [00:03<00:02, 218.61it/s] 71%|███████   | 1124/1593 [00:04<00:02, 232.00it/s] 72%|███████▏  | 1152/1593 [00:04<00:01, 243.51it/s] 74%|███████▍  | 1181/1593 [00:04<00:01, 255.32it/s] 76%|███████▌  | 1211/1593 [00:04<00:01, 266.86it/s] 78%|███████▊  | 1239/1593 [00:04<00:01, 263.95it/s] 80%|███████▉  | 1268/1593 [00:04<00:01, 270.92it/s] 81%|████████▏ | 1296/1593 [00:04<00:01, 251.27it/s] 83%|████████▎ | 1325/1593 [00:04<00:01, 260.99it/s] 85%|████████▌ | 1362/1593 [00:04<00:00, 290.58it/s] 89%|████████▉ | 1418/1593 [00:04<00:00, 364.65it/s] 91%|█████████▏| 1456/1593 [00:05<00:00, 330.19it/s] 94%|█████████▎| 1491/1593 [00:05<00:00, 309.76it/s] 96%|█████████▌| 1523/1593 [00:05<00:00, 303.86it/s] 98%|█████████▊| 1554/1593 [00:05<00:00, 300.71it/s]100%|█████████▉| 1588/1593 [00:05<00:00, 307.08it/s]100%|██████████| 1593/1593 [00:05<00:00, 285.92it/s]
  0%|          | 0/50 [00:00<?, ?it/s]/raid/cs21mtech12001/Research/CodeBERT/Repository/GraphCodeBERT/code-summarization/model.py:175: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  prevK = bestScoresId // numWords
  2%|▏         | 1/50 [00:11<09:12, 11.27s/it]  4%|▍         | 2/50 [00:15<05:55,  7.40s/it]  6%|▌         | 3/50 [00:18<04:10,  5.33s/it]  8%|▊         | 4/50 [00:26<04:46,  6.23s/it] 10%|█         | 5/50 [00:29<03:42,  4.96s/it] 12%|█▏        | 6/50 [00:33<03:23,  4.63s/it] 14%|█▍        | 7/50 [00:37<03:21,  4.68s/it] 16%|█▌        | 8/50 [00:44<03:43,  5.32s/it] 18%|█▊        | 9/50 [00:49<03:29,  5.12s/it] 20%|██        | 10/50 [00:53<03:07,  4.69s/it] 22%|██▏       | 11/50 [00:56<02:46,  4.27s/it] 24%|██▍       | 12/50 [01:00<02:38,  4.16s/it] 26%|██▌       | 13/50 [01:04<02:40,  4.34s/it] 28%|██▊       | 14/50 [01:06<02:09,  3.59s/it] 30%|███       | 15/50 [01:12<02:32,  4.35s/it] 32%|███▏      | 16/50 [01:20<02:57,  5.22s/it] 34%|███▍      | 17/50 [01:30<03:40,  6.68s/it] 36%|███▌      | 18/50 [01:34<03:08,  5.88s/it] 38%|███▊      | 19/50 [01:37<02:41,  5.20s/it] 40%|████      | 20/50 [01:41<02:18,  4.63s/it] 42%|████▏     | 21/50 [01:48<02:40,  5.55s/it] 44%|████▍     | 22/50 [01:52<02:21,  5.05s/it] 46%|████▌     | 23/50 [01:56<02:02,  4.52s/it] 48%|████▊     | 24/50 [02:00<01:59,  4.58s/it] 50%|█████     | 25/50 [02:04<01:47,  4.29s/it] 52%|█████▏    | 26/50 [02:11<02:04,  5.21s/it] 54%|█████▍    | 27/50 [02:16<01:59,  5.21s/it] 56%|█████▌    | 28/50 [02:22<01:56,  5.29s/it] 58%|█████▊    | 29/50 [02:26<01:42,  4.89s/it] 60%|██████    | 30/50 [02:29<01:28,  4.40s/it] 62%|██████▏   | 31/50 [02:33<01:21,  4.30s/it] 64%|██████▍   | 32/50 [02:36<01:06,  3.71s/it] 66%|██████▌   | 33/50 [02:39<01:00,  3.58s/it] 68%|██████▊   | 34/50 [02:42<00:53,  3.35s/it] 70%|███████   | 35/50 [02:51<01:17,  5.14s/it] 72%|███████▏  | 36/50 [02:54<01:04,  4.57s/it] 74%|███████▍  | 37/50 [03:06<01:29,  6.85s/it] 76%|███████▌  | 38/50 [03:17<01:35,  7.98s/it] 78%|███████▊  | 39/50 [03:21<01:14,  6.76s/it] 80%|████████  | 40/50 [03:25<01:00,  6.08s/it] 82%|████████▏ | 41/50 [03:30<00:49,  5.50s/it] 84%|████████▍ | 42/50 [03:33<00:38,  4.77s/it] 86%|████████▌ | 43/50 [03:36<00:31,  4.44s/it] 88%|████████▊ | 44/50 [03:39<00:23,  3.85s/it] 90%|█████████ | 45/50 [03:42<00:19,  3.82s/it] 92%|█████████▏| 46/50 [03:46<00:14,  3.60s/it] 94%|█████████▍| 47/50 [03:54<00:14,  4.95s/it] 96%|█████████▌| 48/50 [03:57<00:09,  4.51s/it] 98%|█████████▊| 49/50 [04:07<00:05,  5.99s/it]100%|██████████| 50/50 [04:10<00:00,  5.21s/it]100%|██████████| 50/50 [04:10<00:00,  5.01s/it]
Total: 1593
10/18/2022 21:43:01 - INFO - __main__ -     bleu-4 = 12.11 
10/18/2022 21:43:01 - INFO - __main__ -     ********************
10/18/2022 21:43:01 - INFO - __main__ -   Test file: /raid/cs21mtech12001/Research/Notebooks_Dataset/splitted_data/competition_notebooks_with_atleast_1_medal_and_10_votes/without_summarization/code-with-usm-only-2/test_dataset.jsonl
  0%|          | 0/1679 [00:00<?, ?it/s]  2%|▏         | 27/1679 [00:00<00:06, 256.67it/s]  3%|▎         | 55/1679 [00:00<00:06, 269.65it/s]  5%|▌         | 89/1679 [00:00<00:05, 298.76it/s]  7%|▋         | 121/1679 [00:00<00:05, 301.86it/s]  9%|▉         | 152/1679 [00:00<00:05, 293.81it/s] 11%|█         | 182/1679 [00:00<00:05, 273.72it/s] 13%|█▎        | 211/1679 [00:00<00:05, 277.81it/s] 14%|█▍        | 241/1679 [00:00<00:05, 282.52it/s] 16%|█▌        | 270/1679 [00:00<00:05, 281.46it/s] 18%|█▊        | 301/1679 [00:01<00:04, 287.56it/s] 20%|█▉        | 333/1679 [00:01<00:04, 293.34it/s] 22%|██▏       | 363/1679 [00:01<00:04, 283.14it/s] 23%|██▎       | 392/1679 [00:01<00:04, 283.93it/s] 25%|██▌       | 421/1679 [00:01<00:04, 278.82it/s] 27%|██▋       | 453/1679 [00:01<00:04, 287.58it/s] 29%|██▊       | 482/1679 [00:01<00:04, 286.93it/s] 30%|███       | 511/1679 [00:01<00:04, 280.93it/s] 32%|███▏      | 540/1679 [00:02<00:05, 211.71it/s] 34%|███▍      | 568/1679 [00:02<00:04, 227.22it/s] 35%|███▌      | 594/1679 [00:02<00:04, 234.42it/s] 37%|███▋      | 622/1679 [00:02<00:04, 245.69it/s] 39%|███▊      | 650/1679 [00:02<00:04, 251.99it/s] 41%|████      | 681/1679 [00:02<00:03, 265.76it/s] 43%|████▎     | 718/1679 [00:02<00:03, 293.04it/s] 45%|████▍     | 748/1679 [00:02<00:03, 287.89it/s] 47%|████▋     | 781/1679 [00:02<00:03, 299.11it/s] 48%|████▊     | 812/1679 [00:02<00:02, 294.86it/s] 50%|█████     | 846/1679 [00:03<00:02, 306.87it/s] 52%|█████▏    | 878/1679 [00:03<00:02, 309.67it/s] 54%|█████▍    | 910/1679 [00:03<00:02, 291.70it/s] 56%|█████▌    | 940/1679 [00:03<00:02, 293.80it/s] 58%|█████▊    | 970/1679 [00:03<00:02, 287.58it/s] 59%|█████▉    | 999/1679 [00:03<00:02, 286.78it/s] 61%|██████    | 1028/1679 [00:03<00:02, 278.64it/s] 63%|██████▎   | 1056/1679 [00:03<00:02, 258.56it/s] 65%|██████▍   | 1083/1679 [00:03<00:02, 254.13it/s] 66%|██████▋   | 1115/1679 [00:04<00:02, 271.13it/s] 68%|██████▊   | 1145/1679 [00:04<00:01, 275.80it/s] 70%|██████▉   | 1173/1679 [00:04<00:01, 260.97it/s] 72%|███████▏  | 1201/1679 [00:04<00:01, 263.66it/s] 73%|███████▎  | 1228/1679 [00:04<00:01, 260.55it/s] 75%|███████▌  | 1260/1679 [00:04<00:01, 274.39it/s] 77%|███████▋  | 1290/1679 [00:04<00:01, 279.53it/s] 79%|███████▊  | 1319/1679 [00:04<00:01, 268.19it/s] 81%|████████  | 1353/1679 [00:04<00:01, 287.10it/s] 82%|████████▏ | 1382/1679 [00:05<00:01, 276.39it/s] 84%|████████▍ | 1410/1679 [00:05<00:00, 271.89it/s] 86%|████████▌ | 1438/1679 [00:05<00:00, 273.63it/s] 87%|████████▋ | 1466/1679 [00:05<00:00, 274.23it/s] 89%|████████▉ | 1494/1679 [00:05<00:00, 268.15it/s] 91%|█████████ | 1525/1679 [00:05<00:00, 278.23it/s] 93%|█████████▎| 1554/1679 [00:05<00:00, 278.61it/s] 95%|█████████▍| 1587/1679 [00:05<00:00, 288.88it/s] 96%|█████████▌| 1616/1679 [00:05<00:00, 285.98it/s] 98%|█████████▊| 1645/1679 [00:05<00:00, 285.05it/s]100%|█████████▉| 1676/1679 [00:06<00:00, 291.17it/s]100%|██████████| 1679/1679 [00:06<00:00, 276.50it/s]
  0%|          | 0/53 [00:00<?, ?it/s]  2%|▏         | 1/53 [00:03<03:13,  3.72s/it]  4%|▍         | 2/53 [00:06<02:49,  3.33s/it]  6%|▌         | 3/53 [00:10<02:46,  3.34s/it]  8%|▊         | 4/53 [00:13<02:39,  3.25s/it]  9%|▉         | 5/53 [00:16<02:33,  3.19s/it] 11%|█▏        | 6/53 [00:19<02:31,  3.22s/it] 13%|█▎        | 7/53 [00:22<02:30,  3.27s/it] 15%|█▌        | 8/53 [00:30<03:33,  4.75s/it] 17%|█▋        | 9/53 [00:40<04:33,  6.23s/it] 19%|█▉        | 10/53 [00:43<03:42,  5.18s/it] 21%|██        | 11/53 [00:46<03:07,  4.46s/it] 23%|██▎       | 12/53 [00:50<03:01,  4.44s/it] 25%|██▍       | 13/53 [00:52<02:29,  3.73s/it] 26%|██▋       | 14/53 [00:57<02:42,  4.16s/it] 28%|██▊       | 15/53 [01:01<02:30,  3.97s/it] 30%|███       | 16/53 [01:03<02:11,  3.55s/it] 32%|███▏      | 17/53 [01:08<02:15,  3.77s/it] 34%|███▍      | 18/53 [01:10<01:56,  3.34s/it] 36%|███▌      | 19/53 [01:13<01:50,  3.26s/it] 38%|███▊      | 20/53 [01:17<01:54,  3.46s/it] 40%|███▉      | 21/53 [01:20<01:46,  3.32s/it] 42%|████▏     | 22/53 [01:27<02:14,  4.34s/it] 43%|████▎     | 23/53 [01:34<02:33,  5.12s/it] 45%|████▌     | 24/53 [01:38<02:19,  4.80s/it] 47%|████▋     | 25/53 [01:42<02:09,  4.61s/it] 49%|████▉     | 26/53 [01:49<02:21,  5.25s/it] 51%|█████     | 27/53 [01:55<02:29,  5.73s/it] 53%|█████▎    | 28/53 [02:01<02:25,  5.83s/it] 55%|█████▍    | 29/53 [02:07<02:15,  5.65s/it] 57%|█████▋    | 30/53 [02:11<01:57,  5.11s/it] 58%|█████▊    | 31/53 [02:14<01:41,  4.61s/it] 60%|██████    | 32/53 [02:17<01:27,  4.17s/it] 62%|██████▏   | 33/53 [02:19<01:10,  3.50s/it] 64%|██████▍   | 34/53 [02:23<01:08,  3.63s/it] 66%|██████▌   | 35/53 [02:29<01:19,  4.40s/it] 68%|██████▊   | 36/53 [02:34<01:16,  4.48s/it] 70%|██████▉   | 37/53 [02:38<01:09,  4.34s/it] 72%|███████▏  | 38/53 [02:41<00:57,  3.85s/it] 74%|███████▎  | 39/53 [02:46<00:59,  4.23s/it] 75%|███████▌  | 40/53 [02:51<00:58,  4.51s/it] 77%|███████▋  | 41/53 [02:54<00:50,  4.19s/it] 79%|███████▉  | 42/53 [02:58<00:42,  3.91s/it] 81%|████████  | 43/53 [03:05<00:50,  5.06s/it] 83%|████████▎ | 44/53 [03:09<00:42,  4.75s/it] 85%|████████▍ | 45/53 [03:12<00:34,  4.28s/it] 87%|████████▋ | 46/53 [03:15<00:27,  3.89s/it] 89%|████████▊ | 47/53 [03:20<00:24,  4.01s/it] 91%|█████████ | 48/53 [03:25<00:22,  4.43s/it] 92%|█████████▏| 49/53 [03:32<00:21,  5.28s/it] 94%|█████████▍| 50/53 [03:41<00:18,  6.32s/it] 96%|█████████▌| 51/53 [03:46<00:11,  5.81s/it] 98%|█████████▊| 52/53 [03:56<00:07,  7.02s/it]100%|██████████| 53/53 [04:03<00:00,  7.24s/it]100%|██████████| 53/53 [04:04<00:00,  4.60s/it]
Total: 1679
10/18/2022 21:47:12 - INFO - __main__ -     bleu-4 = 11.39 
10/18/2022 21:47:12 - INFO - __main__ -     ********************
