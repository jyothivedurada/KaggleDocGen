436	valid_preds random_forest predict features plt figure figsize sns kdeplot y_valid label sns kdeplot valid_preds label plt legend prop 'size' plt title
285	fig ax1 ax2 plt subplots nrows fig set_size_inches sn countplot "bathrooms" data data ax ax1 data1 data groupby 'bathrooms' 'interest_level' 'bathrooms' count unstack 'interest_level' fillna data1 'low' 'medium' "high" plot kind 'bar' stacked True ax ax2
706	best_confidence np zeros len train_df BestRandSearchScore scorehist print "running random search..." for in range trial_confidence np random randint size len train_df train_df trial_confidence train_df 'sigma_clipped' train_df apply lambda max train_df 'diff' abs train_df 'FVC' train_df train_df 'delta' train_df 'diff' apply lambda min train_df 'score' math sqrt train_df 'delta' train_df 'sigma_clipped' np log math sqrt train_df 'sigma_clipped' score train_df 'score' mean if score BestRandSearchScore BestRandSearchScore score best_confidence trial_confidence print "best confidence values found in round {} with best score of {}" format score scorehist append BestRandSearchScore
522	column_types dtypes int_cols column_types column_types 'int' float_cols column_types column_types 'float' cat_cols column_types column_types 'object' print '\tinteger columns:\n{}' format int_cols print '\n\tfloat columns:\n{}' format float_cols print '\n\tto encode categorical columns:\n{}' format cat_cols
626	del model from keras import backend as import gc clear_session gc collect
379	model save include_optimizer False open "preprocess.dill" "wb" dill dump preprocess close classify_model save 'classify_model.h5' include_optimizer False open "classify_preprocess.dill" "wb" dill dump classify_preprocess close if mode 'train'
209	CALENDAR_DTYPES 'date' 'str' 'wm_yr_wk' 'int16' 'weekday' 'object' 'wday' 'int16' 'month' 'int16' 'year' 'int16' 'd' 'object' 'event_name_1' 'object' 'event_type_1' 'object' 'event_name_2' 'object' 'event_type_2' 'object' 'int16' 'int16' 'int16' PARSE_DATES 'date' SPRICES_DTYPES 'store_id' 'object' 'item_id' 'object' 'wm_yr_wk' 'int16' 'sell_price' 'float32'
578	def create_title_mode train_labels titles train_labels title unique title2mode for title in titles mode train_labels train_labels title title accuracy_group value_counts index title2mode title mode return title2mode def add_title_mode labels title2mode labels 'title_mode' labels title apply lambda title title2mode title return labels
243	param 'num_leaves' 'max_bin' 'min_data_in_leaf' 'learning_rate' 'min_sum_hessian_in_leaf' 'bagging_fraction' 'bagging_freq' 'feature_fraction' 'lambda_l1' 'lambda_l2' 'min_gain_to_split' 'max_depth' 'save_binary' True 'seed' 'feature_fraction_seed' 'bagging_seed' 'drop_seed' 'data_random_seed' 'objective' 'binary' 'boosting_type' 'gbdt' 'verbose' 'metric' 'auc' 'is_unbalance' True 'boost_from_average' False
514	result 'toxic' model predict_proba f_matrix_test result 'severe_toxic' model predict_proba f_matrix_test result 'obscene' model predict_proba f_matrix_test result 'threat' model predict_proba f_matrix_test result 'insult' model predict_proba f_matrix_test result 'identity_hate' model predict_proba f_matrix_test
264	target0df metadata_train metadata_train 'target' target1df metadata_train metadata_train 'target' print "target0data shape:" target0df shape print "target1data shape:" target1df shape
480	train_labels np array train 'TARGET' astype np int32 reshape train train drop columns 'SK_ID_CURR' 'TARGET' test_ids list test 'SK_ID_CURR' test test drop columns 'SK_ID_CURR'
863	app_both 'LOAN_INCOME_RATIO' app_both 'AMT_CREDIT' app_both 'AMT_INCOME_TOTAL' app_both 'ANNUITY_INCOME_RATIO' app_both 'AMT_ANNUITY' app_both 'AMT_INCOME_TOTAL' app_both 'ANNUITY LENGTH' app_both 'AMT_CREDIT' app_both 'AMT_ANNUITY' app_both 'WORKING_LIFE_RATIO' app_both 'DAYS_EMPLOYED' app_both 'DAYS_BIRTH' app_both 'INCOME_PER_FAM' app_both 'AMT_INCOME_TOTAL' app_both 'CNT_FAM_MEMBERS' app_both 'CHILDREN_RATIO' app_both 'CNT_CHILDREN' app_both 'CNT_FAM_MEMBERS'
722	n_iter start datetime datetime now for in range n_iter batch_cutmix images labels PROBABILITY end datetime datetime now timing end start total_seconds n_iter print f"batch_cutmix: {timing}"
687	for item in sorted cls_counts items key lambda reverse True _id count item item label label_map int _id print f'attribute_name: {label} count: {count}'
792	total train isnull sum sort_values ascending False percent train isnull sum train isnull count sort_values ascending False missing_train_data pd concat total percent axis keys
878	feature_cols col for col in train columns if col not in 'is_churn' 'msno' train feature_cols train feature_cols applymap lambda np nan if np isinf else test feature_cols test feature_cols applymap lambda np nan if np isinf else
618	train_label train_df 'label' test_indices test_df 'id' train_df train_df drop 'label' axis test_df test_df drop 'id' axis train_x train_df values train_y train_label values test_x test_df values print "shape of train_x :" train_x shape print "shape of train_y :" train_y shape print "shape of test_x :" test_x shape
670	import numpy as np import pandas as pd import efficientnet tfkeras as efn from tensorflow keras import backend as import tensorflow_addons as tfa import tensorflow keras layers as layers import tensorflow as tf
226	train 'year_built' np uint8 train 'year_built' inplace True test 'year_built' np uint8 test 'year_built' inplace True
405	heads data loc data 'parentesco1' copy train_labels data loc data notnull data 'parentesco1' 'idhogar' label_counts train_labels value_counts sort_index label_counts plot bar figsize color colors values edgecolor 'k' linewidth plt xlabel plt ylabel plt xticks for in poverty_mapping keys list poverty_mapping values rotation plt title label_counts
303	for in cat_feature df pd factorize df trn_cat df cat_feature values tst_cat df cat_feature values
131	all for in range input_ids_t shape np argmax preds_start np argmax preds_end if st test loc 'text' else text1 join test loc 'text' split enc tokenizer encode text1 st tokenizer decode enc ids all append st
245	vector vectorizer transform text print vector shape print vector toarray
46	train iloc train train iloc pd DataFrame pd DataFrame for in range lag_featrues imp_col y_train iloc lag_featrues imp_col pred lgbm_pred y_train "pred_{}_day" format pred
302	train pd read_csv '../input/train.csv' low_memory False index_col 'id' test pd read_csv '../input/test.csv' low_memory False index_col 'id' res pd read_csv '../input/resources.csv' low_memory False index_col 'id'
367	real_kappas fold_kappas for in tqdm range df_pred_simulated df_gt_simulated copy inds_to_shuffle np random choice range len df_gt_simulated int len df_gt_simulated df_pred_simulated inds_to_shuffle np random permutation df_pred_simulated inds_to_shuffle real_kappa cohen_kappa_score df_gt_simulated df_pred_simulated weights 'quadratic' scores for in zip np split df_gt_simulated np split df_pred_simulated scores append cohen_kappa_score weights 'quadratic' for in scores real_kappas append real_kappa fold_kappas append
879	from sklearn metrics import confusion_matrix precision_recall_curve auc roc_curve recall_score classification_report f1_score precision_recall_fscore_support
585	with strategy scope transformer_layer TFAutoModel from_pretrained MODEL model build_model transformer_layer max_len MAX_LEN model summary
747	LR_START LR_MAX strategy num_replicas_in_sync LR_MIN LR_RAMPUP_EPOCHS LR_SUSTAIN_EPOCHS LR_EXP_DECAY def lrfn epoch if epoch LR_RAMPUP_EPOCHS lr LR_MAX LR_START LR_RAMPUP_EPOCHS epoch LR_START elif epoch LR_RAMPUP_EPOCHS LR_SUSTAIN_EPOCHS lr LR_MAX else lr LR_MAX LR_MIN LR_EXP_DECAY epoch LR_RAMPUP_EPOCHS LR_SUSTAIN_EPOCHS LR_MIN return lr lr_callback tf keras callbacks LearningRateScheduler lrfn verbose True rng for in range if EPOCHS else EPOCHS lrfn for in rng plt plot rng print format max
175	dup_diff_target dup dup 'mean' dup 'mean' len_dup_diff_target len dup_diff_target print len_dup_diff_target
253	application_train pd read_csv '../input/application_train.csv' application_test pd read_csv '../input/application_test.csv' bureau pd read_csv '../input/bureau.csv' bureau_balance pd read_csv '../input/bureau_balance.csv' pd read_csv credit_card_balance pd read_csv '../input/credit_card_balance.csv' previous_application pd read_csv '../input/previous_application.csv' installments_payments pd read_csv '../input/installments_payments.csv'
247	from sklearn feature_extraction text import HashingVectorizer text "it was the worst of times" "it was the age of wisdom" "it was the age of foolishness" vectorizer HashingVectorizer n_features vector vectorizer transform text print vector shape print vector toarray
810	proportion train 'os' 'is_attributed' groupby 'os' as_index False mean sort_values 'is_attributed' ascending False counts train 'os' 'is_attributed' groupby 'os' as_index False count sort_values 'is_attributed' ascending False merge counts merge proportion on 'os' how 'left' merge columns 'os' 'click_count' 'prop_downloaded' ax merge plot secondary_y 'prop_downloaded' plt title ax set ylabel plt ylabel plt show print print merge
872	np save "x_train" x_train np save "x_test" x_test np save "y_train" y_train np save "features" features np save "test_features" test_features np save "word_index.npy" word_index
653	zone_dict def set_localtime df for sid zone in zone_dict items sids df site_id sid df loc sids 'timestamp' df sids timestamp pd offsets Hour zone
250	from keras models import Model from keras layers import Input from keras layers import Dense visible Input shape hidden Dense visible model Model inputs visible outputs hidden
625	with strategy scope transformer_layer TFAutoModel from_pretrained MODEL model build_model_PT transformer_layer max_len MAX_LEN
387	cheap df df price category_name value_counts map lambda '{:.2f}%' format df shape print cheap head
304	df_text df text_feature fillna df_text 'full_text' for in text_feature df_text 'full_text' df_text 'full_text' df_text
854	def predict_with_keras_model test features model_list full_preds for in model_list preds predict np expand_dims test features values axis batch_size full_preds append preds preds np array full_preds mean axis return preds overall_test_predictions predict_with_keras_model test features model_list test 'target' overall_test_predictions test 'target' to_csv SUBM_PATH 'test_auc_{}.csv' format score index False float_format '%.8f'
14	train_log_target train_df 'target' train_log_target 'target' np log train_df 'target' values train_log_target describe
108	BASEPATH "../input/siim-isic-melanoma-classification" df_train pd read_csv os path join BASEPATH 'train.csv' df_test pd read_csv os path join BASEPATH 'test.csv' df_sub pd read_csv os path join BASEPATH 'sample_submission.csv' GCS_PATH KaggleDatasets get_gcs_path 'melanoma-256x256' files_train np sort np array tf io gfile glob GCS_PATH '/train*.tfrec' files_test np sort np array tf io gfile glob GCS_PATH '/test*.tfrec'
62	test_gen ImageDataGenerator rescale test_generator test_gen flow_from_dataframe test_df "../input/test1/test1/" x_col 'filename' y_col None class_mode None target_size IMAGE_SIZE batch_size batch_size shuffle False
707	train_size int len scaled test_size len scaled train_size scaled train_size scaled train_size len scaled print len len
190	train_df pd read_csv os path join DATA_DIR 'train.csv' dtype 'acoustic_data' np int16 'time_to_failure' np float32 print train_df shape print 'ok'
779	train_df head percent train_df isnull sum train_df shape sort_values ascending False percent
71	df pd read_csv '../input/train.csv' skiprows nrows header pd read_csv '../input/train.csv' nrows df columns header columns df del header gc collect print df shape "rows."
646	root Path '../input/ashrae-feather-format-for-fast-loading' train_df pd read_feather root 'train.feather' weather_train_df pd read_feather root 'weather_train.feather' weather_test_df pd read_feather root 'weather_test.feather' building_meta_df pd read_feather root 'building_metadata.feather'
548	with strategy scope enet efn input_shape weights 'noisy-student' include_top False model tf keras Sequential enet tf keras layers tf keras layers Dense len CLASSES activation 'softmax' model compile optimizer tf keras optimizers Adam lr loss 'sparse_categorical_crossentropy' metrics 'sparse_categorical_accuracy' model summary
787	def oneHotEncode_dataframe df features for feature in features temp_onehot_encoded pd get_dummies df feature column_names format feature for in temp_onehot_encoded columns temp_onehot_encoded columns column_names df df drop feature axis df pd concat df temp_onehot_encoded axis return df
349	fagg_model_accuracies perform_feature_agglomeration y_train y_test print fagg_model_accuracies
214	tag_to_count_map tupl dict tag_to_count_map items word_cloud WordCloud width height generate_from_frequencies tupl plt figure figsize plt imshow word_cloud plt axis 'off' plt tight_layout pad
553	sample_idxs np random choice np arange len train_df for in sample_idxs sample_prep labels processor prepareSample train_root train_df iloc processor createMel CONFIG TRAINING_CONFIG test_mode False proc_mode 'resize' print sample_prep max sample_prep min print sample_prep shape labels shape NCOLS NROWS fig ax plt subplots NCOLS NROWS figsize fig suptitle format labels ax imshow sample_prep cmap plt show
659	ucf_root Path '../input/ashrae-ucf-spider-and-eda-full-test-labels' leak_df pd read_pickle ucf_root 'site0.pkl' leak_df 'meter_reading' leak_df meter_reading_scraped leak_df drop 'meter_reading_original' 'meter_reading_scraped' axis inplace True leak_df fillna inplace True leak_df loc leak_df meter_reading 'meter_reading' leak_df leak_df leak_df timestamp dt year print len leak_df
691	import numpy as np import pandas as pd from tqdm import tqdm import copy import multiprocessing import nltk import re import gensim models word2vec as w2v import matplotlib pyplot as plt
643	def add_lag_feature weather_df window group_df weather_df groupby 'site_id' cols 'air_temperature' 'cloud_coverage' 'dew_temperature' 'precip_depth_1_hr' 'sea_level_pressure' 'wind_direction' 'wind_speed' rolled group_df cols rolling window window min_periods lag_mean rolled mean reset_index astype np float16 lag_max rolled max reset_index astype np float16 lag_min rolled min reset_index astype np float16 lag_std rolled std reset_index astype np float16 for col in cols weather_df f'{col}_mean_lag{window}' lag_mean col weather_df f'{col}_max_lag{window}' lag_max col weather_df f'{col}_min_lag{window}' lag_min col weather_df f'{col}_std_lag{window}' lag_std col
328	has_to_run_sir True has_to_run_sird False has_to_run_seir True has_to_run_seird False has_to_run_seirdq True
40	train Image values del train train values
563	preds test_preds argmax axis astype np int8 print f'predicted accuracy_group distribution:\n\n{pd.Series(preds).value_counts(normalize=True)} \n\n' submission 'accuracy_group' preds submission to_csv 'submission.csv' index False
172	DATA_DIR '../input/gplearn-data' submission pd read_csv os path join 'sample_submission.csv' index_col 'seg_id' scaled_train_X pd read_csv os path join DATA_DIR scaled_test_X pd read_csv os path join DATA_DIR train_y pd read_csv os path join DATA_DIR predictions np zeros len scaled_test_X print 'ok'
479	fig axs plt subplots figsize for hyper in enumerate 'reg_alpha' 'reg_lambda' 'subsample_for_bin' 'subsample' random_hyp hyper random_hyp hyper astype float sns regplot hyper 'score' data random_hyp ax axs color 'b' scatter_kws 'alpha' axs scatter best_random_hyp hyper best_random_hyp 'score' marker 'b' edgecolor 'k' axs set xlabel format hyper ylabel title format hyper opt_hyp hyper opt_hyp hyper astype float sns regplot hyper 'score' data opt_hyp ax axs color 'g' scatter_kws 'alpha' axs scatter best_opt_hyp hyper best_opt_hyp 'score' marker 'g' edgecolor 'k' plt legend plt tight_layout
884	market_train_df 'price_diff' market_train_df 'close' market_train_df 'open' grouped market_train_df groupby 'time' agg 'price_diff' 'std' 'min' reset_index grouped sort_values 'price_diff' 'std' ascending False 'min_text' np round 'price_diff' 'min' astype str trace go Scatter 'time' dt strftime date_format values 'price_diff' 'std' values mode 'markers' marker dict size 'price_diff' 'std' values color 'price_diff' 'std' values colorscale showscale True text 'min_text' values data trace layout go Layout autosize True title hovermode 'closest' yaxis dict title 'price_diff' ticklen gridwidth showlegend False fig go Figure data data layout layout py iplot fig filename 'scatter2010'
29	df_text pd read_csv '../input/training_text' sep engine 'python' skiprows names 'ID' set_index 'ID' df_text head
511	def text_to_words raw_text remove_stopwords False letters_only re sub raw_text words letters_only lower split if remove_stopwords stops set stopwords words "english" meaningful_words for in words if not in stops words meaningful_words return words sentences_train train 'comment_text' apply text_to_words remove_stopwords False sentences_test test 'comment_text' apply text_to_words remove_stopwords False print sentences_train
685	from collections import Counter cls_counts Counter cls for classes in train 'attribute_ids' str split for cls in classes print len cls_counts
150	df_0 df_train df_train 'binary_target' df_1 df_train df_train 'binary_target' sample len df_0 random_state df_data pd concat df_0 df_1 axis reset_index drop True df_data shuffle df_data print df_data shape df_data head
208	dataiter iter validation_loader images labels dataiter next images images to device labels labels to device output model images preds torch max output fig plt figure figsize for idx in np arange ax fig add_subplot idx xticks yticks plt imshow im_convert images idx ax set_title format str classes preds idx item str classes labels idx item color "green" if preds idx labels idx else "red"
341	filters kernel_size hidden_dims
538	def plots_of_daily country country_name temp country temp columns 'prior_confirmed' 'prior_deaths' 'prior_recovered' 'daily_confirmed' 'daily_deaths' 'daily_recovered' 'delta_deaths' 'delta_recovered' last_date temp iloc len temp fig px line temp log_y False width height title country_name color_discrete_sequence dth rec fig show rates for key value in dict items plots_of_daily value key
47	fig px line train_df 'FVC' line_group color title fig update_traces mode 'lines+markers'
509	train pd read_csv '../input/train.csv' test pd read_csv '../input/test.csv' result test 'id' copy print train head
843	df_train pd read_csv "../input/train.csv" df_test pd read_csv "../input/test.csv" df pd concat df_train df_test sort True
327	df_population pd read_csv "../input/countries-of-the-world/countries of the world.csv" df_population
526	train_path data_src 'train' test_path data_src train_ids train_df index values test_ids test_df index values
398	test test 'key_id' iloc 'drawing' img draw_cv2 ast literal_eval img_size plt imshow img
70	sns set plt hist sub1 bins plt show
869	target train_df pop 'TARGET' lgbm_train lgbm Dataset data train_df label target categorical_feature categorical_feats free_raw_data False lgbm_params 'boosting' 'dart' 'application' 'binary' 'learning_rate' 'min_data_in_leaf' 'num_leaves' 'max_depth' 'feature_fraction' 'scale_pos_weight' 'drop_rate' cv_results lgbm cv train_set lgbm_train params lgbm_params nfold num_boost_round early_stopping_rounds verbose_eval metrics 'auc' optimum_boost_rounds np argmax cv_results 'auc-mean' print format optimum_boost_rounds print format np max cv_results 'auc-mean' clf lgbm train train_set lgbm_train params lgbm_params num_boost_round optimum_boost_rounds y_pred clf predict test_df
871	fig ax1 plt subplots figsize plt title plt plot train 'acoustic_data' values color 'y' ax1 set_ylabel 'acoustic_data' color 'y' plt legend 'acoustic_data' ax2 ax1 twinx plt plot train 'time_to_failure' values color 'r' ax2 set_ylabel 'time_to_failure' color 'r' plt legend 'time_to_failure' loc plt grid False
725	type_dict 'ncodpers' np int32 'ind_ahor_fin_ult1' np uint8 'ind_aval_fin_ult1' np uint8 'ind_cco_fin_ult1' np uint8 'ind_cder_fin_ult1' np uint8 'ind_cno_fin_ult1' np uint8 'ind_ctju_fin_ult1' np uint8 'ind_ctma_fin_ult1' np uint8 'ind_ctop_fin_ult1' np uint8 'ind_ctpp_fin_ult1' np uint8 'ind_deco_fin_ult1' np uint8 'ind_deme_fin_ult1' np uint8 'ind_dela_fin_ult1' np uint8 'ind_ecue_fin_ult1' np uint8 'ind_fond_fin_ult1' np uint8 'ind_hip_fin_ult1' np uint8 'ind_plan_fin_ult1' np uint8 'ind_pres_fin_ult1' np uint8 'ind_reca_fin_ult1' np uint8 'ind_tjcr_fin_ult1' np uint8 'ind_valo_fin_ult1' np uint8 'ind_viv_fin_ult1' np uint8 'ind_recibo_ult1' np uint8 train pd read_csv '../input/train_ver2.csv' nrows dtype type_dict test pd read_csv '../input/test_ver2.csv'
380	import warnings warnings filterwarnings "ignore" import pandas as pd import numpy as np import matplotlib pyplot as plt import seaborn as sns from sklearn impute import SimpleImputer import scipy from sklearn linear_model import LogisticRegression from sklearn metrics import auc roc_curve from sklearn model_selection import StratifiedKFold GridSearchCV from tqdm import tqdm_notebook
744	keys_tensor tf constant for in numbers_of_repetition_for_classes vals_tensor tf constant numbers_of_repetition_for_classes for in numbers_of_repetition_for_classes table tf lookup StaticHashTable tf lookup KeyValueTensorInitializer keys_tensor vals_tensor def get_num_of_repetition_for_example training_example label training_example num_to_repeat table lookup label num_to_repeat_integral tf cast int num_to_repeat tf float32 residue num_to_repeat num_to_repeat_integral num_to_repeat num_to_repeat_integral tf cast tf random uniform shape residue tf float32 return tf cast num_to_repeat tf int64
370	length labels for label in df_train "labels" if type label str split_label label split length labels split_label
355	df pd merge agg reset_index products on how 'left' groupby 'short_name' sum sort_values by ascending False
399	train_df 'ID' train_df 'ID' str rsplit pat expand True print train_df shape train_df head
596	pickle dump best_hp open 'best_hp.pickle' 'wb' best_model tuner get_best_models best_model save 'best_model.h5'
11	col 'identity_hate' print col pred lr predict print confusion_matrix col pred print classification_report col pred
65	model CatBoostClassifier iterations learning_rate depth l2_leaf_reg loss_function
295	fig ax1 plt subplots fig set_size_inches merged "yearbuilt" merged "yearbuilt" map lambda str split yearMerged merged groupby 'yearbuilt' 'numberofstories' "parcelid" count unstack 'numberofstories' fillna yearMerged plot kind 'bar' stacked True ax ax1
294	ulimit np percentile merged logerror values llimit np percentile merged logerror values merged 'logerror' ix merged 'logerror' ulimit ulimit merged 'logerror' ix merged 'logerror' llimit llimit fig ax plt subplots fig set_size_inches sn distplot merged logerror values bins kde False color Distribution Of Dependent Variable
666	def change addr if addr return elif addr return elif addr np nan return np nan else return df df "addr2" map change
542	plt style use 'default' plt rcParams 'figure.figsize' N_COLS N_ROWS fig ax plt subplots N_COLS N_ROWS for in range N_COLS for in range N_ROWS ridx np random randint len tr_df img_row tr_df iloc ridx img_filename img_row 'image_filename' pet_id img_row pet_label img_row image tr_parser load_image img_filename preprocess False ax imshow image ax set_title format pet_id pet_label size
282	dataPriceLimited data copy upperLimit np percentile dataPriceLimited price values dataPriceLimited 'price' ix dataPriceLimited 'price' upperLimit upperLimit fig ax1 ax2 plt subplots ncols fig set_size_inches sn distplot data price values bins kde True ax ax1 sn distplot dataPriceLimited price values bins kde True ax ax2
786	etc_ordianal_features 'ps_ind_01' 'ps_ind_03' 'ps_ind_14' 'ps_ind_15' 'ps_reg_01' 'ps_reg_02' 'ps_car_11' 'ps_calc_01' 'ps_calc_02' 'ps_calc_03' 'ps_calc_04' 'ps_calc_05' 'ps_calc_06' 'ps_calc_07' 'ps_calc_08' 'ps_calc_09' 'ps_calc_10' 'ps_calc_11' 'ps_calc_12' 'ps_calc_13' 'ps_calc_14' etc_continuous_features 'ps_reg_03' 'ps_car_12' 'ps_car_13' 'ps_car_14' 'ps_car_15' train_null_columns train_null columns test_null_columns test_null columns
324	df_grouped_spain get_df_country_cases df_covid df_spain_cases_by_day df_grouped_spain df_grouped_spain confirmed df_spain_cases_by_day df_spain_cases_by_day reset_index drop True df_spain_cases_by_day 'day' df_spain_cases_by_day date apply lambda df_spain_cases_by_day date min days reordered_columns 'date' 'day' 'confirmed' 'deaths' 'confirmed_marker' 'deaths_marker' df_spain_cases_by_day df_spain_cases_by_day reordered_columns df_spain_cases_by_day
860	plt hist df_train plt xlabel plt ylabel "count" plt title
389	train_image_labels pd read_csv '../input/avito-images-recognized/train_image_labels.csv' index_col 'image_id' test_image_labels pd read_csv '../input/avito-images-recognized/test_image_labels.csv' index_col 'image_id' all_image_labels pd concat train_image_labels test_image_labels axis
568	original_fake_paths for dirname filenames in tqdm os walk '/kaggle/input/1-million-fake-faces/' for filename in filenames original_fake_paths append os path join dirname filename filename
372	def rle_encode im pixels im flatten order 'F' pixels np concatenate pixels runs np where pixels pixels runs runs return join str for in runs
689	try tpu tf distribute cluster_resolver TPUClusterResolver print tpu master except ValueError tpu None if tpu tf config experimental_connect_to_cluster tpu tf tpu experimental initialize_tpu_system tpu strategy tf distribute experimental TPUStrategy tpu else strategy tf distribute get_strategy print "REPLICAS: " strategy num_replicas_in_sync
836	plt figure figsize plt subplot plt title draw parsed df print patient_class loc df plt subplot plt title draw parsed df print patient_class loc df
332	positive_train train train "sentiment" "positive" negative_train train train "sentiment" "negative" neutral_train train train "sentiment" "neutral"
117	def fa beta fa beta return fa def fb beta gamma fb beta gamma return fb def fc gamma fc gamma return fc
503	from sklearn model_selection import train_test_split unique_img_ids masks groupby size reset_index name 'counts' train_ids valid_ids train_test_split unique_img_ids test_size stratify unique_img_ids 'counts' random_state train_df pd merge masks train_ids valid_df pd merge masks valid_ids print train_df shape 'training masks' print valid_df shape 'validation masks'
400	def id_to_filepath img_id img_dir TRAIN_DIR filepath f'{img_dir}/{img_id}.dcm' if os path exists filepath return filepath else return 'DNE'
662	leak_score leak_df pd read_pickle ucf_root 'site0.pkl' leak_df 'meter_reading' leak_df meter_reading_scraped leak_df drop 'meter_reading_original' 'meter_reading_scraped' axis inplace True leak_df fillna inplace True leak_df leak_df leak_df timestamp dt year leak_df loc leak_df meter_reading 'meter_reading' sample_submission loc sample_submission meter_reading 'meter_reading' for bid in leak_df building_id unique temp_df leak_df leak_df building_id bid for in temp_df meter unique v0 sample_submission loc test_df building_id bid test_df meter 'meter_reading' values v1 temp_df temp_df meter meter_reading values leak_score mean_squared_error np log1p v0 np log1p v1 len v0 sample_submission loc test_df building_id bid test_df meter 'meter_reading' temp_df temp_df meter meter_reading values
674	import matplotlib pyplot as plt def plotImages images_arr fig axes plt subplots figsize axes axes flatten for img ax in zip images_arr axes ax imshow img plt tight_layout plt show augmented_images train_generator for in range plotImages augmented_images
839	def evaluate program input_image np array input_image np array input_image assert type input_image np ndarray image_list input_image for fct in program image_list fct image_list image_list img for img in image_list if img shape and img shape if image_list return return image_list
312	model Sequential model add activation 'relu' input_shape train_iterator image_shape model add pool_size model add activation 'relu' model add pool_size model add Flatten model add Dense activation 'relu' model add Dropout model add Dense activation 'relu' model add Dropout model add Dense len classnames activation 'softmax' model compile loss 'categorical_crossentropy' optimizer metrics "accuracy" model summary
559	train_clean np log train_clean train_clean 'dist1' np log train_clean 'dist1' train_clean 'dist2' np log train_clean 'dist2' test_clean np log test_clean test_clean 'dist1' np log test_clean 'dist1' test_clean 'dist2' np log test_clean 'dist2'
233	road_encoding
796	confirmed_df pd read_csv death_df pd read_csv recovered_df pd read_csv confirmed_table confirmed_df melt id_vars var_name value_name fillna drop axis death_table death_df melt id_vars var_name value_name fillna drop axis recovered_table recovered_df melt id_vars var_name value_name fillna drop axis full_table confirmed_table merge death_table merge recovered_table full_table pd to_datetime full_table full_table
174	print 'ok'
242	import pandas as pd import numpy as np from sklearn model_selection import StratifiedKFold import lightgbm as lgb from sklearn import metrics import gc pd set_option 'display.max_columns'
609	def dice_coef y_true y_pred smooth y_true_f flatten y_true y_pred_f flatten y_pred intersection sum y_true_f y_pred_f return intersection smooth sum y_true_f sum y_pred_f smooth def dice_loss y_true y_pred smooth y_true_f flatten y_true y_pred_f flatten y_pred intersection y_true_f y_pred_f score sum intersection smooth sum y_true_f sum y_pred_f smooth return score def bce_dice_loss y_true y_pred return binary_crossentropy y_true y_pred dice_loss y_true y_pred
26	pneumonia_locations with open os path join '../input/stage_1_train_labels.csv' mode 'r' as infile reader csv reader infile next reader None for rows in reader filename rows location rows pneumonia rows if pneumonia location int float for in location if filename in pneumonia_locations pneumonia_locations filename append location else pneumonia_locations filename location
188	for gname in similar_cars _ids gb_year_make_model_trim1 get_group gname 'id' _trim2 gb_year_make_model_trim1 get_group gname 'trim2' _in_train gb_year_make_model_trim1 get_group gname 'in_train' _in_test gb_year_make_model_trim1 get_group gname 'in_test' plt figure figsize plt suptitle format gname min len _ids int np ceil len _ids for _id in enumerate _ids plt subplot plt title "{}\ntrain={}, test={}\n{}" format _trim2 _in_train _in_test _id image_type if _in_train else img get_image_data _id image_type plt imshow img
115	commits_df pd to_numeric commits_df commits_df 'best' commits_df loc commits_df idxmin 'best'
407	households_leader train groupby 'idhogar' 'parentesco1' sum households_no_head train loc train 'idhogar' isin households_leader households_leader index print format households_no_head 'idhogar' nunique
143	def plot_confusion_matrix cm classes normalize False title cmap plt cm Blues if normalize cm cm astype 'float' cm sum axis np newaxis print else print print cm plt imshow cm interpolation 'nearest' cmap cmap plt title title plt colorbar tick_marks np arange len classes plt xticks tick_marks classes rotation plt yticks tick_marks classes fmt '.2f' if normalize else 'd' thresh cm max for in itertools product range cm shape range cm shape plt text format cm fmt horizontalalignment "center" color "white" if cm thresh else "black" plt ylabel plt xlabel plt tight_layout
5	train 'outliers' train loc train 'target' 'outliers' train 'outliers' value_counts
44	print "item_id" print "item_id unique value counts:{}" format len train "item_id" unique print train "item_id" unique print "dept_id" print "dept_id unique value counts:{}" format len train "dept_id" unique print train "store_id" unique print "cat_id" print "cat_id unique value counts:{}" format len train "cat_id" unique print train "cat_id" unique print "state_id" print "state_id unique value counts:{}" format len train "state_id" unique print train "state_id" unique
42	train_df pd read_csv "/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv" calendar_df pd read_csv "/kaggle/input/m5-forecasting-accuracy/calendar.csv" price_df pd read_csv "/kaggle/input/m5-forecasting-accuracy/sell_prices.csv" sample pd read_csv "/kaggle/input/m5-forecasting-accuracy/sample_submission.csv"
489	def agg_numeric df group_var df_name for col in df if col group_var and 'SK_ID' in col df df drop columns col group_ids df group_var numeric_df df select_dtypes 'number' numeric_df group_var group_ids agg numeric_df groupby group_var agg 'count' 'mean' 'max' 'min' 'sum' reset_index columns group_var for var in agg columns levels if var group_var for stat in agg columns levels columns append '%s_%s_%s' df_name var stat agg columns columns return agg
284	fig ax1 ax2 plt subplots ncols fig set_size_inches interestGroupedData pd DataFrame data groupby "interest_level" "price" mean reset_index interestGroupedSortedData interestGroupedData sort_values by "price" ascending False sn barplot data interestGroupedSortedData "interest_level" "price" ax ax1 orient "v" ax1 set xlabel ylabel title interestData pd DataFrame data interest_level value_counts interestData "interest_level_original" interestData index sn barplot data interestData "interest_level_original" "interest_level" ax ax2 orient "v" ax2 set xlabel ylabel title
187	for gname in similar_cars _ids test_gb_year_make_model_trim1 get_group gname 'id' _trim2 test_gb_year_make_model_trim1 get_group gname 'trim2' plt figure figsize plt suptitle format gname min len _ids int np ceil len _ids for _id in enumerate _ids plt subplot plt title format _trim2 img get_image_data _id plt imshow img
267	def convert_to_grayscale img base_range np amax img np amin img rescaled_range img_rescaled img np amin img rescaled_range base_range return np uint8 img_rescaled
868	train_df feature_matrix_enc feature_matrix_enc 'TARGET' notnull copy test_df feature_matrix_enc feature_matrix_enc 'TARGET' isnull copy test_df drop 'TARGET' axis inplace True del feature_matrix feature_defs feature_matrix_enc gc collect
180	linear_svr LinearSVR linear_svr fit train target acc_model linear_svr train test
716	use_cols col for col in train columns if col not in 'card_id' 'first_active_month' train train use_cols test test use_cols features list train use_cols columns categorical_feats col for col in features if 'feature_' in col
401	def show_examples subtype 'epidural' df train_new df_new df set_index 'ID' filt df_new subtype df_new df_new filt fig axes plt subplots figsize for in range idx df_new index pixels load_one_image idx df_new axes imshow pixels
572	batch_size num_classes epochs val_split save_dir os path join os getcwd 'models' model_name 'keras_cnn_model.h5'
437	model n_jobs model fit features y_train evaluate model features y_train y_valid
90	mean_price_2 pd DataFrame group price mean mean_price_2 reset_index level inplace True plt figure figsize sns kdeplot mean_price_2 price shade True plt title fontsize plt xlabel fontsize
151	df_train df_val train_test_split df_data test_size random_state print df_train shape print df_val shape
98	train 'no_descrip' train loc train item_description 'no_descrip' str round train 'no_descrip' value_counts normalize True iloc print 'of the items have no a description.'
234	directions 'N' 'NE' 'E' 'SE' 'S' 'SW' 'W' 'NW'
853	def get_magic_features dict for in range 'var_{}' format np str train pd read_csv INPUT_PATH 'train.csv' dtype test pd read_csv INPUT_PATH 'test.csv' dtype real_ids get_real_test_data test test test isin real_ids print len test features sorted list keys print train shape test shape table pd concat train features test features axis print table shape feat_to_store for in features print format new_feat dict pd value_counts table for el in table values new_feat append el table '_counts_sum' new_feat feat_to_store append '_counts_sum' train table feat_to_store test table feat_to_store train to_csv FEATURES_PATH 'counts_of_values_train.csv' index False test to_csv FEATURES_PATH 'counts_of_values_test.csv' index False return train test
459	installments pd read_csv '../input/installments_payments.csv' replace np nan installments convert_types installments installments 'LATE' installments 'DAYS_ENTRY_PAYMENT' installments 'DAYS_INSTALMENT' installments 'LOW_PAYMENT' installments 'AMT_PAYMENT' installments 'AMT_INSTALMENT'
288	fig ax1 plt subplots fig set_size_inches ax1 scatter data data 'interest_level' "low" 'bedrooms' data data 'interest_level' "low" 'bathrooms' 'green' ax1 scatter data data 'interest_level' "medium" 'bedrooms' data data 'interest_level' "medium" 'bathrooms' 'red' ax1 scatter data data 'interest_level' "high" 'bedrooms' data data 'interest_level' "high" 'bathrooms' 'blue' ax1 set_xlabel ax1 set_ylabel ax1 legend scatterpoints loc 'upper right' fontsize
216	clf OneVsRestClassifier SGDClassifier loss 'log' alpha penalty 'l2' clf fit y_train y_pred clf predict
471	feature_matrix_spec feature_names_spec ft dfs entityset es target_entity 'app' agg_primitives 'sum' 'count' 'min' 'max' 'mean' 'mode' max_depth features_only False verbose True
58	filenames os listdir "../input/train/train" categories for filename in filenames category filename split if category 'dog' categories append else categories append df pd DataFrame 'filename' filenames 'category' categories
857	def display_imgs columns bs shape rows min bs fig plt figure figsize columns rows for in range rows for in range columns idx columns fig add_subplot rows columns idx plt axis 'off' plt imshow idx astype np int plt show display_imgs np asarray md trn_ds denorm
281	productsCountFirst orderProductsTrain orderProductsTrain "add_to_cart_order" "product_id" value_counts to_frame productsCountFirst "reordered_count" productsCountFirst product_id productsCountFirst "product_id" productsCountFirst index productCountFirstMerged pd merge productsCount productsCountFirst how "left" on "product_id" sort_values by "count" ascending False productCountFirstMerged "first_ordered_ratio" productCountFirstMerged "reordered_count" productCountFirstMerged "count" productCountFirstMerged sort_values by "first_ordered_ratio" ascending False inplace True firstMerged pd merge productCountFirstMerged products how "left" on "product_id" fig ax plt subplots fig set_size_inches sn barplot data firstMerged firstMerged "count" head "product_name" "first_ordered_ratio" color Count ",title=" Top Reordered Products ax set_ylim plt xticks rotation firstMerged head
627	mybest pd read_csv '/kaggle/input/mybest/sub9523.csv' np array test p1 values test p2 values test p3 values test p4 values test p5 values mybest toxic values X_T y_T y_val train_test_split test_size model LinearRegression model fit prds model predict score1 roc_auc_score y_val round astype int prds score2 roc_auc_score prds round astype int y_val print score1 score2 prds model predict score1 roc_auc_score round astype int prds score2 roc_auc_score prds round astype int print score1 score2 test 'prd' prds
189	DATA_DIR r'../input' TEST_DIR r'../input/test' print 'ok'
501	cash pd read_csv cash convert_types cash print_info True cash head
832	train_csv pd read_csv '../input/train/train.csv' low_memory False test_csv pd read_csv '../input/test/test.csv' low_memory False def preprocess csv csv len str tt for tt in csv csv len str tt for tt in csv return csv train_csv preprocess train_csv test_csv preprocess test_csv
350	public_df test query "seq_length == 107" copy private_df test query "seq_length == 130" copy public_inputs public_adj preprocess_inputs public_df private_inputs private_adj preprocess_inputs private_df public_inputs torch tensor public_inputs dtype torch long private_inputs torch tensor private_inputs dtype torch long public_adj torch tensor public_adj dtype torch long private_adj torch tensor private_adj dtype torch long
762	train data val data train_label np float32 train label val_label np float32 val label train_image np float32 train train columns val_image np float32 val val columns test_image np float32 test_data test_data columns print 'train shape: %s' str train shape print 'val shape: %s' str val shape print 'train_label shape: %s' str train_label shape print 'val_label shape: %s' str val_label shape print 'train_image shape: %s' str train_image shape print 'val_image shape: %s' str val_image shape print 'test_image shape: %s' str test_image shape
383	nom_cols f'nom_{i}' for in range fig ax plt subplots figsize for col in enumerate nom_cols plt subplot sns countplot raw_train col plt show
552	FILENAME train_root train_df fname NORMALIZE True sample_mel processor createMel FILENAME CONFIG normalize NORMALIZE sample_mfcc processor createMfcc FILENAME CONFIG normalize NORMALIZE print sample_mel shape print sample_mfcc shape idx_cut plt imshow sample_mel idx_cut cmap plt title plt show plt imshow sample_mfcc idx_cut cmap plt title 'MFCC:' plt show print np min sample_mel np max sample_mel print np min sample_mfcc np max sample_mfcc
193	yt val_datagen __getitem__ print shape print shape print 'test y: ' yt shape fig axes plt subplots figsize nrows BATCH_SIZE ncols SEQ_LEN for in range BATCH_SIZE for in range SEQ_LEN axes imshow axes axis 'off' axes set_title yt plt show print yt
225	train 'square_feet' np log1p train 'square_feet' test 'square_feet' np log1p test 'square_feet' bold distplot train 'square_feet' 'darkgreen'
561	ren AddActor cylinderActor ren SetBackground colors ren ResetCamera ren GetActiveCamera Zoom
229	import warnings as wrn wrn filterwarnings 'ignore' category DeprecationWarning wrn filterwarnings 'ignore' category FutureWarning wrn filterwarnings 'ignore' category UserWarning import pandas as pd import numpy as np from scipy import stats import matplotlib pyplot as plt import seaborn as sns sns set_style "whitegrid" import plotly offline as py from plotly offline import iplot init_notebook_mode import plotly graph_objs as go init_notebook_mode connected True from IPython display import Markdown def bold string display Markdown string
610	BATCH_SIZE train_idx val_idx train_test_split non_missing_train_idx index random_state test_size train_generator DataGenerator train_idx reshape df mask_count_df target_df train_df augment True batch_size BATCH_SIZE n_classes val_generator DataGenerator val_idx reshape df mask_count_df target_df train_df augment False batch_size BATCH_SIZE n_classes
25	preds learn get_preds ds_type DatasetType Test preds np argmax preds numpy axis categories sorted train genres unique astype 'str' final_preds for idx in preds final_preds append categories idx final_submit pd read_csv '../input/clabscvcomp/data/sample_submission.csv' final_submit genres final_preds final_submit head final_submit to_csv 'submission.csv' index False
822	fig plt figure figsize ax fig add_subplot xy cities loc order 'X' 'Y' values poly plt Polygon xy fc 'black' ax add_patch poly plt axis 'equal' plt gca set_axis_off plt subplots_adjust top bottom right left hspace wspace plt margins plt gca xaxis set_major_locator plt NullLocator plt gca yaxis set_major_locator plt NullLocator plt savefig 'mask.png' bbox_inches 'tight' pad_inches dpi
84	total_before_opti sum df memory_usage def conversion var if df var dtype object maxi df var max if maxi df var df var astype np uint8 print var "converted to uint8" elif maxi df var df var astype np uint16 print var "converted to uint16" elif maxi df var df var astype np uint32 print var "converted to uint32" else df var df var astype np uint64 print var "converted to uint64"
211	model CatBoostRegressor iterations task_type 'GPU' verbose loss_function 'RMSE' boosting_type depth model fit train_pool eval_set val_pool plot True del train_pool val_pool gc collect
756	from sklearn metrics import mean_squared_error watchlist dtrain 'train' num_round bst xgb train dict xgb_params silent dtrain num_boost_round num_round preds bst predict dtest err mean_squared_error test target values preds print 'MSE ={}' format err
856	sns set style 'darkgrid' sns_plot sns palplot sns color_palette sns_plot sns palplot sns color_palette sns_plot sns palplot sns color_palette sns_plot sns palplot sns color_palette sns_plot sns palplot sns color_palette
721	model eval with torch no_grad preds np empty for in tqdm_notebook tloader to device output model idx output max dim cpu numpy preds np append preds idx axis
94	brands pd DataFrame train brand_name value_counts brands reset_index level inplace True brands brands sort_values by 'brand_name' ascending False head brands columns 'brand_name' 'number_of_item' group train groupby train brand_name brands_prices pd DataFrame group price mean brands_prices reset_index level inplace True brands pd merge brands brands_prices how 'left' on 'brand_name' labels label for label in zip brands 'brand_name' brands 'number_of_item' brands 'price' plt figure figsize plt rc 'font' size squarify plot sizes brands 'number_of_item' label labels alpha color colors plt title fontsize plt axis 'off'
101	plt figure figsize sns regplot 'coms_length' 'price' data train scatter_kws 's' plt title fontsize plt xlabel fontsize plt ylabel fontsize
45	train iloc train iloc lag_featrues iloc y_train train iloc lag_featrues iloc y_test train iloc lgbm lgb LGBMRegressor learning_rate max_depth param_grid 'learning_rate' learning_rate 'max_depth' max_depth cv_lgbm GridSearchCV lgbm param_grid cv n_jobs cv_lgbm fit y_train print format cv_lgbm best_params_ best_lg cv_lgbm best_estimator_ y_train_pred_lg best_lg predict y_test_pred_lg best_lg predict print format mean_squared_error y_train y_train_pred_lg print format mean_squared_error y_test y_test_pred_lg print format r2_score y_train y_train_pred_lg print format r2_score y_test y_test_pred_lg
556	Parallel n_jobs verbose delayed processor prepareSample test_root sample_submission iloc processor createMel CONFIG TRAINING_CONFIG test_mode True proc_mode 'resize' for in range np array print shape
18	train pd read_csv filepath_or_buffer '../input/train.csv' index_col 'id' parse_dates 'pickup_datetime' 'dropoff_datetime' infer_datetime_format True test pd read_csv filepath_or_buffer '../input/test.csv' index_col 'id' parse_dates 'pickup_datetime' infer_datetime_format True
690	def get_model with strategy scope model tf keras Sequential efn input_shape IMAGE_SIZE weights 'imagenet' include_top False Dense activation 'sigmoid' model compile optimizer 'adam' loss 'binary_crossentropy' metrics tf keras metrics AUC return model
742	def get_training_dataset_raw dataset load_dataset TRAINING_FILENAMES labeled True ordered False return dataset raw_training_dataset get_training_dataset_raw label_counter Counter for images labels in raw_training_dataset label_counter update labels numpy del raw_training_dataset label_counting_sorted label_counter most_common NUM_TRAINING_IMAGES sum for in label_counting_sorted print "number of examples in the original training dataset: {}" format NUM_TRAINING_IMAGES print "labels in the original training dataset, sorted by occurrence" label_counting_sorted
293	from sklearn import model_selection preprocessing import xgboost as xgb import warnings warnings filterwarnings "ignore" mergedFilterd merged fillna for in mergedFilterd columns if mergedFilterd dtype 'object' lbl preprocessing LabelEncoder lbl fit list mergedFilterd values mergedFilterd lbl transform list mergedFilterd values train_y mergedFilterd logerror values train_X mergedFilterd drop "parcelid" "transactiondate" "logerror" axis xgb_params 'eta' 'max_depth' 'subsample' 'colsample_bytree' 'objective' 'reg:linear' 'eval_metric' 'rmse' 'silent' dtrain xgb DMatrix train_X train_y feature_names train_X columns values model xgb train dict xgb_params silent dtrain num_boost_round
338	import numpy as np import pandas as pd import seaborn as sns import matplotlib as plt import tensorflow as tf from tensorflow keras preprocessing import text sequence from tensorflow keras models import Sequential from tensorflow keras layers import Dense Dropout Activation from tensorflow keras layers import Embedding from tensorflow keras layers import from sklearn model_selection import train_test_split print tf __version__
69	import torch torchvision print torch __version__ torch cuda is_available import mmdet print mmdet __version__ from mmcv ops import get_compiling_cuda_version get_compiler_version print get_compiling_cuda_version print get_compiler_version
223	bold '**READINGS REALLY PEAKED FROM MAY TO OCTOBER**' plt rcParams 'figure.figsize' temp_df train groupby 'timestamp' 'month' meter_reading sum reset_index ax sns lineplot data temp_df 'timestamp' 'meter_reading' color 'teal' plt xlabel fontsize plt ylabel plt show
317	corr train ALL_FEATURES corr 'spearman' columns np full corr shape True dtype bool for in range corr shape for in range corr shape if corr iloc if columns columns False selected_columns train ALL_FEATURES columns columns print len selected_columns
106	def plot_3d image threshold image transpose verts faces measure marching_cubes threshold fig plt figure figsize ax fig add_subplot projection '3d' mesh verts faces alpha face_color mesh set_facecolor face_color ax add_collection3d mesh ax set_xlim shape ax set_ylim shape ax set_zlim shape plt show
136	df_data pd read_csv '../input/train_labels.csv' df_data df_data 'id' 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2' df_data df_data 'id' '9369c7278ec8bcc6c880d99194de09fc2bd4efbe' print df_data shape
50	def clean_special_chars text for in specail_signs text text replace specail_signs for in punct text text replace f' {p} ' return text
583	train1 pd read_csv "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv" train2 pd read_csv "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv" train2 toxic train2 toxic round astype int valid pd read_csv '/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv' test pd read_csv '/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv' sub pd read_csv '/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv'
534	train_months DateAvSigVersion apply lambda format year month test_months DateAvSigVersion apply lambda format year month df_months pd DataFrame train_months value_counts reset_index df_months df_months merge pd DataFrame test_months value_counts reset_index how 'left' on 'index' df_months sort_values 'index'
486	feature_matrix feature_names ft dfs entityset es target_entity 'app_train' agg_primitives 'mean' 'max' 'min' 'trend' 'mode' 'count' 'sum' 'percent_true' NormalizedModeCount MostRecent LongestSeq trans_primitives 'diff' 'cum_sum' 'cum_mean' 'percentile' where_primitives 'mean' 'sum' seed_features late_payment past_due max_depth features_only False verbose True chunk_size len app_train ignore_entities 'app_test'
677	fig ax plt subplots figsize sorted_train_df groupby 'date' 'var_91' count plot ax ax label "train" sorted_test_df groupby 'date' 'var_91' count plot ax ax label "test" ax legend
27	tf_cities pd read_csv "../input/traveling-santa-2018-prime-paths/cities.csv" tf_cities tf_cities CityId apply isprime tf_cities np invert tf_cities astype float tf_path_df tf_cities reindex initial_path reset_index tf_input_p tf_path_df isNotPrime tf_input_x tf_path_df tf_input_y tf_path_df gpu_cost compute_cost_by_gpu len initial_path print str gpu_cost compute_cost tf_input_p tf_input_x tf_input_y
669	df np zeros df shape df np zeros df shape df np zeros df shape
297	fig ax plt subplots fig set_size_inches sn boxplot "bathroomcnt" "logerror" data mergedFiltered ax ax color Bathroom Count ",title=" Bathroom Count Vs Log Error
10	vect_word TfidfVectorizer max_features lowercase True analyzer 'word' stop_words 'english' ngram_range dtype np float32 vect_char TfidfVectorizer max_features lowercase True analyzer 'char' stop_words 'english' ngram_range dtype np float32
597	def decode_image filename label None image_size bits tf io read_file filename image tf image decode_jpeg bits channels image tf cast image tf float32 image tf image resize image image_size if label is None return image else return image label def data_augment image label None image tf image random_flip_left_right image image tf image random_flip_up_down image if label is None return image else return image label
780	temp_col 'CREDIT_DAY_OVERDUE' fig ax plt subplots figsize sns kdeplot application_train loc application_train 'TARGET' temp_col dropna label 'repay(0)' color 'r' ax ax sns kdeplot application_train loc application_train 'TARGET' temp_col dropna label 'not repay(1)' color 'b' ax ax ax set_title format temp_col sns kdeplot np log application_train loc application_train 'TARGET' temp_col dropna label 'repay(0)' color 'r' ax ax sns kdeplot np log application_train loc application_train 'TARGET' temp_col dropna label 'not repay(1)' color 'b' ax ax ax set_title format temp_col plt show
371	from pathlib import Path if Path previous_model_name is_file print model2 load_model previous_model_name custom_objects 'my_iou_metric_2' my_iou_metric 'lovasz_loss' lovasz_loss 'my_iou_metric' my_iou_metric else print model2 load_model stored_trained_model custom_objects 'my_iou_metric_2' my_iou_metric 'lovasz_loss' lovasz_loss 'my_iou_metric' my_iou_metric
263	PARENT_DATA_DIR_PATH '../input' METADATA_TRAIN_FILE_PATH os path join PARENT_DATA_DIR_PATH "metadata_train.csv" TRAIN_DATA_FILE_PATH os path join PARENT_DATA_DIR_PATH "train.parquet"
665	def change addr if addr return elif addr return elif addr np nan return np nan else return df df "addr2" map change
504	model UNet model_path 'model_1.pt' state torch load str model_path state key replace 'module.' value for key value in state 'model' items model load_state_dict state if torch cuda is_available model cuda model eval
129	MAX_LEN PATH '../input/tf-roberta/' tokenizer tokenizers ByteLevelBPETokenizer vocab_file PATH 'vocab-roberta-base.json' merges_file PATH 'merges-roberta-base.txt' lowercase True add_prefix_space True EPOCHS BATCH_SIZE PAD_ID SEED LABEL_SMOOTHING tf random set_seed SEED np random seed SEED sentiment_id 'positive' 'negative' 'neutral' train pd read_csv '../input/tweet-sentiment-extraction/train.csv' fillna train head
57	cat_features 'bin_0' 'bin_1' 'bin_2' 'bin_3' 'bin_4' 'nom_5' 'nom_6' 'nom_7' 'nom_8' 'nom_9' 'ord_0' 'ord_1' 'ord_2' 'ord_3' 'ord_4' 'ord_5_1' 'ord_5_2' 'nan_features' 'day_0' 'day_1' 'day_2' 'day_3' 'day_4' 'day_5' 'day_6' 'day_7' 'month_0' 'month_1' 'month_2' 'month_3' 'month_4' 'month_5' 'month_6' 'month_7' 'month_8' 'month_9' 'month_10' 'month_11' 'month_12' 'nom_0_0' 'nom_0_1' 'nom_0_2' 'nom_0_3' 'nom_1_0' 'nom_1_1' 'nom_1_2' 'nom_1_3' 'nom_1_4' 'nom_1_5' 'nom_1_6' 'nom_2_0' 'nom_2_1' 'nom_2_2' 'nom_2_3' 'nom_2_4' 'nom_2_5' 'nom_2_6' 'nom_3_0' 'nom_3_1' 'nom_3_2' 'nom_3_3' 'nom_3_4' 'nom_3_5' 'nom_3_6' 'nom_4_0' 'nom_4_1' 'nom_4_2' 'nom_4_3' 'nom_4_4'
265	reducedtarget0sampleDF pd DataFrame for col in range target0sampledata shape tmp_pdSeries reduce_sample target0sampledata iloc col reducedtarget0sampleDF str col tmp_pdSeries reducedtarget0sampleDF shape
21	from fastai import from fastai vision import from sklearn metrics import f1_score
467	for hyper in enumerate random_hyp columns if hyper not in 'boosting_type' 'iteration' 'subsample' 'score' 'learning_rate' 'is_unbalance' 'metric' 'verbose' 'iteration' 'n_estimators' 'search' plt figure figsize if hyper 'loss' sns kdeplot param_grid hyper label linewidth sns kdeplot random_hyp hyper label linewidth plt vlines best_random_hyp hyper ymin ymax linestyles linewidth colors 'orange' plt legend loc plt title format hyper plt xlabel format hyper plt ylabel plt show
455	import gc def agg_child df parent_var df_name df_agg agg_numeric df parent_var df_name df_agg_cat agg_categorical df parent_var df_name df_info df_agg merge df_agg_cat on parent_var how 'outer' idx np unique df_info axis return_index True df_info df_info iloc idx gc enable del df_agg df_agg_cat gc collect return df_info
450	cols_with_id for in train columns if 'SK_ID_CURR' in cols_with_bureau_id for in train columns if 'SK_ID_BUREAU' in cols_with_previous_id for in train columns if 'SK_ID_PREV' in print len cols_with_id print len cols_with_bureau_id print len cols_with_previous_id train train drop columns cols_with_id test test drop columns cols_with_id print train shape print test shape
96	exp train train 'price' exp name exp name str upper wc WordCloud background_color "white" max_words stopwords STOPWORDS max_font_size wc generate join str for in exp name values plt figure figsize plt title fontsize plt axis 'off' plt imshow wc interpolation 'bilinear'
875	all_words train 'text' str split expand True unstack value_counts data go Bar all_words index values all_words values marker dict colorscale color all_words values text layout go Layout title fig go Figure data data layout layout py iplot fig filename 'basic-bar'
837	import numpy as np import pandas as pd import itertools import random import os import json from pathlib import Path import matplotlib pyplot as plt from matplotlib import colors data_path Path '/kaggle/input/abstraction-and-reasoning-challenge/' training_path data_path 'training' training_tasks sorted os listdir training_path
737	bert_tokenizer bert_nq get_pretrained_model FLAGS model_name if not IS_KAGGLE bert_nq trainable_variables
163	test_gen test_generator df_test test_batch_size num_rows num_cols model load_weights filepath 'model.h5' predictions model predict_generator test_gen steps num_test_batches max_queue_size workers use_multiprocessing False verbose
140	train_path 'base_dir/train_dir' valid_path 'base_dir/val_dir' test_path '../input/test' num_train_samples len df_train num_val_samples len df_val train_batch_size val_batch_size train_steps np ceil num_train_samples train_batch_size val_steps np ceil num_val_samples val_batch_size
48	fig px line train_df 'FVC' line_group color title fig update_traces mode 'lines+markers'
570	real_dir '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/' eval_partition pd read_csv '/kaggle/input/celeba-dataset/list_eval_partition.csv' eval_partition 'filename' eval_partition image_id apply lambda st real_dir st eval_partition 'class' 'REAL'
482	app_types for col in app_train if app_train col dtype 'object' and len app_train col unique app_types col ft variable_types Boolean print len app_types
38	from six moves import cPickle as pickle import bz2 def loadPickleBZ pickle_file with bz2 pickle_file 'r' as loadedData pickle load return loadedData def savePickleBZ pickle_file data with bz2 pickle_file 'w' as pickle dump data pickle HIGHEST_PROTOCOL return
445	train pd read_csv '../input/home-credit-simple-featuers/simple_features_train.csv' test pd read_csv '../input/home-credit-simple-featuers/simple_features_test.csv' test_ids test 'SK_ID_CURR' train_labels np array train 'TARGET' astype np int32 reshape train train drop columns 'SK_ID_CURR' 'TARGET' test test drop columns 'SK_ID_CURR' print train shape print test shape
544	plt rcParams 'figure.figsize' y_tr_temp tr_datagen __getitem__ y_valid_temp valid_datagen __getitem__ fig ax plt subplots ax imshow ax set_title 'train:' ax imshow ax set_title 'valid:'
141	import matplotlib pyplot as plt acc history history 'acc' val_acc history history 'val_acc' loss history history 'loss' val_loss history history 'val_loss' epochs range len acc plt plot epochs loss 'bo' label plt plot epochs val_loss 'b' label plt title plt legend plt figure plt plot epochs acc 'bo' label plt plot epochs val_acc 'b' label plt title plt legend plt figure
456	def agg_grandchild df parent_df parent_var grandparent_var df_name parent_df parent_df parent_var grandparent_var copy set_index parent_var df_agg agg_numeric df parent_var df_name df_agg df_agg merge parent_df on parent_var how 'left' df_agg_client agg_numeric df_agg grandparent_var df_name if any df dtypes 'category' df_agg_cat agg_categorical df parent_var df_name df_agg_cat df_agg_cat merge parent_df on parent_var how 'left' df_agg_cat_client agg_numeric df_agg_cat grandparent_var df_name df_info df_agg_client merge df_agg_cat_client on grandparent_var how 'outer' gc enable del df_agg df_agg_client df_agg_cat df_agg_cat_client gc collect else df_info df_agg_client copy gc enable del df_agg df_agg_client gc collect idx np unique df_info axis return_index True df_info df_info iloc idx return df_info
286	fig ax1 ax2 plt subplots nrows fig set_size_inches sn countplot "bedrooms" data data ax ax1 data1 data groupby 'bedrooms' 'interest_level' 'bedrooms' count unstack 'interest_level' fillna data1 'low' 'medium' "high" plot kind 'bar' stacked True ax ax2
727	fig axes plt subplots nrows ncols figsize plt subplots_adjust wspace hspace fig_row for col_id in range ax_id col_id fig_label train columns col_id feat train columns col_id fig_col col_id countplot sns countplot 'sexo' data train train feat train 'sexo' ax axes fig_row fig_col countplot set xlabel fig_label if fig_col fig_row
876	text list train text values tf_vectorizer LemmaCountVectorizer max_df min_df stop_words 'english' decode_error 'ignore' tf tf_vectorizer fit_transform text print tf_vectorizer get_feature_names
558	print "% of train_transaction data missing = " train_transaction train_transaction columns isnull sum sum np product train_transaction shape print "% of train_identity data missing = " train_identity train_identity columns isnull sum sum np product train_identity shape print "% of test_transaction data missing = " test_transaction test_transaction columns isnull sum sum np product test_transaction shape print "% of test_identity data missing = " test_identity test_identity columns isnull sum sum np product test_identity shape
555	output Parallel n_jobs verbose delayed processor prepareSample train_root train_df iloc processor createMel CONFIG TRAINING_CONFIG test_mode False proc_mode 'resize' for in range np array for in output y_train np array for in output y_train pd Series y_train str get_dummies sep print shape y_train shape
39	import matplotlib pyplot as plt savePickleBZ 'before.pbz' before savePickleBZ 'sets.pbz' sets def showBefore before before np array before dtype np float before before before np transpose np copy before 1e-30 before before np array before dtype np uint8 plt figure figsize plt imshow before showBefore before
753	from sklearn base import TransformerMixin class DataFrameImputer TransformerMixin def fit self None self fill pd Series value_counts index if dtype np dtype 'O' else median for in index columns return self def transform self None return fillna self fill x_train DataFrameImputer fit_transform x_train
359	confirmed pd read_csv sort_values by deaths pd read_csv recovered pd read_csv
310	mask_dir df df id imid masks values masks os listdir mask_dir masks
305	def auc y_true y_pred ptas tf stack binary_PTA y_true y_pred for in np linspace axis pfas tf stack binary_PFA y_true y_pred for in np linspace axis pfas tf concat tf ones pfas axis binSizes pfas pfas ptas binSizes return sum axis def binary_PFA y_true y_pred threshold variable value y_pred cast y_pred threshold 'float32' sum y_true FP sum y_pred y_pred y_true return FP def binary_PTA y_true y_pred threshold variable value y_pred cast y_pred threshold 'float32' sum y_true TP sum y_pred y_true return TP
291	def _resnext block layers pretrained progress kwargs return ResNet block layers kwargs def resnext50_32x4d_swsl progress True kwargs kwargs 'groups' kwargs 'width_per_group' return _resnext Bottleneck True progress kwargs def resnext101_32x4d_swsl progress True kwargs kwargs 'groups' kwargs 'width_per_group' return _resnext Bottleneck True progress kwargs
318	from keras losses import binary_crossentropy import keras backend as import tensorflow as tf def dice_coeff_L y_true y_pred smooth y_pred_sig tf nn sigmoid y_pred y_true_f flatten y_true y_pred_f flatten y_pred_sig intersection sum y_true_f y_pred_f score intersection smooth sum y_true_f sum y_pred_f smooth return score def dice_coeff y_true y_pred smooth y_true_f flatten y_true y_pred_f flatten y_pred intersection sum y_true_f y_pred_f score intersection smooth sum y_true_f sum y_pred_f smooth return score def dice_loss y_true y_pred loss dice_coeff y_true y_pred return loss def bce_dice_loss y_true y_pred loss binary_crossentropy y_true y_pred dice_loss y_true y_pred return loss
648	zone_dict def set_localtime df for sid zone in zone_dict items sids df site_id sid df loc sids 'timestamp' df sids timestamp pd offsets Hour zone
442	bayes_results pd read_csv '../input/home-credit-model-tuning/bayesian_trials_1000.csv' sort_values 'score' ascending False reset_index random_results pd read_csv '../input/home-credit-model-tuning/random_search_trials_1000.csv' sort_values 'score' ascending False reset_index random_results 'loss' random_results 'score' bayes_params evaluate bayes_results name random_params evaluate random_results name 'random'
453	def agg_numeric df parent_var df_name for col in df if col parent_var and 'SK_ID' in col df df drop columns col parent_ids df parent_var copy numeric_df df select_dtypes 'number' copy numeric_df parent_var parent_ids agg numeric_df groupby parent_var agg 'count' 'mean' 'max' 'min' 'sum' columns for var in agg columns levels if var parent_var for stat in agg columns levels columns append '%s_%s_%s' df_name var stat agg columns columns idx np unique agg axis return_index True agg agg iloc idx return agg
880	plt plot history 'loss' plt plot history 'val_loss' plt title 'model loss' plt ylabel 'loss' plt xlabel 'epoch' plt legend 'train' 'test' loc 'upper right'
218	bold display building head bold display weather_train head bold display weather_test head bold display train head bold display test head
142	from sklearn metrics import roc_auc_score roc_auc_score y_true y_pred
730	bert_tokenizer bert_nq get_pretrained_model FLAGS model_name if not IS_KAGGLE bert_nq trainable_variables
414	range_ lambda max min range_ __name__ 'range_' ind_agg ind drop columns groupby 'idhogar' agg 'min' 'max' 'sum' 'count' 'std' range_ ind_agg head
785	import missingno as msno train_null train train_null train_null replace np NaN msno matrix df train_null iloc figsize color
333	positive_train 'temp_list' positive_train 'selected_text' apply lambda str split positive_train 'temp_list' positive_train 'temp_list' apply lambda remove_stopword positive_top Counter item for sublist in positive_train 'temp_list' for item in sublist positive_temp pd DataFrame positive_top most_common positive_temp columns 'count' positive_temp style background_gradient cmap
761	plt figure figsize sns countplot submission "diagnosis" plt title plt show
717	data_dir '../input/alaska2-image-steganalysis' folder_names 'JUNIWARD/' 'UERD/' class_names 'JUNIWARD_75' 'JUNIWARD_90' 'JUNIWARD_95' 'UERD_75' 'UERD_90' 'UERD_95' class_labels name for name in enumerate class_names
201	from sklearn metrics import confusion_matrix confusion confusion_matrix yt yt_pred print confusion
709	look_back trainX trainY create_dataset look_back testX testY create_dataset look_back
3	nulls np sum train isnull nullcols nulls loc nulls dtypes train dtypes dtypes2 dtypes loc nulls info pd concat nullcols dtypes2 axis sort_values by ascending False
633	fig axs plt subplots figsize axs flatten sample train train sample iloc for err_col in enumerate err_cols axs plot sample err_col color 'red' drawstyle 'steps-mid' axs set_title err_col
412	corr_matrix ind corr upper corr_matrix where np triu np ones corr_matrix shape astype np bool to_drop column for column in upper columns if any abs upper column to_drop
510	train 'len' train 'comment_text' str len print train 'len' mean print train 'len' quantile print '90th percentile comment length: %d' train 'len' quantile
77	data_to_plot2 pd DataFrame reset_index data_to_plot2 data_to_plot2 loc data_to_plot2 'is_attributed' data_to_plot2 loc data_to_plot2 'is_attributed' data_to_plot2 loc data_to_plot2 'is_attributed' plt figure figsize data_to_plot2 value_counts plot kind 'pie' autopct '%1.0f%%' plt title fontsize plt ytitle
562	plt figure figsize dir import pydicom as dcm plt imshow dcm dcmread dir os listdir dir pixel_array
741	input_layer tf keras layers InputLayer input_shape IMAGE_SIZE IMAGE_SIZE name 'input_layer' data_augmentation_layer with strategy scope model tf keras Sequential input_layer data_augmentation_layer
421	plt figure figsize sns countplot label 'surface' order label surface value_counts index plt show
165	ID df_preds preds df_preds submission pd DataFrame ID preds set_index submission to_csv 'pneu_keras_model.csv' columns
235	bold display df_train head bold display df_test head
475	random 'set' 'random' scores random 'score' 'iteration' 'set' opt 'set' 'opt' scores scores append opt 'set' 'iteration' 'score' sort True scores head
466	bars alt Chart random_hyp width mark_bar encode 'boosting_type' alt 'count()' scale alt Scale domain bars title text bars mark_text align 'center' baseline 'bottom' size encode text 'count()' bars text
224	bold '**MANUFACTURING REALLY BUCKED THE GENERAL TREND**' temp_df train groupby 'timestamp' "primary_use" meter_reading sum reset_index ax sns FacetGrid temp_df col "primary_use" col_wrap height aspect sharey False ax map sns lineplot 'timestamp' 'meter_reading' color "teal" plt subplots_adjust hspace plt show
78	ip_level pd merge data_to_plot2 on 'ip' cross_tab pd crosstab ip_level ip_level 'clicker_type' normalize 'columns' cross_tab index pd CategoricalIndex cross_tab index categories cross_tab cross_tab sort_index ascending False cross_tab cross_tab 'huge_clicker' 'big_clicker' 'little_clicker' 'very_little_clicker' plt figure figsize plt title fontsize sns heatmap cross_tab annot True fmt plt xlabel fontsize plt ylabel fontsize del data_to_plot2 gc collect
392	hits_sample hits sample sns pairplot hits_sample hue 'volume_id' size plt show
873	import numpy as np import pandas as pd import matplotlib pyplot as plt import os import datetime import warnings warnings filterwarnings "ignore" import seaborn as sns import scipy
723	start datetime datetime now for in range n_iter batch_mixup images labels PROBABILITY end datetime datetime now timing end start total_seconds n_iter print f"batch_mixup: {timing}"
315	inv_map for in train_iterator class_indices items print inv_map classes np argmax preds axis probes np max preds axis print classes print probes unique_elements counts_elements np unique classes return_counts True print np asarray unique_elements counts_elements res for cl in classes res append inv_map cl import pandas as pd df pd DataFrame np transpose np vstack np array test_filenames res columns 'fname' 'label' df to_csv 'submission.csv' header True quoting index False
592	data_dir '/kaggle/input/stanford-covid-vaccine/' train pd read_json data_dir 'train.json' lines True test pd read_json data_dir 'test.json' lines True sample_df pd read_csv data_dir 'sample_submission.csv'
197	test_norm_feat MinMaxScaler fit_transform test_feat pca PCA n_components CLUSTER_DIM fit test_norm_feat test_norm_feat pca transform test_norm_feat print format pca explained_variance_ratio_ sum def get_silhouette clt KMeans n_clusters random_state RANDOM_SEED fit test_norm_feat return silhouette_score test_norm_feat clt labels_ silhouette Parallel n_jobs N_THREADS delayed get_silhouette for in n_clusters plt plot np arange len silhouette silhouette plt xlabel plt ylabel plt grid True plt title
654	def add_lag_feature weather_df window group_df weather_df groupby 'site_id' cols 'air_temperature' 'cloud_coverage' 'dew_temperature' 'precip_depth_1_hr' 'sea_level_pressure' 'wind_direction' 'wind_speed' rolled group_df cols rolling window window min_periods lag_mean rolled mean reset_index astype np float16 lag_max rolled max reset_index astype np float16 lag_min rolled min reset_index astype np float16 lag_std rolled std reset_index astype np float16 for col in cols weather_df f'{col}_mean_lag{window}' lag_mean col weather_df f'{col}_max_lag{window}' lag_max col weather_df f'{col}_min_lag{window}' lag_min col weather_df f'{col}_std_lag{window}' lag_std col
802	import plotly express as px fig px histogram df 'age' 'gender' 'hospital_death' 'bmi' dropna "age" "hospital_death" color "gender" marginal "box" hover_data df 'age' 'gender' 'hospital_death' 'bmi' columns fig show
431	lr fit 'haversine' 'abs_lat_diff' 'abs_lon_diff' 'passenger_count' y_train evaluate lr 'haversine' 'abs_lat_diff' 'abs_lon_diff' 'passenger_count' y_train y_valid
373	df shape miss_count for col in df columns df col isnull sum miss_count append miss_count_rate np array miss_count
248	from keras preprocessing text import hashing_trick text words set text_to_word_sequence text vocab_size len words print vocab_size result hashing_trick text round vocab_size hash_function 'md5' print result
207	class LeNet nn Module def __init__ self super __init__ self conv1 nn padding self conv2 nn padding self conv3 nn padding self fc1 nn Linear self dropout1 nn Dropout self fc2 nn Linear def forward self relu self conv1 max_pool2d relu self conv2 max_pool2d relu self conv3 max_pool2d view relu self fc1 self dropout1 self fc2 return
410	heads 'phones-per-capita' heads 'qmobilephone' heads 'tamviv' heads 'tablets-per-capita' heads 'v18q1' heads 'tamviv' heads 'rooms-per-capita' heads 'rooms' heads 'tamviv' heads 'rent-per-capita' heads 'v2a1' heads 'tamviv'
200	from sklearn metrics import confusion_matrix confusion confusion_matrix yT y_pred print confusion
82	df 'click_time' df index df sort_values 'click_time' 'ip' inplace True clicks_minute pd DataFrame df groupby 'ip' 'app' rolling 'min' count clicks_minute reset_index inplace True clicks_minute sort_values 'click_time' 'ip' inplace True del clicks_minute 'click_time' clicks_minute 'ip' df 'click_time' gc collect df 'clicks_minute' clicks_minute values conversion 'clicks_minute' del clicks_minute gc collect
851	def create_set_of_png_for_patient patient needed_shape first_patient load_scan INPUT_FOLDER patient first_patient_pixels get_pixels_hu first_patient print format len first_patient_pixels pix_resampled spacing resample first_patient_pixels first_patient print first_patient_pixels shape print pix_resampled shape print total image_list for in range pix_resampled shape im pix_resampled image_list append cv2 resize normalize im needed_shape print for in range pix_resampled shape im pix_resampled image_list append cv2 resize normalize im needed_shape print for in range pix_resampled shape im pix_resampled image_list append cv2 resize normalize im needed_shape return image_list
507	ed application groupby 'TARGET' 'CNT_CHILDREN' 'TARGET' count unstack 'TARGET' fillna ed plot kind 'bar' stacked True print ed
316	DATA_BATCH_SIZE TRAIN_SAMPLE_RATE TRAIN_BATCH_SIZE int len train TRAIN_SAMPLE_RATE ax1 plt subplots nrows ncols figsize sns lineplot data train signal TRAIN_SAMPLE_RATE ax ax1 hue "size" size "size" sns lineplot data train open_channels TRAIN_SAMPLE_RATE ax ax1 hue "size" size "size" ax1 set_title f'Full train signal' ax1 plt subplots nrows ncols figsize sns lineplot data test signal TRAIN_SAMPLE_RATE ax ax1 hue "size" size "size" ax1 set_title f'Full test signal'
335	neutral_train 'temp_list' neutral_train 'selected_text' apply lambda str split neutral_train 'temp_list' neutral_train 'temp_list' apply lambda remove_stopword neutral_top Counter item for sublist in neutral_train 'temp_list' for item in sublist neutral_temp pd DataFrame neutral_top most_common neutral_temp columns 'count' neutral_temp style background_gradient cmap
668	model LGBMClassifier params fit categorical_feature pdp_Pd pdp pdp_isolate model model dataset model_features columns tolist feature n_jobs pdp pdp_plot pdp_Pd ncols plt show
337	def spoiler seed None if seed is not None np random seed seed tospoil np random choice range length size replace False submission perfect_sub copy submission tospoil np random rand return submission submissions for spoil_n in range length score_pub score_priv evaluate spoiler spoil_n spoil_n submissions append spoil_n score_pub score_priv submissions pd DataFrame submissions columns "n" "public_score" "private_score" submissions head
443	for hyper in enumerate random_params columns if hyper not in 'class_weight' 'n_estimators' 'score' 'is_unbalance' 'boosting_type' 'iteration' 'subsample' 'metric' 'verbose' 'loss' 'learning_rate' plt figure figsize if hyper 'loss' sns kdeplot sample space hyper for in range label linewidth sns kdeplot random_params hyper label linewidth sns kdeplot bayes_params hyper label linewidth plt vlines best_random_params hyper best_bayes_params hyper ymin ymax linestyles linewidth colors 'orange' 'green' plt legend loc plt title format hyper plt xlabel format hyper plt ylabel plt show
750	import re def breakdown_topic str re search '(.*)\_(.*).wikipedia.org\_(.*)\_(.*)' str if is not None return group group group group else return print breakdown_topic print breakdown_topic "_zh.wikipedia.org_all-access_spider" print breakdown_topic
724	n_iter start datetime datetime now for in range n_iter batch_grid_mask images end datetime datetime now timing end start total_seconds n_iter print f"batch_grid_mask: {timing}"
258	ax plt subplots ncols figsize sns distplot application_test EXT_SOURCE_1 dropna kde True color "g" ax ax set_title sns distplot application_test EXT_SOURCE_2 dropna kde True color "b" ax ax set_title sns distplot application_test EXT_SOURCE_3 dropna kde True color "r" ax ax set_title
173	predictions np zeros len scaled_test_X n_fold folds KFold n_splits n_fold shuffle True random_state fold_importance_df pd DataFrame fold_importance_df scaled_train_X columns print 'ok'
356	df_hmp np log1p df_hmp sns FacetGrid df_hmp row map sns distplot
88	def rle_encoding dots np where flatten run_lengths prev for in dots if prev run_lengths extend run_lengths prev return join str for in run_lengths print format rle_encoding label_mask
809	proportion train 'app' 'is_attributed' groupby 'app' as_index False mean sort_values 'is_attributed' ascending False counts train 'app' 'is_attributed' groupby 'app' as_index False count sort_values 'is_attributed' ascending False merge counts merge proportion on 'app' how 'left' merge columns 'app' 'click_count' 'prop_downloaded' ax merge plot secondary_y 'prop_downloaded' plt title ax set ylabel plt ylabel plt show print print merge
340	model Sequential model add Embedding max_features embedding_dim embeddings_initializer tf keras initializers Constant embedding_matrix trainable False model add Dropout
485	from featuretools variable_types import Boolean Datetime DatetimeTimeIndex Discrete Index Numeric Variable Id from featuretools primitives import AggregationPrimitive make_agg_primitive from datetime import datetime timedelta from collections import Counter def normalized_mode_count if mode shape return np nan counts dict Counter values mode mode iloc return counts mode np sum list counts values NormalizedModeCount make_agg_primitive function normalized_mode_count input_types Discrete return_type Numeric def longest_repetition dropna if shape return None longest_element current_element None longest_repeats current_repeats for element in if current_element element current_repeats else current_element element current_repeats if current_repeats longest_repeats longest_repeats current_repeats longest_element current_element return longest_element LongestSeq make_agg_primitive function longest_repetition input_types Discrete return_type Discrete
434	y_train y_valid train_test_split data np array data 'fare_amount' stratify data 'fare-bin' random_state RSEED test_size
641	ucf_root Path '../input/ashrae-ucf-spider-and-eda-full-test-labels' leak0_df pd read_pickle ucf_root 'site0.pkl' leak0_df 'meter_reading' leak0_df meter_reading_scraped leak0_df drop 'meter_reading_original' 'meter_reading_scraped' axis inplace True leak0_df fillna inplace True leak0_df loc leak0_df meter_reading 'meter_reading' leak0_df leak0_df leak0_df timestamp dt year print len leak0_df
257	def group_by df t1 t2 a1 df groupby t1 t2 t2 count return a1
52	train features y_train np log train b_train np log train cases_model lgb LGBMRegressor max_depth colsample_bytree learning_rate n_estimators subsample cases_model fit y_train init_score b_train train features y_train np log train b_train np log train fatalities_model lgb LGBMRegressor max_depth colsample_bytree learning_rate n_estimators subsample fatalities_model fit y_train init_score b_train
49	def count_words_from series sentences series str split vocab for sentence in tqdm sentences for word in sentence try vocab word except KeyError vocab word return vocab
508	application 'income_bins' pd cut application 'AMT_INCOME_TOTAL' range ed application groupby 'TARGET' 'income_bins' 'TARGET' count unstack 'TARGET' fillna ed plot kind 'bar' stacked True figsize print ed
712	def series_to_supervised data n_in n_out dropnan True n_vars if type data is list else data shape df pd DataFrame data cols names list list for in range n_in cols append df shift names 'var%d(t-%d)' for in range n_vars for in range n_out cols append df shift if names 'var%d(t)' for in range n_vars else names 'var%d(t+%d)' for in range n_vars agg pd concat cols axis agg columns names if dropnan agg dropna inplace True return agg
589	with strategy scope transformer_layer transformers TFDistilBertModel from_pretrained 'distilbert-base-multilingual-cased' model build_model transformer_layer max_len MAX_LEN model summary
205	transform_train transforms Compose transforms Resize transforms RandomHorizontalFlip transforms RandomRotation transforms RandomAffine shear scale transforms ColorJitter brightness contrast saturation transforms ToTensor transforms Normalize transform transforms Compose transforms Resize transforms ToTensor transforms Normalize training_dataset datasets CIFAR10 root './data' train True download True transform transform_train validation_dataset datasets CIFAR10 root './data' train False download True transform transform training_loader torch utils data DataLoader training_dataset batch_size shuffle True validation_loader torch utils data DataLoader validation_dataset batch_size shuffle False
757	for in test_df columns if 'mo_ye' continue if test_df dtype 'object' lbl preprocessing LabelEncoder lbl fit list test_df values test_df lbl transform list test_df values test_df 'mo_ye' test_df 'mo_ye' apply lambda pd to_datetime year pd to_datetime month
396	train_all_zero_features cr index cr train drop columns train_all_zero_features inplace True count_of_binary_features train max sum print format count_of_binary_features
102	def data_info _id df print Fore YELLOW print "ID = " _id sample_data df loc df 'id' _id print Fore MAGENTA print sample_data 'sequence' values print dict Counter sample_data 'sequence' values print len sample_data 'sequence' values print Fore CYAN print sample_data 'structure' values print dict Counter sample_data 'structure' values print len sample_data 'structure' values print Fore WHITE print "predicted_loop_type : \n\n" sample_data 'predicted_loop_type' values print dict Counter sample_data 'predicted_loop_type' values print len sample_data 'predicted_loop_type' values print Fore GREEN print "seq_length :" sample_data 'seq_length' values print "seq_scored :" sample_data 'seq_scored' values print Style RESET_ALL
841	program build_model task 'train' verbose True print if program is None print else print program_desc program
334	negative_train 'temp_list' negative_train 'selected_text' apply lambda str split negative_train 'temp_list' negative_train 'temp_list' apply lambda remove_stopword negative_top Counter item for sublist in negative_train 'temp_list' for item in sublist negative_temp pd DataFrame negative_top most_common negative_temp columns 'count' negative_temp style background_gradient cmap
72	print print "IP :" len df 'ip' unique print len df 'app' unique print len df 'device' unique print "OS :" len df 'os' unique print len df 'channel' unique
306	masks pd read_csv os path join '../input/' 'train_ship_segmentations_v2.csv' print masks shape 'masks found' print masks value_counts shape masks head
289	corrMatt data "bedrooms" "bathrooms" "price" corr mask np array corrMatt mask np tril_indices_from mask False fig ax plt subplots fig set_size_inches sn heatmap corrMatt mask mask vmax square True annot True
184	image_id train_ids plt figure figsize img get_image_data image_id mask get_image_data image_id img_masked cv2 bitwise_and img img mask mask print format img shape img dtype mask shape mask dtype plt subplot plt imshow img plt subplot plt imshow mask plt subplot plt imshow img_masked
726	fig axes plt subplots nrows ncols figsize plt subplots_adjust wspace hspace fig_row for col_id in range ax_id col_id fig_label train columns col_id feat train columns col_id fig_col col_id box_plot sns boxplot 'age' data train train feat train 'age' train 'age' ax axes fig_row fig_col box_plot set xlabel fig_label if fig_col fig_row
829	event_date calendar loc calendar 'event_name_1' isin calendar event_name_1 unique train_sales loc train_sales 'cat_id' 'HOBBIES' groupby 'state_id' mean reset_index loc 'index' isin event_date plt figure figsize plt subplot nine_example 'HOBBIES_CA' plot title 'HOBBIES_CA' color next color_cycle plt scatter reset_index level_0 'CA' color next color_cycle zorder plt subplot nine_example 'HOBBIES_TX' plot title 'HOBBIES_TX' color next color_cycle plt scatter reset_index level_0 'TX' color next color_cycle zorder plt subplot nine_example 'HOBBIES_WI' plot title 'HOBBIES_WI' color next color_cycle plt scatter reset_index level_0 'WI' color next color_cycle zorder plt tight_layout plt show
95	price_of_zero train loc train price plt figure figsize sns countplot price_of_zero category_name order price_of_zero category_name value_counts iloc index orient 'v' plt title fontsize plt ylabel fontsize plt xlabel fontsize
135	print len os listdir '../input/train' print len os listdir '../input/test'
697	files folders path "/kaggle/input/osic-pulmonary-fibrosis-progression/train" for dirnames filenames in os walk path files len filenames folders len dirnames print "{:,} files/images, {:,} folders/patients" format files folders
680	from fbprophet import Prophet from fbprophet plot import add_changepoints_to_plot dfs def fit_and_plot_trend store_id ts_df yearly_rolling_mean_store_df loc lambda df df "store_id" store_id dropna drop "store_id" axis rename columns "date" "ds" "qty" "y" Prophet daily_seasonality True fit ts_df future make_future_dataframe periods forecast predict future fig plot forecast dfs append forecast "ds" "trend" assign store_id store_id return add_changepoints_to_plot fig gca forecast
381	num_cols raw_test select_dtypes exclude 'object' columns fig ax plt subplots figsize for col in enumerate num_cols plt subplot plt xlabel col fontsize sns kdeplot raw_train col values bw label sns kdeplot raw_test col values bw label plt show
571	densenet weights include_top False input_shape for layer in densenet layers layer trainable False
530	map avsig_timestamp map osver_timestamp pd to_datetime pd to_datetime map avsig_timestamp map osver_timestamp pd to_datetime pd to_datetime print 'timestamps mapped.'
745	def get_training_dataset_with_oversample repeat_dataset True oversample False augumentation False dataset load_dataset TRAINING_FILENAMES labeled True if oversample dataset dataset flat_map lambda image label tf data Dataset from_tensors image label repeat get_num_of_repetition_for_example image label if augumentation dataset dataset map transform num_parallel_calls AUTO if repeat_dataset dataset dataset repeat dataset dataset shuffle dataset dataset batch BATCH_SIZE dataset dataset prefetch AUTO return dataset
206	def im_convert tensor image tensor cpu clone detach numpy image image transpose image image np array np array image image clip return image
261	print ap_train shape ap_train ap_train merge br_data left_on 'SK_ID_CURR' right_on 'SK_ID_CURR' how 'inner' print ap_train shape
612	def compute_text_and_questions test tokenizer test_text tokenizer texts_to_sequences test text values test_questions tokenizer texts_to_sequences test question values test_text sequence pad_sequences test_text maxlen test_questions sequence pad_sequences test_questions return test_text test_questions
236	ncaa_win_camp win_team win_team value_counts reset_index source ColumnDataSource ncaa_win_camp win_camp_list source data 'index' tolist figure y_range win_camp_list plot_width plot_height title y_axis_label tools title text_font 'helvetica' title text_font_size '12pt' title text_font_style "bold" hbar 'index' right height color 'blue' line_color "black" line_width fill_alpha source source show ncaa_lost_camp lost_team lost_team value_counts reset_index source ColumnDataSource ncaa_lost_camp lost_camp_list source data 'index' tolist figure y_range lost_camp_list plot_width plot_height title y_axis_label tools title text_font 'helvetica' title text_font_size '12pt' title text_font_style "bold" hbar 'index' right height color 'orange' line_color "black" line_width fill_alpha source source show
130	n_split lr 3e-5
705	x_train_full2 np square x_train_full x_test_full2 np square x_test_full x_sub_full2 np square x_sub_full
270	XGBOOST_PARAM 'random_state' 'n_estimators' 'learning_rate' 'num_leaves' 'max_depth' 'metric' 'auc' 'boosting_type' 'gbdt' 'reg_alpha' 'reg_lambda' 'feature_fraction' 'feature_fraction_seed' 'max_bins' 'min_split_gain' 'min_child_weight' 'min_data_in_leaf' 'random_state' 'subsample' 'subsample_freq' 'boost_from_average' False 'is_unbalance' True XGBGBDT xgb XGBClassifier XGBOOST_PARAM tree_method 'gpu_hist' silent
32	import random real fake for in zip if real append else fake append fake random sample fake len real for in real append append for in fake append append
336	import numpy as np test pd read_csv "../input/train.csv" length len test np random seed perfect_sub np random rand length target perfect_sub astype dtype int print perfect_sub print target print counts pd Series target value_counts counts counts sum
221	bold '**READINGS HIGHEST DURING THE MIDDLE OF THE DAY**' plt rcParams 'figure.figsize' temp_df train groupby 'hour' meter_reading sum temp_df plot linewidth color 'teal' plt xlabel fontsize plt ylabel plt show
402	def process_det index outputs score_threshold boxes outputs index 'boxes' data cpu numpy scores outputs index 'scores' data cpu numpy boxes boxes clip min max astype int indexes np where scores score_threshold boxes boxes indexes scores scores indexes return boxes scores
449	train_labels train_bureau 'TARGET' previous_features append 'SK_ID_CURR' train_ids train_bureau 'SK_ID_CURR' test_ids test_bureau 'SK_ID_CURR' train train_bureau merge train_previous previous_features on 'SK_ID_CURR' test test_bureau merge test_previous previous_features on 'SK_ID_CURR' print train shape print test shape
766	df_train 'roof_waste_material' np nan df_test 'roof_waste_material' np nan df_train 'electricity_other' np nan df_test 'electricity_other' np nan def fill_roof_exception if 'techozinc' and 'techoentrepiso' and 'techocane' and 'techootro' return else return def fill_no_electricity if 'public' and 'planpri' and 'noelec' and 'coopele' return else return df_train 'roof_waste_material' df_train apply lambda fill_roof_exception axis df_test 'roof_waste_material' df_test apply lambda fill_roof_exception axis df_train 'electricity_other' df_train apply lambda fill_no_electricity axis df_test 'electricity_other' df_test apply lambda fill_no_electricity axis
144	from sklearn metrics import classification_report y_pred_binary predictions argmax axis report classification_report y_true y_pred_binary target_names cm_plot_labels print report
374	df shape col df columns plt figure figsize for in range col_ df col df col notnull q_high col_ quantile q_low col_ quantile iqr q_high q_low high q_high iqr low q_low iqr col_ col_ col_ high col_ low plt subplot plt hist col_ bins plt xticks plt title str col plt tight_layout pad
254	def type_features data categorical_features data select_dtypes include "object" columns numerical_features data select_dtypes exclude "object" columns print "categorical_features :" categorical_features print print "numerical_features:" numerical_features
322	df_brazil_cases_by_day df_grouped_brazil df_grouped_brazil confirmed df_brazil_cases_by_day df_brazil_cases_by_day reset_index drop True df_brazil_cases_by_day 'day' df_brazil_cases_by_day date apply lambda df_brazil_cases_by_day date min days reordered_columns 'date' 'day' 'confirmed' 'deaths' 'confirmed_marker' 'deaths_marker' df_brazil_cases_by_day df_brazil_cases_by_day reordered_columns df_brazil_cases_by_day
541	labels_breed pd read_csv '../input/breed_labels.csv' labels_state pd read_csv '../input/color_labels.csv' labels_color pd read_csv '../input/state_labels.csv'
12	col 'identity_hate' print col pred_pro lr predict_proba frp trp thres roc_curve col pred_pro auc_val auc frp trp plt figure figsize plt plot color 'b' plt plot frp trp color 'r' label auc_val plt legend loc 'lower right' plt xlabel plt ylabel plt title
644	target_meter y_train create_X_y train_df target_meter target_meter y_valid_pred_total np zeros shape gc collect print 'target_meter' target_meter shape cat_features columns get_loc cat_col for cat_col in category_cols print 'cat_features' cat_features models0 for train_idx valid_idx in kf split y_train train_data iloc train_idx y_train train_idx valid_data iloc valid_idx y_train valid_idx print 'train' len train_idx 'valid' len valid_idx model y_pred_valid log fit_lgbm train_data valid_data cat_features category_cols num_rounds num_rounds lr bf y_valid_pred_total valid_idx y_pred_valid models0 append model gc collect if debug break sns distplot y_train sns distplot y_valid_pred_total oof0 mean_squared_error y_train y_valid_pred_total oof_total oof0 len y_train del y_train gc collect
708	def create_dataset dataset look_back dataX dataY for in range len dataset look_back dataset look_back dataX append dataY append dataset look_back print len dataY return np array dataX np array dataY
675	def get_molecule_graph df molecule_name molecule_df df loc lambda df df 'molecule_name' molecule_name labels molecule_df 'atom_1' 'atom_index_1' set_index 'atom_index_1' 'atom_1' to_dict labels update molecule_df 'atom_0' 'atom_index_0' set_index 'atom_index_0' 'atom_0' to_dict graph nx from_pandas_edgelist molecule_df source 'atom_index_0' target 'atom_index_1' edge_attr 'scalar_coupling_constant' create_using nx Graph return graph labels def draw_graph graph labels weight "distance_l2" position nx spring_layout graph weight weight fig ax plt subplots figsize nx draw_networkx_nodes graph position node_color 'red' alpha ax ax nx draw_networkx_edges graph position edge_color 'blue' alpha ax ax nx draw_networkx_labels graph position labels font_size ax ax return ax
419	from sklearn feature_selection import RFECV estimator RandomForestClassifier random_state n_estimators n_jobs selector RFECV estimator step cv scoring scorer n_jobs
606	figure title "interest level based on geography" y_range x_range xaxis axis_label 'longitude' yaxis axis_label 'latitude' lowLat trainDF 'latitude' trainDF 'interest_level' 'low' lowLong trainDF 'longitude' trainDF 'interest_level' 'low' medLat trainDF 'latitude' trainDF 'interest_level' 'medium' medLong trainDF 'longitude' trainDF 'interest_level' 'medium' highLat trainDF 'latitude' trainDF 'interest_level' 'high' highLong trainDF 'longitude' trainDF 'interest_level' 'high' circle lowLong lowLat size color terrain as_hex fill_alpha line_alpha legend 'low' circle medLong medLat size color plasma as_hex fill_alpha line_alpha legend 'med' circle highLong highLat size color plasma as_hex fill_alpha line_alpha legend 'high' show notebook_handle True
523	train_ target train_ drop 'target' axis test_ copy features_to_remove 'first_active_month' drop features_to_remove axis drop features_to_remove axis assert np all columns columns del train_ test_ gc collect
630	x1 x2 x3 x4 sess run num_frames video_matrix batch_labels batch_frames z1 z2 sess run labels num_frames vid_byte sess run batch_video_ids vid vid_byte decode print 'vid = %s' vid
815	def precision_and_recall y_true y_pred threshold tp fp fn tn for in range len y_true if y_pred threshold if y_true tp else fp elif y_true tn else fn precision tp tp fp if tp fp else recall tp tp fn if tp fn else accuracy tp tn tp tn fp fn print threshold format precision recall accuracy return precision recall accuracy y_test_pred model predict df_test columns values precision recall accuracy precision_and_recall y_test y_test_pred threshold precision recall accuracy precision_and_recall y_test y_test_pred threshold precision recall accuracy precision_and_recall y_test y_test_pred threshold
624	test pd read_csv '/kaggle/input/jigsaw-multilingual-toxic-test-translated/jigsaw_miltilingual_test_translated.csv' test 'content' test 'content' apply lambda text_process x_test regular_encode test content values tokenizer maxlen MAX_LEN lang_tag_test np array lang_embed row 'lang' 'orig' for row in test iterrows
866	def process_dataframe input_df encoder_dict None print categorical_feats input_df columns input_df dtypes 'object' for feat in categorical_feats encoder LabelEncoder input_df feat encoder fit_transform input_df feat fillna 'NULL' print return input_df categorical_feats tolist encoder_dict
492	bureau_by_loan bureau_balance_agg merge bureau_balance_counts right_index True left_on 'SK_ID_BUREAU' how 'outer' bureau_by_loan bureau 'SK_ID_BUREAU' 'SK_ID_CURR' merge bureau_by_loan on 'SK_ID_BUREAU' how 'left' bureau_balance_by_client agg_numeric bureau_by_loan drop columns 'SK_ID_BUREAU' group_var 'SK_ID_CURR' df_name 'client'
28	def ConvNet embeddings max_sequence_length num_words embedding_dim labels_index trainable False extra_conv True embedding_layer Embedding num_words embedding_dim weights embeddings input_length max_sequence_length trainable trainable sequence_input Input shape max_sequence_length dtype 'int32' embedded_sequences embedding_layer sequence_input convs filter_sizes for filter_size in filter_sizes l_conv filters kernel_size filter_size activation 'relu' embedded_sequences l_pool pool_size l_conv convs append l_pool l_merge Merge mode 'concat' concat_axis convs conv filters kernel_size activation 'relu' embedded_sequences pool pool_size conv if extra_conv True Dropout l_merge else Dropout pool Flatten Dense activation 'relu' Dropout preds Dense labels_index activation 'sigmoid' model Model sequence_input preds model compile loss 'binary_crossentropy' optimizer 'adam' metrics 'acc' model summary return model
619	def display_aug_effect img aug repeat aug_item 'rotate' plt figure figsize int repeat plt subplot repeat plt imshow img cmap 'gray' plt title 'original image' for in range repeat plt subplot repeat temp_aug_img aug image img astype 'uint8' 'image' plt imshow temp_aug_img cmap 'gray' plt title aug_item str plt axis 'off' plt show
763	integer_cols for in test_num_cols try if df_test fillna apply float is_integer all integer_cols except Exception as print "error: " stats df_test integer_cols describe transpose int8columns stats stats 'max' index int16columns stats stats 'max' stats 'max' index for in int8columns df_test df_test astype 'int8' for in int16columns df_test df_test astype 'int16'
496	def agg_categorical df parent_var df_name categorical pd get_dummies df select_dtypes 'category' categorical parent_var df parent_var categorical categorical groupby parent_var agg 'sum' 'count' 'mean' column_names for var in categorical columns levels for stat in 'sum' 'count' 'mean' column_names append '%s_%s_%s' df_name var stat categorical columns column_names idx np unique categorical axis return_index True categorical categorical iloc idx return categorical
714	test_X test_X reshape test_X shape test_X shape inv_yhat np concatenate yhat test_X axis inv_yhat scaler inverse_transform inv_yhat inv_yhat inv_yhat test_y test_y reshape len test_y inv_y np concatenate test_y test_X axis inv_y scaler inverse_transform inv_y inv_y inv_y
452	train train drop columns to_drop test test drop columns to_drop print train shape print test shape
532	colname train_in loc colname isin dates_intersect colname shape shape train_not loc colname isin dates_intersect colname shape shape test_in loc colname isin dates_intersect colname shape shape test_not loc colname isin dates_intersect colname shape shape print 'train and whole test sets...' print 'based on: {}' format colname print 'fraction of train dates intersection: {:.3f}' format train_in print 'fraction of train dates difference: {:.3f}' format train_not print 'fraction of test dates intersection: {:.3f}' format test_in print 'fraction of test dates difference: {:.3f}' format test_not
470	default_agg_primitives "sum" "std" "max" "skew" "min" "mean" "count" "percent_true" "num_unique" "mode" default_trans_primitives "day" "year" "month" "weekday" "haversine" "numwords" "characters" feature_names ft dfs entityset es target_entity 'app' trans_primitives default_trans_primitives agg_primitives default_agg_primitives max_depth features_only True print len feature_names
861	plt figure figsize df_train value_counts plot kind 'bar' plt title plt ylabel "count" plt show print df_train value_counts
629	import sys os multiprocessing csv from urllib import request error from PIL import Image from io import BytesIO
547	if len VALIDATION_MISMATCHES_IDS dataset load_dataset TRAINING_FILENAMES labeled True dataset dataset filter lambda image label idnum tf reduce_sum tf cast idnum VALIDATION_MISMATCHES_IDS tf int32 dataset dataset map lambda image label idnum image label imgs next iter dataset batch len VALIDATION_MISMATCHES_IDS display_batch_of_images imgs
107	import os random re math time random seed import numpy as np import pandas as pd import tensorflow as tf import tensorflow keras backend as import efficientnet tfkeras as efn import PIL from kaggle_datasets import KaggleDatasets from tqdm import tqdm
0	def extract_dicom_meta_data filename str Dict image_data pydicom read_file filename img np array image_data pixel_array flatten row image_data PatientID 'body_part_examined' image_data BodyPartExamined 'image_position_patient' image_data ImagePositionPatient 'image_orientation_patient' image_data ImageOrientationPatient 'photometric_interpretation' image_data PhotometricInterpretation 'rows' image_data Rows 'columns' image_data Columns 'pixel_spacing' image_data PixelSpacing 'window_center' image_data WindowCenter 'window_width' image_data WindowWidth 'modality' image_data Modality image_data StudyInstanceUID image_data StudyInstanceUID image_data StudyInstanceUID image_data SamplesPerPixel image_data BitsAllocated image_data BitsStored image_data HighBit image_data PixelRepresentation image_data RescaleIntercept image_data RescaleSlope 'img_min' np min img 'img_max' np max img 'img_mean' np mean img 'img_std' np std img return row
60	example_df train_df sample reset_index drop True example_generator train_datagen flow_from_dataframe example_df "../input/train/train/" x_col 'filename' y_col 'category' target_size IMAGE_SIZE class_mode 'categorical'
16	train_data observation train train_data train_data set_index 'id' 'timestamp' sort_index train_data
376	q_high df quantile q_low df quantile iqr q_high q_low high q_high iqr low q_low iqr df df drop df df high index df df drop df df low index
593	fig px line history history 'loss' 'val_loss' labels 'index' 'epoch' 'value' 'MCRMSE' title fig show
352	date_agg_2 train_agg groupby level sum date_agg_2 columns 'bookings' 'total' date_agg_2 index name date_agg_2 plot kind 'bar' stacked
272	def order_dict_bylist order None unordered_dict None if order None or isinstance order list or isinstance order dict False print return None elif isinstance order list order list columns values orderdict for in order orderdict order orderdict newdict for in order items unordered_dict newdict del order orderdict return newdict
603	def focal_loss prediction_tensor target_tensor weights None alpha gamma sigmoid_p tf nn sigmoid prediction_tensor zeros array_ops zeros_like sigmoid_p dtype sigmoid_p dtype pos_p_sub array_ops where target_tensor zeros target_tensor sigmoid_p zeros neg_p_sub array_ops where target_tensor zeros zeros sigmoid_p per_entry_cross_ent alpha pos_p_sub gamma tf log tf clip_by_value sigmoid_p 1e-8 alpha neg_p_sub gamma tf log tf clip_by_value sigmoid_p 1e-8 return tf reduce_sum per_entry_cross_ent
323	df_china_cases_by_day df_grouped_china df_grouped_china confirmed df_china_cases_by_day df_china_cases_by_day reset_index drop True df_china_cases_by_day 'day' df_china_cases_by_day date apply lambda df_china_cases_by_day date min days reordered_columns 'date' 'day' 'confirmed' 'deaths' 'confirmed_marker' 'deaths_marker' df_china_cases_by_day df_china_cases_by_day reordered_columns df_china_cases_by_day
813	def calc_extra df_timeseries gp df_timeseries groupby 'object_id' dfe gp 'mjd' max gp 'mjd' min rename 'dmjd' reset_index dfe 'dmjd' dfe 'dmjd' dfe 'std_flux' gp flux std reset_index flux return dfe
484	credit 'MONTHS_BALANCE' pd to_timedelta credit 'MONTHS_BALANCE' 'M' cash 'MONTHS_BALANCE' pd to_timedelta cash 'MONTHS_BALANCE' 'M' credit 'credit_balance_date' start_date credit 'MONTHS_BALANCE' credit credit drop columns 'MONTHS_BALANCE' cash 'cash_balance_date' start_date cash 'MONTHS_BALANCE' cash cash drop columns 'MONTHS_BALANCE' example_credit cash cash 'SK_ID_PREV' plt plot example_credit 'cash_balance_date' example_credit 'NAME_CONTRACT_STATUS' 'ro' plt title plt xlabel plt ylabel
673	def dense_added_model inp layers Input shape img_size img_size name 'inp' efnetb3 efn weights 'imagenet' include_top False efnetb3 inp layers Dense activation 'relu' layers Dropout layers Dense activation 'relu' layers Dropout layers Dense activation 'relu' layers Dropout output layers Dense activation 'sigmoid' model tf keras models Model inputs inp outputs output opt tf keras optimizers Adam learning_rate LR model compile optimizer opt loss binary_focal_loss gamma alpha metrics tf keras metrics BinaryAccuracy tf keras metrics AUC return model
586	tokenizer transformers DistilBertTokenizer from_pretrained 'distilbert-base-multilingual-cased' tokenizer save_pretrained fast_tokenizer BertWordPieceTokenizer 'vocab.txt' lowercase False fast_tokenizer
765	total df_train isnull sum sort_values ascending False percent df_train isnull sum df_train isnull count sort_values ascending False missing_df pd concat total percent axis keys missing_df head
4	numeric_dtypes 'float64' numerics for in train columns if train dtype in numeric_dtypes numerics append
772	new_feats for col in family_size_features new_col_name 'new_{}_per_{}' format 'qmobilephone' col new_feats append new_col_name df_train new_col_name df_train 'qmobilephone' df_train col df_test new_col_name df_test 'qmobilephone' df_test col for col in new_feats df_train col replace np inf np nan inplace True df_train col fillna inplace True df_test col replace np inf np nan inplace True df_test col fillna inplace True
807	plt figure figsize mean train is_attributed values mean ax sns barplot mean mean ax set ylabel title for uniq in zip ax patches mean mean height get_height ax text get_x get_width height format round uniq ha "center"
111	feature_score pd DataFrame preprocessing MinMaxScaler fit_transform feature_score columns feature_score columns index feature_score index feature_score 'mean' feature_score mean axis feature_score sort_values 'mean' ascending False plot kind 'bar' figsize
754	import operator import xgboost as xgb target 'price_doc' IDcol 'id' predictors for in x_train columns if not in target IDcol xgb_params 'eta' 'max_depth' 'subsample' 'colsample_bytree' 'objective' 'reg:linear' 'eval_metric' 'rmse' 'silent' train_matrix xgb DMatrix x_train predictors x_train target values feature_names x_train predictors columns values model xgb train dict xgb_params silent train_matrix num_boost_round importance model get_fscore importance sorted importance items key operator itemgetter df pd DataFrame importance columns 'feature' 'fscore' df 'fscore' df 'fscore' df 'fscore' max df df sort_values by "fscore" ascending False df head plot kind 'barh' 'feature' 'fscore' legend False figsize plt title plt xlabel 'relative importance' plt show
386	import networkx as nx import random from itertools import combinations nx Graph clear random_pick_from_top_n random sample top_n for list_of_nodes in train ingredients filtered_nodes set list_of_nodes intersection set for in random_pick_from_top_n for node1 node2 in list combinations filtered_nodes add_node node1 add_node node2 add_edge node1 node2 nx draw_networkx
339	train_df pd read_csv '/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip' fillna test_df pd read_csv '/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip' fillna train_df sample
638	for task prediction solved in tqdm zip evaluation_tasks evaluation_predictions evaluation_solved if solved for in range len task 'train' plot_sample task 'train' for in range len task 'test' plot_sample task 'test' prediction
358	dftrain pd read_csv '../input/covid19-global-forecasting-week-2/train.csv' parse_dates sort_values by dftest pd read_csv '../input/covid19-global-forecasting-week-2/test.csv' parse_dates sort_values by dftrain head
118	dates_overlap train2 train loc train isin dates_overlap all_data pd concat train2 test axis sort False all_data loc all_data np nan all_data loc all_data np nan all_data pd to_datetime all_data le preprocessing LabelEncoder all_data le fit_transform all_data Date all_data all_data dt day all_data all_data dt month all_data all_data dt year all_data fillna inplace True all_data fillna inplace True all_data fillna inplace True all_data fillna inplace True all_data fillna inplace True display all_data display all_data loc all_data
162	import matplotlib pyplot as plt loss history history 'loss' val_loss history history 'val_loss' epochs range len loss plt legend plt plot epochs loss 'bo' label plt plot epochs val_loss 'b' label plt title plt legend plt show
658	root Path '../input/ashrae-feather-format-for-fast-loading' train_df pd read_feather root 'train.feather' weather_train_df pd read_feather root 'weather_train.feather' weather_test_df pd read_feather root 'weather_test.feather' building_meta_df pd read_feather root 'building_metadata.feather'
806	plt figure figsize cols 'ip' 'app' 'device' 'os' 'channel' uniques len train col unique for col in cols sns set font_scale ax sns barplot cols uniques log True ax set xlabel ylabel 'log(unique count)' title for uniq in zip ax patches uniques height get_height ax text get_x get_width height uniq ha "center"
494	test pd read_csv '../input/application_test.csv' test test merge bureau_counts on 'SK_ID_CURR' how 'left' test test merge bureau_agg on 'SK_ID_CURR' how 'left' test test merge bureau_balance_by_client on 'SK_ID_CURR' how 'left'
800	stats for country in sorted full_table unique df get_time_series country if len df or max df continue print format country opt_display_model df stats
515	def rle_encode im pixels im flatten order 'F' pixels np concatenate pixels runs np where pixels pixels runs runs return join str for in runs
760	df_train 'diagnosis' df_train 'diagnosis' astype 'str' df_train df_train 'id_code' 'diagnosis' if df_train 'id_code' split 'png' for index in range len df_train 'id_code' df_train 'id_code' index df_train 'id_code' index '.png' df_test df_test 'id_code' if df_test 'id_code' split 'png' for index in range len df_test 'id_code' df_test 'id_code' index df_test 'id_code' index '.png' train_data np arange df_train shape train_idx val_idx train_test_split train_data train_size random_state df_train iloc train_idx df_train iloc val_idx df_test print shape print shape print shape
75	df groupby 'ip' is_attributed sum plt figure figsize plt title fontsize ax value_counts normalize True plot kind 'bar' for in ax patches ax annotate '{:.2f}%' format get_height get_x get_height
844	np save "x_train" x_train np save "x_test" x_test np save "y_train" y_train np save "features" features np save "test_features" test_features np save "word_index.npy" word_index
529	def rle_encode im pixels im flatten order 'F' pixels np concatenate pixels runs np where pixels pixels runs runs return join str for in runs binary_prediction test_predictions_stacked astype int all_masks idx rle_encode binary_prediction for idx in enumerate tqdm tqdm test_ids
639	for task prediction in tqdm zip train_tasks train_predictions if input_output_shape_is_same task for in range len task 'test' plot_sample task 'test' prediction
676	epoch_datetime pd datetime trf_var_68_s train_df 'var_68' epoch_datetime toordinal astype int date_s trf_var_68_s map datetime fromordinal train_df 'date' date_s sorted_train_df train_df drop 'var_68' axis sort_values 'date'
469	train pd read_csv '../input/home-credit-simple-featuers/simple_features_train.csv' test pd read_csv '../input/home-credit-simple-featuers/simple_features_test.csv' test_ids test 'SK_ID_CURR' train_labels np array train 'TARGET' astype np int32 reshape train train drop columns 'SK_ID_CURR' 'TARGET' test test drop columns 'SK_ID_CURR' print train shape print test shape
804	h1_col for in col if "h1_" in d1_col for in col if "d1_" in h1d1 list pd Series h1_col str replace "h1_" for in h1d1 'diff_' 'd1_' 'h1_'
348	def perform_pca train_X train_Y test_X test_Y pca_model_accuracies pd DataFrame pca PCA n_components svd_solver 'randomized' whiten True pca fit train_X train_X_pca pca transform train_X test_X_pca pca transform test_X svc_acc_val perform_svc train_X_pca train_Y test_X_pca test_Y rfc_acc_val perform_rfc train_X_pca train_Y test_X_pca test_Y knn_acc_val perform_knn train_X_pca train_Y test_X_pca test_Y lr_acc_val perform_linear_regression train_X_pca train_Y test_X_pca test_Y lc_acc_val perform_linear_lasso train_X_pca train_Y test_X_pca test_Y rr_acc_val perform_ridge_regression train_X_pca train_Y test_X_pca test_Y enet_acc_val perform_elastinet_regression train_X_pca train_Y test_X_pca test_Y pca_model_accuracies pca_model_accuracies append svc_acc_val rfc_acc_val knn_acc_val lr_acc_val lc_acc_val rr_acc_val enet_acc_val cols list pca_model_accuracies columns values cols cols cols pca_model_accuracies pca_model_accuracies cols pca_model_accuracies pca_model_accuracies sort_values by 'r2_score' return pca_model_accuracies
393	plt figure figsize plt subplot sns distplot particles nhits values axlabel bins plt title plt subplot plt pie particles groupby 'q' 'vx' count labels 'negative' 'positive' autopct '%.0f%%' shadow True radius plt title plt show
256	ax plt subplots figsize application_train TARGET value_counts plot pie explode autopct '%1.1f%%' ax ax shadow True ax set_title ax set_ylabel sns countplot 'TARGET' data application_train ax ax ax set_title plt show
76	print describe quantile quantile quantile
123	VotingRegressor estimators 'lin' linreg 'ridge' ridge 'sgd' sgd fit train target acc_model train test
147	num_test_images model load_weights 'model.h5' predictions model predict_generator test_gen steps num_test_images verbose
820	cities pd read_csv '../input/cities.csv' xy_int cities 'X' 'Y' astype np int64 with open 'xy_int.csv' 'w' as fp print len xy_int file fp print xy_int to_csv index False header False sep file fp
321	df_grouped_italy get_df_country_cases df_covid df_grouped_italy
821	order with open 'lk.sol' 'r' as fp lines fp readlines order int split for in lines
736	from transformers import BertTokenizer pretrained_weights os path join NQ_DIR "bert-base-uncased" bert_tokenizer BertTokenizer from_pretrained pretrained_weights bert_barebone TFBertModel from_pretrained pretrained_weights bert_for_nq TFBertForNQDemo from_pretrained pretrained_weights input_ids tf constant bert_tokenizer encode None input_masks tf constant shape input_ids shape segment_ids tf constant shape input_ids shape inputs input_ids input_masks segment_ids outputs bert_barebone inputs last_hidden_states outputs print last_hidden_states shape outputs bert_for_nq inputs start_pos_logits end_pos_logits answer_type_logits outputs print start_pos_logits shape print end_pos_logits shape print answer_type_logits shape len bert_for_nq trainable_variables
733	if FLAGS do_valid if FLAGS smaller_valid_dataset predict_file FLAGS validation_predict_file_small else predict_file FLAGS validation_predict_file f1 long_f1 short_f1 compute_f1_scores valid_predictions_json predict_file print f" valid f1: {f1}\n valid long_f1: {long_f1}\nvalid short_f1: {short_f1}"
86	print format im shape from skimage color import rgb2gray im_gray rgb2gray im print format im_gray shape
403	from itertools import product tta_transforms for tta_combination in product TTAHorizontalFlip None TTAVerticalFlip None None tta_transforms append TTACompose tta_transform for tta_transform in tta_combination if tta_transform
81	df 'id' range len df last_clicks df groupby 'ip' id last reset_index last_clicks 'last_click' last_clicks drop 'ip' axis inplace True df pd merge df last_clicks on 'id' how 'left' set_index pd to_datetime df 'click_time' df 'last_click' fillna inplace True conversion 'last_click' del df 'id' df 'click_time' last_clicks gc collect
266	def print_hit_rate_stats df_summary print '{:6s} {:>4s} {:6s}' format print for zone in df_summary iterrows print '{:6s} {:>4d} {:>6.3f}%' format zone np int16 zone 'sum' zone 'pct' print print '{:6s} {:>4d} {:6.3f}%' format np int16 df_summary 'sum' sum axis df_summary 'sum' sum axis df_summary 'count' sum axis
110	columns for in data columns dummies pd get_dummies data columns columns drop_first True sparse True del data
734	if FLAGS do_predict test_features tf train Example FromString numpy for in tf data TFRecordDataset FLAGS test_tf_record predictions_json get_prediction_json mode 'test' max_nb_pos_logits FLAGS n_best_size
183	sorted_train_categories_count sorted train_categories_count values index_8000 np where np array sorted_train_categories_count plt figure figsize plt title plt plot sorted_train_categories_count plt figure figsize plt subplot plt title index_8000 plt plot sorted_train_categories_count index_8000 plt subplot plt title index_8000 plt plot sorted_train_categories_count index_8000
771	new_feats for col in family_size_features new_col_name 'new_{}_per_{}' format 'v18q1' col new_feats append new_col_name df_train new_col_name df_train 'v18q1' df_train col df_test new_col_name df_test 'v18q1' df_test col for col in new_feats df_train col replace np inf np nan inplace True df_train col fillna inplace True df_test col replace np inf np nan inplace True df_test col fillna inplace True
203	from sklearn metrics import confusion_matrix confusion confusion_matrix yT yR_pred print confusion
416	from sklearn ensemble import RandomForestClassifier from sklearn metrics import f1_score make_scorer from sklearn model_selection import cross_val_score from sklearn preprocessing import Imputer from sklearn preprocessing import MinMaxScaler from sklearn pipeline import Pipeline scorer make_scorer f1_score greater_is_better True average 'macro'
748	result_1 "oversampling" "f1" "recall" "precision" "acc" "f1" "recall" "precision" "acc" "f1" "recall" "precision" "acc" "f1" "recall" "precision" "acc" print json dumps result_1 ensure_ascii False indent
460	cash pd read_csv replace np nan cash convert_types cash cash 'LATE_PAYMENT' cash 'SK_DPD' cash 'INSTALLMENTS_PAID' cash 'CNT_INSTALMENT' cash 'CNT_INSTALMENT_FUTURE'
80	plt figure figsize df resample 'H' is_attributed mean plot plt title fontsize plt xlabel plt ylabel
696	filename ds pydicom dcmread filename plt imshow ds pixel_array cmap plt cm bone
649	def add_lag_feature weather_df window group_df weather_df groupby 'site_id' cols 'air_temperature' 'cloud_coverage' 'dew_temperature' 'precip_depth_1_hr' 'sea_level_pressure' 'wind_direction' 'wind_speed' rolled group_df cols rolling window window min_periods lag_mean rolled mean reset_index astype np float16 lag_max rolled max reset_index astype np float16 lag_min rolled min reset_index astype np float16 lag_std rolled std reset_index astype np float16 for col in cols weather_df f'{col}_mean_lag{window}' lag_mean col weather_df f'{col}_max_lag{window}' lag_max col weather_df f'{col}_min_lag{window}' lag_min col weather_df f'{col}_std_lag{window}' lag_std col
439	num_leaves 'num_leaves' hp quniform 'num_leaves' num_leaves_dist for in range num_leaves_dist append sample num_leaves 'num_leaves' plt figure figsize sns kdeplot num_leaves_dist linewidth shade True plt title size plt xlabel size plt ylabel size
601	def build_new_df df extension 'jpeg' new_df pd concat df df new_df 'filename' pd concat df 'id_code' apply lambda string string f'_s1.{extension}' df 'id_code' apply lambda string string f'_s2.{extension}' return new_df new_train build_new_df train_df new_test build_new_df test_df new_train to_csv 'new_train.csv' index False new_test to_csv 'new_test.csv' index False
855	import seaborn as sns import numpy as np import pandas as pd from mpl_toolkits mplot3d import import matplotlib pyplot as plt sns set style 'darkgrid' import os print os listdir "../input" from pylab import rcParams rcParams 'figure.figsize' train pd read_csv '../input/train.csv' test pd read_csv '../input/test.csv' train head
97	plt figure figsize sns boxplot train shipping train price showfliers False orient 'v' plt title fontsize plt xlabel fontsize plt ylabel fontsize
252	from keras utils import plot_model from keras models import Model from keras layers import Input from keras layers import Dense from keras layers recurrent import LSTM visible Input shape hidden1 LSTM visible hidden2 Dense activation 'relu' hidden1 output Dense activation 'sigmoid' hidden2 model Model inputs visible outputs output model summary plot_model model to_file 'recurrent_neural_network.png'
138	df_0 df_data df_data 'label' sample SAMPLE_SIZE random_state df_1 df_data df_data 'label' sample SAMPLE_SIZE random_state df_data pd concat df_0 df_1 axis reset_index drop True df_data shuffle df_data df_data 'label' value_counts
661	target_meter y_train create_X_y train_df target_meter target_meter y_valid_pred_total np zeros shape gc collect print 'target_meter' target_meter shape cat_features columns get_loc cat_col for cat_col in category_cols print 'cat_features' cat_features models0 for train_idx valid_idx in kf split y_train train_data iloc train_idx y_train train_idx valid_data iloc valid_idx y_train valid_idx print 'train' len train_idx 'valid' len valid_idx model y_pred_valid log fit_lgbm train_data valid_data cat_features category_cols num_rounds num_rounds lr bf y_valid_pred_total valid_idx y_pred_valid models0 append model gc collect if debug break sns distplot y_train sns distplot y_valid_pred_total oof0 mean_squared_error y_train y_valid_pred_total oof_total oof0 len y_train del y_train gc collect
584	train_dataset tf data Dataset from_tensor_slices x_train y_train repeat shuffle batch BATCH_SIZE prefetch AUTO valid_dataset tf data Dataset from_tensor_slices x_valid y_valid batch BATCH_SIZE cache prefetch AUTO test_dataset tf data Dataset from_tensor_slices x_test batch BATCH_SIZE
849	leak pd read_csv '../input/breaking-lb-fresh-start-with-lag-selection/train_leak.csv' data 'leak' leak 'compiled_leak' values data 'log_leak' np log1p leak 'compiled_leak' values
847	class MyDataset Dataset def __init__ self dataset self dataset dataset def __getitem__ self index data target self dataset index return data target index def __len__ self return len self dataset
368	df_train df_train df_train 'outliers' target df_train 'target' del df_train 'target' features for in df_train columns if not in 'card_id' 'first_active_month' 'outliers' categorical_feats for in features if 'feature_' in
269	dtypestrain dtypestrain 'category' dtypestrain 'target' 'int8' for in range dtypestrain 'var_' str 'float32' dtypestest dtypestest 'category' for in range dtypestest 'var_' str 'float32'
738	decay_var_list for in range len bert_nq trainable_variables name bert_nq trainable_variables name if any in name for in "layer_norm" "bias" decay_var_list append name decay_var_list
652	root Path '../input/ashrae-feather-format-for-fast-loading' train_df pd read_feather root 'train.feather' weather_train_df pd read_feather root 'weather_train.feather' weather_test_df pd read_feather root 'weather_test.feather' building_meta_df pd read_feather root 'building_metadata.feather'
159	df_train pickle load open '../input/python-generators-to-reduce-ram-usage-part-1/dftrain.pickle' 'rb' df_test pickle load open '../input/python-generators-to-reduce-ram-usage-part-1/dftest.pickle' 'rb' print df_train shape print df_test shape
682	logregModel LogisticRegression params 'C' np logspace start stop num clf GridSearchCV logregModel params scoring 'neg_log_loss' refit True clf fit y_train
241	train_df train_transaction merge train_identity how 'left' left_index True right_index True test_df test_transaction merge test_identity how 'left' left_index True right_index True print str train_df shape print str test_df shape
775	cols_with_only_one_value for col in df_train columns if col continue if df_train col value_counts shape or df_test col value_counts shape print col cols_with_only_one_value append col
679	def compute_rolling_mean_per_store_df df period return df set_index "date" groupby "store_id" rolling period mean reset_index
686	label_map dict labels 'attribute_id' 'attribute_name' values tolist not_in_train_labels set labels 'attribute_id' astype str values set list cls_counts for _id in not_in_train_labels label label_map int _id print f'attribute_id: {_id} attribute_name: {label}'
276	fig ax plt subplots fig set_size_inches ordersDay orders "order_dow" replace sn countplot color Order Count Across Days Of The Week
194	def compute_histogram img hist_size hist cv2 calcHist img mask None histSize hist_size ranges hist cv2 normalize hist dst hist return hist
155	df_train_padded df_test_padded y_toxic df_train 'toxic' y_severe_toxic df_train 'severe_toxic' y_obscene df_train 'obscene' y_threat df_train 'threat' y_insult df_train 'insult' y_identity_hate df_train 'identity_hate'
296	fig ax plt subplots fig set_size_inches sn boxplot "bedroomcnt" "logerror" data mergedFiltered ax ax color Bedroom Count ",title=" Bedroom Count Vs Log Error
614	lwk metrics cohen_kappa_score y_true y_pred weights 'linear' qwk metrics cohen_kappa_score y_true y_pred weights 'quadratic' print lwk print qwk
93	group train groupby train brand_name ranking pd DataFrame group price mean ranking reset_index level inplace True ranking ranking sort_values by 'price' ascending False head plt figure figsize sns barplot 'price' 'brand_name' data ranking orient 'h' plt title fontsize plt ylabel fontsize plt xlabel fontsize
222	bold '**MONTHLY READINGS ARE HIGHEST CHANGES BASED ON BUILDING TYPE**' temp_df train groupby 'month' 'primary_use' meter_reading sum reset_index ax sns FacetGrid temp_df col "primary_use" col_wrap height aspect sharey False ax map plt plot 'month' 'meter_reading' color "teal" linewidth plt subplots_adjust hspace plt show
819	for in tqdm range len df_test if df_test 'sentiment' iloc 'neutral' df_test 'selected_text' iloc df_test 'text' iloc else pass
605	test_df for in range filtered_test_imgs shape batch_idx list range min filtered_test_imgs shape test_generator DataGenerator batch_idx df filtered_test_imgs shuffle False mode 'predict' base_path '../input/severstal-steel-defect-detection/test_images' target_df filtered_sub_df reshape batch_size n_classes batch_pred_masks unet predict_generator test_generator workers verbose use_multiprocessing False for in tqdm enumerate batch_idx filename filtered_test_imgs iloc image_df filtered_sub_df filtered_sub_df filename copy pred_masks batch_pred_masks round astype int pred_rles build_rles pred_masks reshape image_df pred_rles test_df append image_df
476	plt rcParams 'font.size' best_random_score random loc 'score' best_random_iteration random loc 'iteration' best_opt_score opt loc 'score' best_opt_iteration opt loc 'iteration' sns lmplot 'iteration' 'score' hue 'set' data scores size plt scatter best_random_iteration best_random_score marker 'blue' edgecolor 'k' plt scatter best_opt_iteration best_opt_score marker 'red' edgecolor 'k' plt xlabel plt ylabel 'ROC AUC' plt title
656	leak_df pd read_feather '../input/ashrae-leak-data-station/leak.feather' leak_df fillna inplace True leak_df leak_df leak_df timestamp dt year leak_df loc leak_df meter_reading 'meter_reading' leak_df leak_df leak_df building_id sample_submission loc sample_submission meter_reading 'meter_reading' test_df 'pred' sample_submission meter_reading leak_df leak_df merge test_df 'building_id' 'meter' 'timestamp' 'pred' 'row_id' left_on 'building_id' 'meter' 'timestamp' right_on 'building_id' 'meter' 'timestamp' how "left" leak_df leak_df merge building_meta_df 'building_id' 'site_id' on 'building_id' how 'left'
735	PRETRAINED_MODELS "BERT" 'bert-base-uncased' 'bert-large-uncased' 'bert-base-cased' 'bert-large-cased' 'bert-base-multilingual-uncased' 'bert-base-multilingual-cased' 'bert-base-chinese' 'bert-base-german-cased' 'bert-large-uncased-whole-word-masking' 'bert-large-cased-whole-word-masking' 'bert-large-uncased-whole-word-masking-finetuned-squad' 'bert-large-cased-whole-word-masking-finetuned-squad' 'bert-base-cased-finetuned-mrpc' "DISTILBERT" 'distilbert-base-uncased' 'distilbert-base-uncased-distilled-squad'
795	import pandas as pd numpy as np from matplotlib import pyplot as plt import scipy stats as stats pd options display max_columns
874	train pd read_csv "../input/train.csv" train head
537	def plots_by_country country country_name temp country temp round temp temp temp round temp temp last_date temp iloc len temp death_rate temp temp Date last_date recovered_rate temp temp Date last_date temp temp melt id_vars value_vars var_name value_name fig px line temp color log_y True width height title country_name color_discrete_sequence dth rec fig show return death_rate recovered_rate rates for key value in dict items death_rate recovered_rate plots_by_country value key rates append key np float death_rate np float recovered_rate
357	from bokeh charts import HeatMap from bokeh plotting import vplot df pd qcut df heatmaps for in df cat categories values hm HeatMap df_hmp df_hmp short_name isin df df index values 'short_name' values hover_tool True title str xgrid False stat 'sum' plot_width plot_height tools 'hover, box_zoom, resize, save, wheel_zoom, reset' heatmaps append hm show vplot heatmaps
481	app_train pd read_csv '../input/application_train.csv' sort_values 'SK_ID_CURR' reset_index loc drop columns 'index' app_test pd read_csv '../input/application_test.csv' sort_values 'SK_ID_CURR' reset_index loc drop columns 'index' bureau pd read_csv '../input/bureau.csv' sort_values 'SK_ID_CURR' 'SK_ID_BUREAU' reset_index loc drop columns 'index' bureau_balance pd read_csv '../input/bureau_balance.csv' sort_values 'SK_ID_BUREAU' reset_index loc drop columns 'index' cash pd read_csv sort_values 'SK_ID_CURR' 'SK_ID_PREV' reset_index loc drop columns 'index' credit pd read_csv '../input/credit_card_balance.csv' sort_values 'SK_ID_CURR' 'SK_ID_PREV' reset_index loc drop columns 'index' previous pd read_csv '../input/previous_application.csv' sort_values 'SK_ID_CURR' 'SK_ID_PREV' reset_index loc drop columns 'index' installments pd read_csv '../input/installments_payments.csv' sort_values 'SK_ID_CURR' 'SK_ID_PREV' reset_index loc drop columns 'index'
92	plt figure figsize sns boxplot 'price' 'cat1' data train orient 'h' plt title fontsize plt ylabel fontsize plt xlabel fontsize
461	credit pd read_csv '../input/credit_card_balance.csv' replace np nan credit convert_types credit credit 'OVER_LIMIT' credit 'AMT_BALANCE' credit 'AMT_CREDIT_LIMIT_ACTUAL' credit 'BALANCE_CLEARED' credit 'AMT_BALANCE' credit 'LOW_PAYMENT' credit 'AMT_PAYMENT_CURRENT' credit 'AMT_INST_MIN_REGULARITY' credit 'LATE' credit 'SK_DPD'
462	def objective hyperparameters iteration if 'n_estimators' in hyperparameters keys del hyperparameters 'n_estimators' cv_results lgb cv hyperparameters train_set num_boost_round nfold N_FOLDS early_stopping_rounds metrics 'auc' seed score cv_results 'auc-mean' estimators len cv_results 'auc-mean' hyperparameters 'n_estimators' estimators return score hyperparameters iteration
251	from keras utils import plot_model from keras models import Model from keras layers import Input from keras layers import Dense from keras layers convolutional import from keras layers pooling import visible Input shape conv1 kernel_size activation 'relu' visible pool1 pool_size conv1 conv2 kernel_size activation 'relu' pool1 pool2 pool_size conv2 hidden1 Dense activation 'relu' pool2 output Dense activation 'sigmoid' hidden1 model Model inputs visible outputs output model summary plot_model model to_file 'convolutional_neural_network.png'
51	def clean_up_text_with_all_process text text text lower text clean_contractions text text clean_special_chars text text clean_small_caps text return text
164	df_preds pd DataFrame predictions new_names 'conf_1' 'x_1' 'y_1' 'width_1' 'height_1' 'conf_2' 'x_2' 'y_2' 'width_2' 'height_2' df_preds columns new_names df_preds df_test df_preds
275	fig ax plt subplots fig set_size_inches sn countplot data orders "order_hour_of_day" ax ax color Order Count Across Hour Of The Day
255	def missingdata data total data isnull sum sort_values ascending False percent data isnull sum data isnull count sort_values ascending False ms pd concat total percent axis keys ms ms ms ax plt subplots figsize plt xticks rotation fig sns barplot ms index ms color "green" alpha plt xlabel fontsize plt ylabel fontsize plt title fontsize return ms
798	stats for Province in df get_time_series_province Province print format Province opt_display_model df stats
791	cv_index train_index train_all cv_index evaluate_index evaluate_all cv_index print train_index shape evaluate_index shape histall histcoverage train_df coverage_class train_index values histall_test histcoverage train_df coverage_class evaluate_index values fig axes plt subplots nrows ncols figsize sharex True sharey True for in range for in train_index if train_df coverage_class axes imshow np array train_df masks axes set_axis_off axes set_title 'class {}' format if break
577	def compute_game_time_stats group col return group 'installation_id' col 'event_count' 'game_time' groupby 'installation_id' col agg np mean np sum np std reset_index pivot columns col index 'installation_id'
192	train pd read_csv f'{DATA_PATH}/train.csv' train drop_duplicates keep False inplace True subset test pd read_csv f'{DATA_PATH}/test.csv' subm pd read_csv f'{DATA_PATH}/sample_submission.csv' subm subm apply lambda split subm subm apply lambda int split subm subm subm subm merge test drop axis on train 'SPLIT' 'train' test 'SPLIT' 'val' subm 'SPLIT' 'test' data train append test subm print 'train:' train shape train Patient nunique '\ntest:' test shape test Patient nunique '\nsubm:' subm shape subm Patient nunique '\ndata' data shape data Patient nunique data 'min_week' data data loc data SPLIT 'test' 'min_week' np nan data 'min_week' data groupby 'min_week' transform 'min'
816	history resa2 clustering hits stds filters phik nu nu truth truth history history resa2 "event_id" event_num score score_event_fast truth resa2 rename index str columns "label" "track_id" print score
384	map_ord1 full_data ord_1 full_data ord_1 map map_ord1
220	bold '**SUNDAYS HAVE THE LOWEST READINGS**' plt rcParams 'figure.figsize' ax sns boxplot data train 'weekday_name' 'meter_reading' color 'teal' boxprops dict alpha ax set_ylabel fontsize ax set_xlabel 'weekdays' fontsize plt show
524	kf KFold n_splits shuffle True random_state train_cols columns tolist params 'learning_rate' 'boosting' 'gbdt' 'objective' 'regression' 'metric' 'rmse' 'num_leaves' 'min_data_in_leaf' 'max_bin' 'bagging_fraction' 'lambda_l2' 1e-4 'max_depth' 'seed' 'nthreads' oof_val np zeros shape oof_test np zeros shape for tr val in kf split print format y_tr iloc tr iloc tr y_val iloc val iloc val dtrain lgb Dataset values y_tr values feature_name train_cols dvalid lgb Dataset values y_val values feature_name train_cols reference dtrain lgb_model lgb train params dtrain num_boost_round valid_sets dvalid valid_names 'valid' verbose_eval early_stopping_rounds oof_val val lgb_model predict oof_test lgb_model predict
776	binary_cat_features col for col in train columns if train col value_counts shape object_features 'edjefe' 'edjefa' categorical_feats binary_cat_features object_features
867	all_data_na feature_matrix_enc isnull sum len feature_matrix_enc all_data_na all_data_na drop all_data_na all_data_na index sort_values ascending False missing_data pd DataFrame all_data_na missing_data head
237	import pandas as pd import numpy as np import warnings warnings filterwarnings 'ignore' from datetime import datetime from sklearn model_selection import RandomizedSearchCV GridSearchCV from sklearn import metrics from sklearn metrics import roc_auc_score from sklearn model_selection import StratifiedKFold from xgboost import XGBClassifier pd set_option 'display.max_columns'
279	productsCount orderProductsTrain "product_id" value_counts to_frame productsCount "count" productsCount product_id productsCount "product_id" productsCount index mergedData pd merge productsCount products how "left" on "product_id" sort_values by "count" ascending False fig ax plt subplots fig set_size_inches sn barplot data mergedData head "product_name" "count" ax ax orient "v" color Count ",title=" Best Selling Products plt xticks rotation mergedData head
520	labels_breed pd read_csv '../input/breed_labels.csv' labels_state pd read_csv '../input/color_labels.csv' labels_color pd read_csv '../input/state_labels.csv'
565	try tpu tf distribute cluster_resolver TPUClusterResolver print tpu master except ValueError tpu None if tpu tf config experimental_connect_to_cluster tpu tf tpu experimental initialize_tpu_system tpu strategy tf distribute experimental TPUStrategy tpu else strategy tf distribute get_strategy print "REPLICAS: " strategy num_replicas_in_sync
68	clear_output wait True print
664	import datetime START_DATE startdate datetime datetime strptime START_DATE df df apply lambda startdate datetime timedelta seconds df 'hour' df dt hour
498	import sys def return_size df return round sys getsizeof df 1e9 def convert_types df print_info False original_memory df memory_usage sum for in df if 'SK_ID' in df df fillna astype np int32 elif df dtype 'object' and df nunique df shape df df astype 'category' elif list df unique df df astype bool elif df dtype float df df astype np float32 elif df dtype int df df astype np int32 new_memory df memory_usage sum if print_info print f'Original Memory Usage: {round(original_memory / 1e9, 2)} gb.' print f'New Memory Usage: {round(new_memory / 1e9, 2)} gb.' return df
178	plt_st plt imshow complete_images plt title
440	space 'boosting_type' hp choice 'boosting_type' 'boosting_type' 'gbdt' 'subsample' hp uniform 'gdbt_subsample' 'boosting_type' 'dart' 'subsample' hp uniform 'dart_subsample' 'boosting_type' 'goss' 'subsample' 'num_leaves' hp quniform 'num_leaves' 'learning_rate' hp loguniform 'learning_rate' np log np log 'subsample_for_bin' hp quniform 'subsample_for_bin' 'min_child_samples' hp quniform 'min_child_samples' 'reg_alpha' hp uniform 'reg_alpha' 'reg_lambda' hp uniform 'reg_lambda' 'colsample_bytree' hp uniform 'colsample_by_tree' 'is_unbalance' hp choice 'is_unbalance' True False
331	def generate_word_cloud text wordcloud WordCloud width height background_color 'black' generate str text fig plt figure figsize facecolor 'k' edgecolor 'k' plt imshow wordcloud interpolation 'bilinear' plt axis 'off' plt tight_layout pad plt show
513	batch_size total_rows f_matrix_train shape duration start_train time time pos classes while duration and pos total_rows for in range if pos batch_size total_rows batch_size total_rows pos f_matrix_train pos pos batch_size y_p pos pos batch_size model partial_fit y_p classes pos pos batch_size duration time time start_train print pos total_rows duration
694	link_count np zeros len title_dic len title_dic dtype np int node_count np zeros len title_dic for in tqdm train index link_count train loc 'previous_title' train loc 'title' node_count train loc 'title'
126	def plot_cm y_true y_pred title figsize y_pred y_pred round astype int cm confusion_matrix y_true y_pred labels np unique y_true cm_sum np sum cm axis keepdims True cm_perc cm cm_sum astype float annot np empty_like cm astype str nrows ncols cm shape for in range nrows for in range ncols cm cm_perc if cm_sum annot '%.1f%%\n%d/%d' elif annot else annot '%.1f%%\n%d' cm pd DataFrame cm index np unique y_true columns np unique y_true cm index name cm columns name fig ax plt subplots figsize figsize plt title title sns heatmap cm cmap annot annot fmt ax ax
314	test_path_audio os path join test_path 'audio' test_filenames os listdir test_path_audio test_filenames np sort test_filenames list test_filenames
41	model compile optimizer 'adam' loss 'mean_squared_error' metrics 'mae' model fit batch_size epochs model fit batch_size epochs model fit batch_size epochs
858	sample_df pd read_csv SAMPLE sample_list list sample_df Id pred_dic dict key value for key value in zip learner data test_ds fnames pred_list pred_list_cor pred_dic id for id in sample_list df pd DataFrame sample_list pred_list_cor df to_csv 'protein_classification.csv' header True index False
125	tourney_win_result tourney_win_result tourney_win_result tourney_win_result tourney_win_result tourney_win_result tourney_lose_result tourney_lose_result tourney_lose_result tourney_lose_result tourney_lose_result tourney_lose_result
179	from PIL import Image import seaborn as sns def _get_image_data_pil image_id image_type return_exif_md False fname get_filename image_id image_type try img_pil Image open fname except Exception as assert False image_id image_type img np asarray img_pil assert isinstance img np ndarray image_id image_type if not return_exif_md return img else return img img_pil _getexif
672	def basic_model inp layers Input shape img_size img_size name 'inp' efnetb3 efn weights 'imagenet' include_top False efnetb3 inp output layers Dense activation 'sigmoid' model tf keras models Model inputs inp outputs output opt tf keras optimizers Adam learning_rate LR model compile optimizer opt loss binary_focal_loss gamma alpha metrics tf keras metrics BinaryAccuracy tf keras metrics AUC return model
441	sample space subsample 'boosting_type' get 'subsample' 'boosting_type' 'boosting_type' 'boosting_type' 'subsample' subsample
472	features_sample pd read_csv '../input/home-credit-default-risk-feature-tools/feature_matrix.csv' nrows features_sample features_sample features_sample 'set' 'train' features_sample head
827	sns catplot "store_id" "total_sales" hue "cat_id" data train_sales kind "bar" height aspect
19	n_train_rows n_train_cols train shape n_test_rows n_test_cols test shape print format train shape print format test shape print testing data examples format n_train_rows n_test_rows n_train_rows n_test_rows print train isnull sum sum print test isnull sum sum
406	all_equal train groupby 'idhogar' apply lambda nunique not_equal all_equal all_equal True print format len not_equal
360	def transpose_df df df df drop axis groupby sum df index pd to_datetime df index return df
458	previous pd read_csv '../input/previous_application.csv' replace np nan previous convert_types previous previous 'LOAN_RATE' previous 'AMT_ANNUITY' previous 'AMT_CREDIT' previous "AMT_DIFFERENCE" previous 'AMT_CREDIT' previous 'AMT_APPLICATION'
803	weight_df df 'weight' 'hospital_death' 'bmi' weight_df 'weight' weight_df 'weight' round weight_df 'bmi' weight_df 'bmi' round weight_death weight_df 'weight' 'hospital_death' groupby 'weight' mean reset_index bmi_death weight_df 'bmi' 'hospital_death' groupby 'bmi' mean reset_index fig make_subplots rows cols shared_yaxes True fig add_trace go Scatter weight_death 'weight' weight_death 'hospital_death' name row col fig add_trace go Scatter bmi_death 'bmi' bmi_death 'hospital_death' name "BMI" row col fig update_layout title_text fig update_yaxes title_text fig show
801	stats for Province in sorted full_table unique if Province continue df get_time_series_province Province if len df or max df continue print format Province opt_display_model df stats
551	FILENAME train_root train_df fname sample_mel processor createMel FILENAME CONFIG sample_mfcc processor createMfcc FILENAME CONFIG print sample_mel shape print sample_mfcc shape idx_cut plt imshow sample_mel idx_cut cmap plt title plt show plt imshow sample_mfcc idx_cut cmap plt title 'MFCC:' plt show print np min sample_mel np max sample_mel print np min sample_mfcc np max sample_mfcc
61	test_filenames os listdir "../input/test1/test1" test_df pd DataFrame 'filename' test_filenames nb_samples test_df shape
33	answer LABELS for in val_y pred np random random len val_X print 'random loss: ' str log_loss answer pred clip pred np array for in range len val_X print '1 loss: ' str log_loss answer pred pred np array for in range len val_X print '0 loss: ' str log_loss answer pred pred np array for in range len val_X print '0.5 loss: ' str log_loss answer pred
463	for in param_grid 'learning_rate' if and elif and print format print format
91	alldf for col in train cat1 train cat1 isnull False unique temp train cat2 train 'cat1' col temp pd DataFrame temp value_counts reset_index alldf col temp fig axs plt subplots figsize plt suptitle fontsize for cat in alldf temp alldf cat sns barplot 'cat2' 'index' data temp ax axs flatten axs flatten set_ylabel axs flatten set_xlabel
307	images_with_ship masks ImageId masks EncodedPixels isnull False images_with_ship np unique images_with_ship values print str len images_with_ship ' image files with masks'
158	VotingRegressor estimators 'lin' linreg 'ridge' ridge 'sgd' sgd fit train target acc_model train test
219	bold '**ELECTRICITY THE MOST FREQUENT METER TYPE MEASURED**' plt rcParams 'figure.figsize' ax sns countplot data train 'meter' palette alpha ax set_ylabel fontsize ax set_xlabel fontsize plt show
519	cred_card_bal pd read_csv "../input/credit_card_balance.csv" cred_card_bal cred_card_bal drop 'SK_ID_PREV' axis cred_card_bal_dfs feature_aggregator_on_df cred_card_bal aggs_cat aggs_num 'SK_ID_CURR' 'cred_card_balance' 'basic' save False
590	sample_image_path "../input/test/6beb79b52308112d.jpg" with tf Graph as_default image_string_placeholder tf placeholder tf string decoded_image tf image decode_jpeg image_string_placeholder decoded_image_float tf image convert_image_dtype image decoded_image dtype tf float32 image_tensor tf expand_dims decoded_image_float model_url "https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1" detector hub Module model_url detector_output detector image_tensor as_dict True init_ops tf global_variables_initializer tf tables_initializer sess tf Session sess run init_ops with tf gfile Open sample_image_path "rb" as binfile image_string binfile read result_out image_out sess run detector_output decoded_image feed_dict image_string_placeholder image_string
292	probs np concatenate probs result_df pd DataFrame 'row_id' names 'birds' probs for in range probs shape result_df result_df groupby 'row_id' 'birds' apply lambda np stack max reset_index result_df
582	train pd read_csv "../input/liverpool-ion-switching/train.csv" test pd read_csv "../input/liverpool-ion-switching/test.csv" sub pd read_csv "../input/liverpool-ion-switching/sample_submission.csv" dtype dict time str
777	data_dir '/kaggle/input/stanford-covid-vaccine/' train pd read_json data_dir 'train.json' lines True test pd read_json data_dir 'test.json' lines True sample_df pd read_csv data_dir 'sample_submission.csv'
684	X_COL "var_81" Y_COL "var_68" Z_COL "var_108" HUE_COL "target" N_SAMPLES df train_df sample N_SAMPLES
465	import altair as alt alt renderers enable 'notebook'
698	files folders path "/kaggle/input/osic-pulmonary-fibrosis-progression/test" for dirnames filenames in os walk path files len filenames folders len dirnames print "{:,} files/images, {:,} folders/patients" format files folders
870	plt figure figsize plt plot plot1 compute plot2 compute plt xlabel plt ylabel plt title "PLOT 0"
824	cols_to_drop 'V300' 'V309' 'V111' 'C3' 'V124' 'V106' 'V125' 'V315' 'V134' 'V102' 'V123' 'V316' 'V113' 'V136' 'V305' 'V110' 'V299' 'V289' 'V286' 'V318' 'V103' 'V304' 'V116' 'V29' 'V284' 'V293' 'V137' 'V295' 'V301' 'V104' 'V311' 'V115' 'V109' 'V119' 'V321' 'V114' 'V133' 'V122' 'V319' 'V105' 'V112' 'V118' 'V117' 'V121' 'V108' 'V135' 'V320' 'V303' 'V297' 'V120' print '{} features are going to be dropped for being useless' format len cols_to_drop train train drop cols_to_drop axis test test drop cols_to_drop axis del cols_to_drop gc collect
569	save_dir '/kaggle/tmp/fake/' if not os path exists save_dir os makedirs save_dir
361	from datetime import datetime lockdown confirmedT copy lockdown loc country_lockdown pd DataFrame datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime datetime index state_lockdown pd DataFrame 'US' datetime 'US' datetime 'US' datetime 'US' datetime 'US' datetime 'US' datetime 'US' datetime 'US' datetime index state_lockdown head
783	total train isnull sum sort_values ascending False percent train isnull sum train isnull count sort_values ascending False missing_train_data pd concat total percent axis keys
865	feature_matrix feature_defs ft dfs entityset es target_entity 'applications' drop_contains 'SK_ID_PREV' max_depth verbose True
740	print f"{ckpt_manager._directory}" os system f"ls -l {ckpt_manager._directory} > results.txt" with open "results.txt" "r" encoding "UTF-8" as fp for line in fp print line strip
834	patientId df print patient_class loc patientId plt figure figsize plt title draw parsed patientId
793	import seaborn as sns sns set sns FacetGrid pd melt df 'bone_length' 'rotting_flesh' 'hair_length' 'has_soul' 'type' id_vars 'type' col 'type' map sns boxplot 'value' 'variable'
171	model RandomForestRegressor max_depth random_state n_estimators embeded_rf_selector SelectFromModel model threshold '1.25*median' embeded_rf_selector fit dfe target_fe
811	proportion train 'device' 'is_attributed' groupby 'device' as_index False mean sort_values 'is_attributed' ascending False counts train 'device' 'is_attributed' groupby 'device' as_index False count sort_values 'is_attributed' ascending False merge counts merge proportion on 'device' how 'left' merge columns 'device' 'click_count' 'prop_downloaded' print print merge
239	train_df train_transaction merge train_identity how 'left' left_index True right_index True test_df test_transaction merge test_identity how 'left' left_index True right_index True print str train_df shape print str test_df shape
814	if False chunksize df_test_meta pd read_csv DATA_DIR 'test_set_metadata.csv' extras df_test_extras for chunk in tqdm_notebook pd read_csv DATA_DIR 'test_set.csv' chunksize chunksize first_id chunk head 'object_id' values last_id chunk tail 'object_id' values select chunk 'object_id' isin first_id last_id extras append chunk select copy mid_chunk chunk select sort_values 'object_id' 'mjd' copy if mid_chunk shape df_test_extras append calc_extra mid_chunk mid_chunk pd concat extras df_test_extras append calc_extra mid_chunk df_test_extra pd concat df_test_extras sort_values 'object_id' df_test_extra sample df_test_extra shape df_test_extra to_csv DATA_DIR 'test_extra.csv' index False
278	orderCount orders orders "eval_set" "prior" groupby by "user_id" "order_id" count to_frame fig ax plt subplots fig set_size_inches sn countplot color Order Count
137	def draw_category_images col_name figure_cols df IMAGE_PATH categories df groupby col_name col_name nunique index ax plt subplots nrows len categories ncols figure_cols figsize figure_cols len categories for cat in enumerate categories sample df df col_name cat sample figure_cols for in range figure_cols file IMAGE_PATH sample iloc 'id' '.tif' im cv2 imread file ax imshow im resample True cmap 'gray' ax set_title cat fontsize plt tight_layout plt show
699	def create_datagen return ImageDataGenerator zoom_range fill_mode 'constant' cval horizontal_flip True vertical_flip True data_generator create_datagen flow x_train y_train batch_size BATCH_SIZE seed
823	import os import sys sys path append "../input/pystacknet/repository/h2oai-pystacknet-af571e0" import pystacknet
427	def haversine_np lon1 lat1 lon2 lat2 lon1 lat1 lon2 lat2 map np radians lon1 lat1 lon2 lat2 dlon lon2 lon1 dlat lat2 lat1 np sin dlat np cos lat1 np cos lat2 np sin dlon np arcsin np sqrt km return km
277	fig ax plt subplots fig set_size_inches sn countplot color Reorder Count
366	fig axs plt subplots ncols figsize plt title sns kdeplot train 'landmark_id' color "tomato" shade True ax axs temp pd DataFrame train landmark_id value_counts head temp reset_index inplace True temp columns 'landmark_id' 'count' plt title sns set_color_codes "pastel" sns barplot "landmark_id" "count" data temp label ax axs temp pd DataFrame train landmark_id value_counts tail temp reset_index inplace True temp columns 'landmark_id' 'count' plt title sns set_color_codes "pastel" sns barplot "landmark_id" "count" data temp label ax axs plt show
417	model RandomForestClassifier n_estimators random_state n_jobs cv_score cross_val_score model train_set train_labels cv scoring scorer print f'10 Fold Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}'
64	train_data eval_data train_label eval_label train_test_split test_size random_state print train_data shape eval_data shape train_label shape eval_label shape
825	import lightgbm as lgb import xgboost as xgb from sklearn ensemble import RandomForestRegressor lgbclf lgb LGBMRegressor num_leaves n_estimators max_depth learning_rate subsample colsample_bytree boosting_type "gbdt" reg_alpha reg_lamdba metric "AUC" xgbclf xgb XGBRegressor n_estimators max_depth learning_rate subsample colsample_bytree missing tree_method 'gpu_hist' reg_alpha reg_lamdba rfclf RandomForestRegressor n_estimators max_depth max_features 'sqrt' random_state
204	from sklearn metrics import confusion_matrix confusion confusion_matrix yt yr_pred print confusion
620	valid_labels valid_df 'label' valid_datas valid_df drop 'label' axis values valid_datas valid_datas reshape valid_predictions np zeros len valid_datas num_classes for model_index model in enumerate model_members print str model_index '_model predicting' normal_generator InputGenerator valid_datas aug albu Compose training False batch_size aug_generator InputGenerator valid_datas aug tta_aug training False batch_size tta_model tta_wrapper model model normal_generator normal_generator aug_generator aug_generator repeats valid_predictions tta_model predict valid_predictions valid_predictions k_fold_split valid_predictions np argmax valid_predictions axis
365	train pd read_csv "../input/landmark-retrieval-2020/train.csv" def get_paths index_location index os listdir '../input/landmark-retrieval-2020/train/' paths index_location for in index for in index try paths extend f"../input/landmark-retrieval-2020/train/{a}/{b}/{c}/" for in os listdir f"../input/landmark-retrieval-2020/train/{a}/{b}/{c}" except pass return paths def show_sample pathes plt rcParams "axes.grid" False axarr plt subplots figsize axarr imshow cv2 imread pathes axarr imshow cv2 imread pathes axarr imshow cv2 imread pathes axarr imshow cv2 imread pathes axarr imshow cv2 imread pathes axarr imshow cv2 imread pathes axarr imshow cv2 imread pathes axarr imshow cv2 imread pathes axarr imshow cv2 imread pathes show_sample get_paths
769	new_feats for col in family_size_features new_col_name 'new_{}_per_{}' format 'rooms' col new_feats append new_col_name df_train new_col_name df_train 'rooms' df_train col df_test new_col_name df_test 'rooms' df_test col for col in new_feats df_train col replace np inf np nan inplace True df_train col fillna inplace True df_test col replace np inf np nan inplace True df_test col fillna inplace True
533	colname test_pub_in loc colname isin dates_intersect colname shape shape test_pub_not loc colname isin dates_intersect colname shape shape test_priv_in loc colname isin dates_intersect colname shape shape test_priv_not loc colname isin dates_intersect colname shape shape print 'test public and test private..' print 'based on: {}' format colname print 'fraction of public test dates intersection: {:.3f}' format test_pub_in print 'fraction of public test dates difference: {:.3f}' format test_pub_not print 'fraction of private test dates intersection: {:.3f}' format test_priv_in print 'fraction of private test dates difference: {:.3f}' format test_priv_not
382	bin_cols f'bin_{i}' for in range fig ax plt subplots figsize for col in enumerate bin_cols ax0 plt subplot raw_train col value_counts plot bar color 'pink' height sum get_height for in ax0 patches for in ax0 patches ax0 text get_x get_width get_height f'{100*p.get_height()/height:.2f} %' ha 'center' plt xlabel f'{col}' plt suptitle
581	if predict_submission print test pd read_json "../input/test.json" y_fin create_dataset test False print prediction common_model predict verbose batch_size print submission pd DataFrame 'id' test "id" 'is_iceberg' prediction reshape prediction shape submission to_csv "./submission.csv" index False print
182	def run_mp_build t0 time time num_proc NUM_THREADS pool mp Pool processes num_proc results pool apply_async build_fields args pid for pid in range NUM_THREADS output get for in results num_built sum output pool close pool join print num_built print time time t0
273	params 'bagging_fraction' 'feature_fraction' 'max_depth' int 'min_child_weight' 'min_data_in_leaf' int 'n_estimators' 'num_leaves' int 'reg_alpha' 'reg_lambda' 'metric' 'auc' 'boosting_type' 'gbdt' 'colsample_bytree' 'subsample' 'min_split_gain' 'max_bin' 'bagging_freq' 'learning_rate' 'early_stopping_rounds'
468	fig axs plt subplots figsize for hyper in enumerate 'colsample_bytree' 'learning_rate' 'min_child_samples' 'num_leaves' random_hyp hyper random_hyp hyper astype float sns regplot 'iteration' hyper data random_hyp ax axs axs scatter best_random_hyp 'iteration' best_random_hyp hyper marker 'k' axs set xlabel ylabel format hyper title format hyper plt tight_layout
105	def load_scan path slices dicom read_file path for in os listdir path slices sort key lambda int InstanceNumber try slice_thickness np abs slices ImagePositionPatient slices ImagePositionPatient except slice_thickness np abs slices SliceLocation slices SliceLocation for in slices SliceThickness slice_thickness return slices
198	best_n_clusters norm_feat MinMaxScaler fit_transform test_feat clt KMeans n_clusters best_n_clusters random_state RANDOM_SEED fit norm_feat test_clusters pd DataFrame clt labels_ columns 'cluster' index test_meta 'signal_id' stats_df test_clusters reset_index groupby 'cluster' count stats_df columns 'count' display stats_df
636	fig axs plt subplots figsize axs flatten sample train train sample iloc for mes_col err_col in enumerate zip mes_cols err_cols err np array sample err_col mes np array sample mes_col axs errorbar np arange mes yerr err color 'blue' ecolor 'red' drawstyle 'steps-mid' barsabove True axs set_title mes_col
831	seed random seed seed np random seed seed torch manual_seed seed torch backends cudnn deterministic True if torch cuda is_available torch cuda manual_seed_all seed
195	ix test_image ix astype float imshow test_image plt show
623	yhat if else for in yhat test_df 'label' yhat label_map dict for in train_generator class_indices items test_df 'label' test_df 'label' replace label_map test_df 'label' test_df 'label' replace 'dog' 'cat' test_df to_csv 'submission.csv' index False
536	shap_sum np abs shap_values mean axis importance_df pd DataFrame columns tolist shap_sum tolist importance_df columns 'column_name' 'shap_importance' importance_df importance_df sort_values 'shap_importance' ascending False importance_df
395	def classify_inception image_path img Image open image_path target_size if img size target_size img img resize target_size image img_to_array img np expand_dims axis inception_v3 preprocess_input preds inception_model predict return inception_v3 decode_predictions preds top def image_id_from_path path return path split split
474	train feature_matrix2 feature_matrix2 'set' 'train' test feature_matrix2 feature_matrix2 'set' 'test' train pd get_dummies train test pd get_dummies test train test train align test join 'inner' axis test test drop columns 'TARGET' print train shape print test shape
85	print str round total_before_opti 'GB' print str round sum df memory_usage 'GB' print str round total_before_opti sum df memory_usage total_before_opti
415	new_col for in ind_agg columns levels for stat in ind_agg columns levels new_col append f'{c}-{stat}' ind_agg columns new_col ind_agg head
274	aisles pd read_csv '../input/aisles.csv' departments pd read_csv '../input//departments.csv' orderProductsTrain pd read_csv '../input/order_products__train.csv' orders pd read_csv '../input/orders.csv' products pd read_csv '../input/products.csv' orderProductsPrior pd read_csv '../input/order_products__prior.csv'
24	learn unfreeze learn lr_find learn recorder plot suggestion True
145	shutil rmtree 'base_dir'
228	result step_size for in tqdm range int np ceil test shape result append np expm1 sum model predict test iloc step_size for model in models folds step_size
660	def add_lag_feature weather_df window group_df weather_df groupby 'site_id' cols 'air_temperature' 'cloud_coverage' 'dew_temperature' 'precip_depth_1_hr' 'sea_level_pressure' 'wind_direction' 'wind_speed' rolled group_df cols rolling window window min_periods lag_mean rolled mean reset_index astype np float16 lag_max rolled max reset_index astype np float16 lag_min rolled min reset_index astype np float16 lag_std rolled std reset_index astype np float16 for col in cols weather_df f'{col}_mean_lag{window}' lag_mean col weather_df f'{col}_max_lag{window}' lag_max col weather_df f'{col}_min_lag{window}' lag_min col weather_df f'{col}_std_lag{window}' lag_std col
651	leak_score0 leak_df pd read_pickle ucf_root 'site0.pkl' leak_df 'meter_reading' leak_df meter_reading_scraped leak_df drop 'meter_reading_original' 'meter_reading_scraped' axis inplace True leak_df fillna inplace True leak_df leak_df leak_df timestamp dt year leak_df loc leak_df meter_reading 'meter_reading' sample_submission loc sample_submission meter_reading 'meter_reading' for bid in leak_df building_id unique temp_df leak_df leak_df building_id bid for in temp_df meter unique v0 sample_submission loc test_df building_id bid test_df meter 'meter_reading' values v1 temp_df temp_df meter meter_reading values leak_score0 mean_squared_error np log1p v0 np log1p v1 len v0 sample_submission loc test_df building_id bid test_df meter 'meter_reading' temp_df temp_df meter meter_reading values leak_score0 len leak_df
704	train_df train_df apply lambda if str else train_df train_df apply lambda if str else test_df test_df apply lambda if str else test_df test_df apply lambda if str else
512	def makeFeatureVec words model num_features featureVec np zeros num_features dtype "float32" nwords index2word_set set model wv index2word for word in words if word in index2word_set nwords nwords featureVec np add featureVec model word if nwords nwords featureVec np divide featureVec nwords return featureVec def getAvgFeatureVecs reviews model num_features reviewFeatureVecs np zeros len reviews num_features dtype "float32" counter for review in reviews reviewFeatureVecs counter makeFeatureVec review model num_features counter counter return reviewFeatureVecs f_matrix_train getAvgFeatureVecs sentences_train model num_features f_matrix_test getAvgFeatureVecs sentences_test model num_features train 'toxic' train 'severe_toxic' train 'obscene' train 'threat' train 'insult' train 'identity_hate'
549	if not SKIP_VALIDATION cmdataset get_validation_dataset ordered True images_ds cmdataset map lambda image label image labels_ds cmdataset map lambda image label label unbatch cm_correct_labels next iter labels_ds batch NUM_VALIDATION_IMAGES numpy model predict images_ds m2 model2 predict images_ds scores for alpha in np linspace cm_probabilities alpha alpha m2 cm_predictions np argmax cm_probabilities axis scores append f1_score cm_correct_labels cm_predictions labels range len CLASSES average 'macro' print cm_correct_labels shape cm_correct_labels print cm_predictions shape cm_predictions plt plot scores best_alpha np argmax scores cm_probabilities best_alpha best_alpha m2 cm_predictions np argmax cm_probabilities axis else best_alpha
73	print print df 'is_attributed' value_counts plt figure figsize plt title fontsize ax df 'is_attributed' value_counts normalize True plot kind 'bar' for in ax patches ax annotate '{:.2f}%' format get_height get_x get_height
59	sample random choice filenames image load_img "../input/train/train/" sample plt imshow image
422	train fillna inplace True train replace np inf inplace True train replace np inf inplace True test fillna inplace True test replace np inf inplace True test replace np inf inplace True
580	fig plt figure figsize random_indicies np random choice range len False subset random_indicies for in range ax fig add_subplot ax imshow subset plt show
695	plt figure figsize sns heatmap link_count plt show
451	threshold corr_matrix train corr abs corr_matrix head
429	y_train y_valid train_test_split data np array data 'fare_amount' stratify data 'fare-bin' random_state RSEED test_size
426	nyc_map_zoom plt imread
826	replace np inf replace np inf replace np inf replace np inf from sklearn ensemble import RandomForestRegressor rf RandomForestRegressor rf fit y_train feature_cols columns values tolist feature_imp sorted zip map lambda round rf feature_importances_ feature_cols reverse True print feature_imp del rf
731	checkpoint_path os path join FLAGS input_checkpoint_dir FLAGS model_name ckpt tf train Checkpoint model bert_nq ckpt_manager tf train CheckpointManager ckpt checkpoint_path max_to_keep if ckpt_manager latest_checkpoint ckpt restore ckpt_manager latest_checkpoint last_epoch int ckpt_manager latest_checkpoint split print f'Latest BertNQ checkpoint restored -- Model trained for {last_epoch} epochs' else print last_epoch print ckpt_manager _directory ckpt_manager _directory os path join FLAGS output_checkpoint_dir FLAGS model_name ckpt_manager _checkpoint_prefix os path join ckpt_manager _directory "ckpt" print ckpt_manager _directory from tensorflow python lib io file_io import recursive_create_dir recursive_create_dir ckpt_manager _directory
1	def get_test_transforms mode if mode return Compose Resize height width elif mode return Compose HorizontalFlip Resize height width elif mode return Compose VerticalFlip Resize height width else return Compose HorizontalFlip VerticalFlip Resize height width
22	def seed_everything seed random seed seed os environ 'PYTHONHASHSEED' str seed np random seed seed torch manual_seed seed torch cuda manual_seed seed torch backends cudnn deterministic True seed_everything
181	VotingRegressor estimators 'lin' linreg 'ridge' ridge 'sgd' sgd fit train target acc_model train test
447	hyperparameters dict bayes_results loc 'hyperparameters' del hyperparameters 'n_estimators' cv_results lgb cv hyperparameters train_set num_boost_round early_stopping_rounds metrics 'auc' nfold N_FOLDS print format cv_results 'auc-mean' cv_results 'auc-stdv' print format len cv_results 'auc-mean'
560	colors vtk vtkNamedColors bkg map lambda colors SetColor bkg
109	def show_dataset thumb_size cols rows ds mosaic PIL Image new mode 'RGB' size thumb_size cols cols thumb_size rows rows for idx data in enumerate iter ds img target_or_imgid data ix idx cols iy idx cols img np clip img numpy astype np uint8 img PIL Image fromarray img img img resize thumb_size thumb_size resample PIL Image BILINEAR mosaic paste img ix thumb_size ix iy thumb_size iy display mosaic ds get_dataset files_train CFG unbatch take show_dataset ds
320	df_covid 'country' df_covid 'country' replace df_covid
846	seed_everything glove_embeddings load_glove word_index paragram_embeddings load_para word_index fasttext_embeddings load_fasttext word_index embedding_matrix np mean glove_embeddings paragram_embeddings fasttext_embeddings axis del glove_embeddings paragram_embeddings fasttext_embeddings gc collect np shape embedding_matrix
758	test test groupby transform 'min' base test loc test Weeks test base base 'FVC' copy base columns test test merge base on how 'left' test test test
850	tst_leak pd read_csv '../input/breaking-lb-fresh-start-with-lag-selection/test_leak.csv' test 'leak' tst_leak 'compiled_leak' test 'log_leak' np log1p tst_leak 'compiled_leak'
759	convert_path './convert_dir' if not os path isdir convert_path os mkdir convert_path else pass for in os listdir sample_path if 'dcm' ds pydicom read_file sample_path img ds pixel_array cv2 imwrite convert_path replace '.dcm' '.png' img os listdir convert_path
840	def are_two_images_equals if tuple shape tuple shape if np abs all return True return False def is_solution program task verbose True for sample in task np array sample 'input' np array sample 'output' images evaluate program if len images return False images images is_program_of_for_sample any are_two_images_equals for in images if not is_program_of_for_sample return False return True program groupByColor cropToContent print program_desc program "is a solution of the task:" is_solution program task 'train'
121	fig ax1 ax2 plt subplots figsize y1 all_data all_data country_dict all_data all_data x1 range len y1 ax1 plot x1 y1 'bo--' ax1 set_title ax1 set_xlabel ax1 set_ylabel y2 all_data all_data country_dict all_data all_data apply lambda np log x2 range len y2 ax2 plot x2 y2 'bo--' ax2 set_title ax2 set_xlabel ax2 set_ylabel
506	from PIL import Image print format len face_locations for face_location in face_locations face_location print format face_image image fig ax plt subplots figsize plt grid False ax xaxis set_visible False ax yaxis set_visible False ax imshow face_image
388	dff df df price df price price_log np log dff price out bins pd cut price_log bins retbins True labels False plt figure figsize ax sns distplot price_log axlabel plt title plt vlines bins color 'g' ymin ymax alpha plt show
488	new_corrs for col in columns corr train 'TARGET' corr train col new_corrs append col corr
240	import pandas as pd import numpy as np from sklearn model_selection import StratifiedKFold from sklearn import metrics import gc import xgboost as xgb pd set_option 'display.max_columns'
692	train_sentences data_train 'comment_text' values tolist test_sentences data_test 'comment_text' values tolist total_ copy deepcopy train_sentences total_ extend test_sentences print len train_sentences print len test_sentences print len total_ for in tqdm range len total_ total_ str total_ lower
790	def get_mask_type mask border outer np zeros border border np float32 outer cv2 copyMakeBorder outer border border border border borderType cv2 BORDER_CONSTANT value cover mask sum if cover return if cover mask outer sum return if np all mask mask return percentage cover if percentage return elif percentage return elif percentage return elif percentage return else return def histcoverage coverage histall np zeros for in coverage histall return histall train_df "coverage" train_df masks map np sum pow img_size_target train_df "coverage_class" train_df masks map get_mask_type
732	if FLAGS do_valid validation_features tf train Example FromString numpy for in tf data TFRecordDataset valid_tf_record valid_predictions_json get_prediction_json mode 'valid' max_nb_pos_logits FLAGS n_best_size
308	dict_images list bboxes_dict keys for in range image dict_images fig ax1 ax2 ax3 plt subplots figsize img_0 cv2 imread train_image_dir image rle_0 masks query image mask_0 masks_as_image rle_0 img_1 img_0 copy bboxs bboxes_dict image for bbox in bboxs cv2 rectangle img_1 bbox bbox bbox bbox ax1 imshow img_0 ax2 imshow mask_0 cmap 'gray' ax3 imshow img_1 plt show
119	def calculate_trend df lag_list column for lag in lag_list trend_column_lag column str lag df trend_column_lag df column df column shift lag fill_value df column shift lag fill_value return df def calculate_lag df lag_list column for lag in lag_list column_lag column str lag df column_lag df column shift lag fill_value return df ts time time all_data calculate_lag all_data range all_data calculate_lag all_data range all_data calculate_trend all_data range all_data calculate_trend all_data range all_data replace np inf np inf inplace True all_data fillna inplace True print time time ts
53	base_df pd read_csv "/kaggle/input/covid19-global-forecasting-week-2/train.csv" base_df base_df rename "state" "country" axis base_df loc base_df "state" isna "state" scoring_dates test unique
15	plt figure figsize plt hist np log train_df columns_to_use values flatten bins plt title plt xlabel plt ylabel plt show
122	linear_svr LinearSVR linear_svr fit train target acc_model linear_svr train test
301	combined_aug Compose transforms GaussianTargetNoise gaus_std TemporalFlip
343	def check_missing_values df if df isnull any any print else print check_missing_values train_df check_missing_values test_df
210	val_size int strain shape val_idxs np random choice strain index values val_size replace False train_idxs np setdiff1d strain index values val_idxs train_pool Pool strain loc train_idxs train_cols strain loc train_idxs 'sales' cat_features cat_cols val_pool Pool strain loc val_idxs train_cols strain loc val_idxs 'sales' cat_features cat_cols del strain gc collect
433	plt figure figsize for grouped in data groupby sns kdeplot grouped 'fare_amount' label f'{d}' plt title
20	for col_name_pretty col_name_official figsize in zip 'passenger count' 'store and forward flag' 'passenger_count' 'vendor_id' 'store_and_fwd_flag' ax pd DataFrame col_name_pretty capitalize ' (train)' train col_name_official value_counts train col_name_official value_counts sum col_name_pretty capitalize ' (test)' test col_name_official value_counts test col_name_official value_counts sum plot barh figsize figsize legend 'reverse' rot stacked False color COLOR_YELLOW COLOR_DARK ax set xlabel ylabel ax set_title col_name_pretty fontsize
667	def create_gdf df gdf df copy gdf list zip gdf gdf gdf Coordinates gdf Coordinates apply Point gdf gpd GeoDataFrame gdf geometry crs 'init' 'epsg:4326' return gdf train_gdf create_gdf train world gpd read_file gpd datasets get_path 'naturalearth_lowres' ax world plot color 'white' edgecolor 'black' train_gdf plot ax ax color 'red' plt show
852	def create_video image_list out_file height width image_list shape fourcc cv2 'X264' fps video cv2 VideoWriter out_file fourcc fps width height False for im in image_list video write im astype np uint8 cv2 destroyAllWindows video release
715	rooms train "num_room" "price_doc" groupby "num_room" aggregate np mean reset_index mplt scatter rooms num_room rooms price_doc mplt xlabel mplt ylabel
298	fig ax plt subplots fig set_size_inches sn boxplot "roomcnt" "logerror" data mergedFiltered ax ax color Room Count ",title=" Room Count Vs Log Error
156	df_results pd DataFrame 'id' df_test id 'toxic' preds 'severe_toxic' preds 'obscene' preds 'threat' preds 'insult' preds 'identity_hate' preds set_index 'id' df_results df_results 'toxic' 'severe_toxic' 'obscene' 'threat' 'insult' 'identity_hate' df_results to_csv 'kaggle_submission.csv' columns 'toxic' 'severe_toxic' 'obscene' 'threat' 'insult' 'identity_hate'
833	patientId df print patient_class loc patientId plt figure figsize plt title draw parsed patientId
428	corrs data corr corrs 'fare_amount' plot bar color 'b' plt title
830	cal calendar 'd' 'wday' 'month' 'year' cal cal rename columns 'd' 'index' hobbies_state train_sales loc train_sales 'cat_id' 'HOBBIES' groupby 'state_id' sum hobbies_state hobbies_state reset_index hobbies_state pd merge hobbies_state cal on 'index' household_state train_sales loc train_sales 'cat_id' 'HOUSEHOLD' groupby 'state_id' sum household_state household_state reset_index household_state pd merge household_state cal on 'index' foods_state train_sales loc train_sales 'cat_id' 'FOODS' groupby 'state_id' sum foods_state foods_state reset_index foods_state pd merge foods_state cal on 'index'
230	bold display df_train head bold display df_test head
615	task_num np random randint arc task_num arc plot_task image np array train_tasks task_num 'train' 'input' arc identify_object image method arc plot_identified_objects arc identified_objects
490	def count_categorical df group_var df_name categorical pd get_dummies df select_dtypes 'object' categorical group_var df group_var categorical categorical groupby group_var agg 'sum' 'mean' column_names for var in categorical columns levels for stat in 'count' 'count_norm' column_names append '%s_%s_%s' df_name var stat categorical columns column_names return categorical
404	pd options display max_columns train pd read_csv '../input/train.csv' test pd read_csv '../input/test.csv' train head
502	credit pd read_csv '../input/credit_card_balance.csv' credit convert_types credit print_info True credit head
148	submission pd DataFrame 'id' image_id 'label' y_pred set_index 'id' submission to_csv 'patch_preds.csv' columns 'label'
99	wc WordCloud background_color "white" max_words stopwords STOPWORDS max_font_size wc generate join str for in train item_description values plt figure figsize plt axis 'off' plt imshow wc interpolation 'bilinear'
545	import cv2 def load_scans patient basepath "../input/osic-pulmonary-fibrosis-progression/train/" dcm_path basepath patient slices dcmread dcm_path file for file in os listdir dcm_path slices sort key lambda float InstanceNumber return slices def resize_array pixel_array return cv2 resize pixel_array dsize interpolation cv2 INTER_CUBIC def transform_to_hu slices images np stack resize_array file pixel_array for file in slices images images astype np int16 for in range len slices intercept slices RescaleIntercept slope slices RescaleSlope if slope images slope images astype np float64 images images astype np int16 images np int16 intercept return np array images dtype np int16 slices load_scans patient pixels transform_to_hu slices
574	img cv2 imread f'../input/train/{label_df.loc[0,"Image"]}' pad_width get_pad_width img max img shape padded np pad img pad_width pad_width mode 'constant' constant_values resized cv2 resize padded plt imshow resized
751	def generate_date_features input_data pd DataFrame date_col str use_col_name bool True inplace bool False pd DataFrame if inplace data_frame input_data else data_frame input_data copy if use_col_name new_col_name f'{date_col}_' else new_col_name data_frame date_col pd to_datetime data_frame date_col data_frame f'{new_col_name}year' data_frame date_col dt year data_frame f'{new_col_name}month' data_frame date_col dt month data_frame f'{new_col_name}day' data_frame date_col dt day data_frame f'{new_col_name}weeknum' data_frame date_col dt weekofyear data_frame f'{new_col_name}dayofweek' data_frame date_col dt dayofweek data_frame f'{new_col_name}quarter' data_frame date_col dt quarter return data_frame
13	embeddings_train for in tqdm range embeddings embed train_text embeddings_train append embeddings
330	import numpy as np import pandas as pd pd set_option 'display.max_colwidth' import os for dirname filenames in os walk '/kaggle/input' for filename in filenames print os path join dirname filename
363	totalcases totaldeaths mortality percentincrease casesperday deathsperday for region in list_regions italy2 italy italy 'denominazione_regione' region totalcases append italy2 'totale_casi' totaldeaths append italy2 'deceduti' mortality append italy2 'deceduti' italy2 'totale_casi' percentincrease append italy2 'totale_casi' pct_change rolling mean casesperday append italy2 'totale_casi' diff deathsperday append italy2 'deceduti' diff
611	directory '/kaggle/input/tensorflow2-question-answering/' test_path directory 'simplified-nq-test.jsonl' test build_test test_path submission pd read_csv "../input/tensorflow2-question-answering/sample_submission.csv" test head
728	PRETRAINED_MODELS "BERT" 'bert-base-uncased' 'bert-large-uncased' 'bert-base-cased' 'bert-large-cased' 'bert-base-multilingual-uncased' 'bert-base-multilingual-cased' 'bert-base-chinese' 'bert-base-german-cased' 'bert-large-uncased-whole-word-masking' 'bert-large-cased-whole-word-masking' 'bert-large-uncased-whole-word-masking-finetuned-squad' 'bert-large-cased-whole-word-masking-finetuned-squad' 'bert-base-cased-finetuned-mrpc' "DISTILBERT" 'distilbert-base-uncased' 'distilbert-base-uncased-distilled-squad'
635	fig axs plt subplots figsize axs flatten for mes_col in enumerate mes_cols mess np array train train mes_col values tolist for mes in mess axs plot mes color 'black' alpha zorder mess_avg mess mean axis mess_std mess std axis axs errorbar np arange mess_avg yerr mess_std color 'lime' ecolor 'yellow' drawstyle 'steps-mid' axs set_ylim axs set_title err_col
153	train_path 'base_dir/train_dir' val_path 'base_dir/val_dir' num_train_samples len df_train num_val_samples len df_val train_batch_size val_batch_size train_steps np ceil num_train_samples train_batch_size val_steps np ceil num_val_samples val_batch_size
104	def render_neato format 'png' dpi subprocess Popen 'neato' '-T' format '-o' '/dev/stdout' format dpi stdout subprocess PIPE stdin subprocess PIPE image communicate bytes encoding 'utf-8' return image
564	def get_pad_width im new_shape is_rgb True pad_diff new_shape im shape new_shape im shape math floor pad_diff math ceil pad_diff math floor pad_diff math ceil pad_diff if is_rgb pad_width else pad_width return pad_width
420	model RandomForestClassifier max_depth None n_estimators model fit train_selected train_labels estimator_nonlimited model estimators_ export_graphviz estimator_nonlimited out_file 'tree_nonlimited.dot' feature_names train_selected columns class_names 'extreme' 'moderate' 'vulnerable' 'non-vulnerable' rounded True proportion False precision
812	proportion train 'channel' 'is_attributed' groupby 'channel' as_index False mean sort_values 'is_attributed' ascending False counts train 'channel' 'is_attributed' groupby 'channel' as_index False count sort_values 'is_attributed' ascending False merge counts merge proportion on 'channel' how 'left' merge columns 'channel' 'click_count' 'prop_downloaded' ax merge plot secondary_y 'prop_downloaded' plt title ax set ylabel plt ylabel plt show print print merge
602	train_resized_imgs test_resized_imgs for image_id in label_df 'id' train_resized_imgs append pad_and_resize image_id 'train' for image_id in submission_df test_resized_imgs append pad_and_resize image_id 'test'
213	import pandas as pd import numpy as np import re import warnings warnings filterwarnings "ignore" import matplotlib pyplot as plt import seaborn as sns from sklearn feature_extraction text import CountVectorizer from sklearn feature_extraction text import TfidfVectorizer from wordcloud import WordCloud from nltk corpus import stopwords from nltk tokenize import word_tokenize from nltk stem snowball import SnowballStemmer from sklearn model_selection import train_test_split from sklearn multiclass import OneVsRestClassifier from sklearn linear_model import SGDClassifier from sklearn linear_model import LogisticRegression from sklearn import metrics from sklearn metrics import f1_score precision_score recall_score
89	import pandas as pd def analyze_image im_path im_id im_path parts im imageio imread str im_path im_gray rgb2gray im thresh_val threshold_otsu im_gray mask np where im_gray thresh_val if np sum mask np sum mask mask np where mask labels nlabels ndimage label mask labels nlabels ndimage label mask im_df pd DataFrame for label_num in range nlabels label_mask np where labels label_num if label_mask flatten sum rle rle_encoding label_mask pd Series im_id rle im_df im_df append ignore_index True return im_df def analyze_list_of_images im_path_list all_df pd DataFrame for im_path in im_path_list im_df analyze_image im_path all_df all_df append im_df ignore_index True return all_df
650	target_meter y_train create_X_y train_df target_meter target_meter y_valid_pred_total np zeros shape gc collect print 'target_meter' target_meter shape cat_features columns get_loc cat_col for cat_col in category_cols print 'cat_features' cat_features models0 for train_idx valid_idx in kf split y_train train_data iloc train_idx y_train train_idx valid_data iloc valid_idx y_train valid_idx print 'train' len train_idx 'valid' len valid_idx model y_pred_valid log fit_lgbm train_data valid_data cat_features category_cols num_rounds num_rounds lr bf y_valid_pred_total valid_idx y_pred_valid models0 append model gc collect if debug break sns distplot y_train sns distplot y_valid_pred_total oof0 mean_squared_error y_train y_valid_pred_total oof_total oof0 len y_train del y_train gc collect
199	from sklearn tree import DecisionTreeClassifier dt DecisionTreeClassifier dt dt fit xT yT
710	yhat model predict testX yhat_inverse scaler inverse_transform yhat reshape testY_inverse scaler inverse_transform testY reshape
35	import random real fake for in zip paths if real append else fake append fake random sample fake len real paths for in real paths append append for in fake paths append append
287	data "created" pd to_datetime data "created" data "hour" data "created" dt hour fig ax1 ax2 plt subplots nrows fig set_size_inches sn countplot "hour" data data ax ax1 data1 data groupby 'hour' 'interest_level' 'hour' count unstack 'interest_level' fillna data1 'low' 'medium' "high" plot kind 'bar' stacked True ax ax2
642	zone_dict def set_localtime df for sid zone in zone_dict items sids df site_id sid df loc sids 'timestamp' df sids timestamp pd offsets Hour zone
375	df df ix
859	import numpy as np import pandas as pd from sklearn import model_selection preprocessing metrics import matplotlib pyplot as plt import seaborn as sns pd set_option 'display.width' pd set_option 'display.max_rows' pd set_option 'display.max_columns' df_train pd read_csv '../input/train.csv' df_test pd read_csv '../input/test.csv'
628	of 'toxic' mybest toxic values of toxic values score1 roc_auc_score mybest toxic round astype int of toxic values score2 roc_auc_score of toxic round astype int mybest toxic values print '%2.4f\t%2.4f' score1 score2 print of head of to_csv 'submission.csv' index False
883	def display_host_sample host n_images jumps cams list sorted image_df 'cam' unique fig axs plt subplots n_images len cams figsize len cams n_images sharex True sharey True gridspec_kw 'wspace' 'hspace' for in range n_images for cam in enumerate cams if axs set_title cam mask1 image_df cam cam mask2 image_df host host image_path image_df mask1 mask2 image_path image_path sort_values 'timestamp' 'filename' iloc jumps img cv2 imread BASE_PATH '/train_' image_path img cv2 cvtColor img cv2 COLOR_BGR2RGB img cv2 resize img axs imshow img axs axis 'off'
579	clf xgb XGBClassifier grid best_params_ clf fit y_train sample_submission clf predict_proba sample_submission to_csv 'simple_xgboost.csv'
100	train 'coms_length' train 'item_description' str len pd options display float_format '{:.2f}' format train 'coms_length' describe
749	clf RandomForestClassifier n_estimators criterion 'gini' max_depth min_samples_split min_samples_leaf min_weight_fraction_leaf max_features 'auto' max_leaf_nodes None min_impurity_decrease min_impurity_split None bootstrap True oob_score False n_jobs random_state verbose warm_start False class_weight 'balanced'
202	from sklearn ensemble import RandomForestClassifier rfc RandomForestClassifier n_estimators n_jobs random_state rfc fit
521	train_breed_main train_proc merge labels_breed how 'left' left_on right_on suffixes '_main_breed' train_breed_main train_breed_main iloc train_breed_main train_breed_main add_prefix 'main_breed_' train_breed_second train_proc merge labels_breed how 'left' left_on right_on suffixes '_second_breed' train_breed_second train_breed_second iloc train_breed_second train_breed_second add_prefix 'second_breed_' train_proc pd concat train_proc train_breed_main train_breed_second axis test_breed_main test_proc merge labels_breed how 'left' left_on right_on suffixes '_main_breed' test_breed_main test_breed_main iloc test_breed_main test_breed_main add_prefix 'main_breed_' test_breed_second test_proc merge labels_breed how 'left' left_on right_on suffixes '_second_breed' test_breed_second test_breed_second iloc test_breed_second test_breed_second add_prefix 'second_breed_' test_proc pd concat test_proc test_breed_main test_breed_second axis print train_proc shape test_proc shape
54	for feat in tqdm features lbl_enc preprocessing LabelEncoder all_df feat lbl_enc fit_transform all_df feat fillna astype str values all_df 'target' all_df 'target' fillna all_df continuous all_df continuous fillna
146	test_path 'test_dir' test_gen datagen flow_from_directory test_path target_size IMAGE_SIZE IMAGE_SIZE batch_size class_mode 'categorical' shuffle False
543	plt style use 'default' plt rcParams 'figure.figsize' N_COLS N_ROWS fig ax plt subplots N_COLS N_ROWS for in range N_COLS for in range N_ROWS ridx np random randint len valid_df img_row valid_df iloc ridx img_filename img_row 'image_filename' pet_id img_row pet_label img_row image valid_parser load_image img_filename preprocess False ax imshow image ax set_title format pet_id pet_label size
599	for folder in 'train' 'test' os makedirs folder
249	from keras preprocessing text import Tokenizer docs "it was the worst of times" "it was the age of wisdom" "it was the age of foolishness" tokenizer Tokenizer tokenizer fit_on_texts docs
557	import numpy as np import pandas as pd import time from sklearn preprocessing import Imputer from sklearn preprocessing import RobustScaler import seaborn as sns import matplotlib pyplot as plt import warnings warnings filterwarnings "ignore" import xgboost as xgb from sklearn import preprocessing import os print os listdir "../input"
683	preds clf predict_proba clipped_preds np clip preds df_sample_sub Pred clipped_preds
755	from sklearn model_selection import train_test_split params 'n_estimators' 'max_depth' 'min_child_weight' 'subsample' 'gamma' 'objective' 'reg:linear' 'colsample_bytree' 'nthread' 'silent' 'seed' train test train_test_split x_train test_size predictors df 'feature' df 'fscore' tolist
23	sz bs tfms get_transforms do_flip False flip_vert False max_rotate max_zoom max_lighting
170	lsvr LinearSVR max_iter fit dfe target_fe model SelectFromModel lsvr prefit True model transform dfe pd DataFrame columns dfe columns for in range len dfe columns if model get_support shape
805	data np array tolist random_state y_train y_test train_test_split data test_size random_state random_state stratify pd DataFrame columns data columns pd DataFrame columns data columns
794	from sklearn linear_model import LogisticRegression lr LogisticRegression penalty 'l2' class_weight "balanced" lr fit y_train y_pred lr predict print classification_report y_pred y_test
774	for col1 in 'lugar1' 'lugar2' 'lugar3' 'lugar4' 'lugar5' 'lugar6' for col2 in 'instlevel1' 'instlevel2' 'instlevel3' 'instlevel4' 'instlevel5' 'instlevel6' 'instlevel7' 'instlevel8' 'instlevel9' new_col_name 'new_{}_x_{}' format col1 col2 df_train new_col_name df_train col1 df_train col2 df_test new_col_name df_test col1 df_test col2
397	plt figure figsize ax sns distplot train max kde False norm_hist False bins ax sns distplot test max kde False norm_hist False bins plt xlim left right 1e9 ax set_xlabel ax set_ylabel ax set_title ax legend
495	def agg_numeric df parent_var df_name for col in df if col parent_var and 'SK_ID' in col df df drop columns col parent_ids df parent_var copy numeric_df df select_dtypes 'number' copy numeric_df parent_var parent_ids agg numeric_df groupby parent_var agg 'count' 'mean' 'max' 'min' 'sum' columns for var in agg columns levels if var parent_var for stat in agg columns levels columns append '%s_%s_%s' df_name var stat agg columns columns idx np unique agg axis return_index True agg agg iloc idx return agg
718	class Net nn Module def __init__ self num_classes super __init__ self model EfficientNet from_name 'efficientnet-b0' self dense_output nn Linear num_classes def forward self feat self model extract_features feat avg_pool2d feat feat size reshape return self dense_output feat
491	import gc gc enable del train bureau bureau_balance bureau_agg bureau_agg_new bureau_balance_agg bureau_balance_counts bureau_by_loan bureau_balance_by_client bureau_counts gc collect
591	sample_submission_df pd read_csv '../input/sample_submission.csv' image_ids sample_submission_df predictions for image_id in tqdm image_ids image_path f'../input/test/{image_id}.jpg' with tf gfile Open image_path "rb" as binfile image_string binfile read result_out sess run detector_output feed_dict image_string_placeholder image_string predictions append format_prediction_string image_id result_out sess close
752	corr_df pd DataFrame columns 'feature' 'pearson' 'kendall' 'spearman' corr macro_df macro_columns corr method 'spearman' fig ax plt subplots figsize sns heatmap corr annot True linewidths ax ax
454	def agg_categorical df parent_var df_name categorical pd get_dummies df select_dtypes 'category' categorical parent_var df parent_var categorical categorical groupby parent_var agg 'sum' 'count' 'mean' column_names for var in categorical columns levels for stat in 'sum' 'count' 'mean' column_names append '%s_%s_%s' df_name var stat categorical columns column_names idx np unique categorical axis return_index True categorical categorical iloc idx return categorical
166	def my_generator for in range yield print my_gen my_generator
6	plt figure figsize plt hist train target values bins plt title plt xlabel plt ylabel plt show
342	print model Sequential model add Embedding nb_words embed_dim weights embedding_matrix input_length max_seq_len trainable False model add num_filters activation 'relu' padding 'same' model add model add num_filters activation 'relu' padding 'same' model add model add Dropout model add Dense activation 'relu' kernel_regularizer regularizers l2 weight_decay model add Dense num_classes activation 'sigmoid' adam optimizers Adam lr beta_1 beta_2 epsilon 1e-08 decay model compile loss 'binary_crossentropy' optimizer adam metrics 'accuracy' model summary
838	def lift fct def lifted_function xs list_of_results fct for in xs return list itertools chain list_of_results import re lifted_function __name__ re sub '_unlifted$' '_lifted' fct __name__ return lifted_function cropToContent lift cropToContent_unlifted groupByColor lift groupByColor_unlifted splitH lift splitH_unlifted negative lift negative_unlifted
657	scores np zeros for in range leak_df 'pred1' values leak_df 'pred3' values vl1p np log1p scores np sqrt mean_squared_error vl1p leak_df meter_reading_l1p
575	train_resized_imgs test_resized_imgs for image_path in label_df train_resized_imgs append pad_and_resize image_path 'train' for image_path in submission_df test_resized_imgs append pad_and_resize image_path 'test'
587	train1 pd read_csv "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv" train2 pd read_csv "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv" train2 toxic train2 toxic round astype int valid pd read_csv '/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv' test pd read_csv '/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv' sub pd read_csv '/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv'
300	class GaussianTargetNoise object def __init__ self float gaus_std float self self gaus_std gaus_std def __call__ self x_arr y_arr atten_arr if np random binomial self y_arr y_arr np random normal scale self gaus_std size y_arr shape return x_arr y_arr atten_arr
739	checkpoint_path os path join FLAGS input_checkpoint_dir FLAGS model_name ckpt tf train Checkpoint model bert_nq ckpt_manager tf train CheckpointManager ckpt checkpoint_path max_to_keep if ckpt_manager latest_checkpoint ckpt restore ckpt_manager latest_checkpoint last_epoch int ckpt_manager latest_checkpoint split print f'Latest BertNQ checkpoint restored -- Model trained for {last_epoch} epochs' else print last_epoch print ckpt_manager _directory ckpt_manager _directory os path join FLAGS output_checkpoint_dir FLAGS model_name ckpt_manager _checkpoint_prefix os path join ckpt_manager _directory "ckpt" print ckpt_manager _directory from tensorflow python lib io file_io import recursive_create_dir recursive_create_dir ckpt_manager _directory
617	import tensorflow as tf from sklearn metrics import confusion_matrix accuracy_score classification_report import seaborn as sn import albumentations as albu from sklearn model_selection import train_test_split KFold from tqdm import tqdm_notebook import gc import os import warnings warnings filterwarnings 'ignore' main_dir tf keras __version__
729	def jsonl_iterator jsonl_files to_json False for file_path in jsonl_files with open file_path "r" encoding "UTF-8" as fp for jsonl in fp raw_example jsonl if to_json raw_example json loads jsonl yield raw_example creator TFExampleCreator is_training False nq_lines jsonl_iterator FLAGS predict_file creator process_nq_lines nq_lines nq_lines output_tfrecord FLAGS test_tf_record max_examples collect_nq_features False
409	heads 'walls' np argmax np array heads 'epared1' 'epared2' 'epared3' axis plot_categoricals 'walls' heads
788	def gini actual pred cmpcol sortcol assert len actual len pred all np asarray np c_ actual pred np arange len actual dtype np float all all np lexsort all all totalLosses all sum giniSum all cumsum sum totalLosses giniSum len actual return giniSum len actual def gini_normalized return gini gini def gini_xgb preds dtrain labels dtrain get_label gini_score gini_normalized labels preds return 'gini' gini_score
351	date_agg_1 train_agg groupby level agg 'sum' date_agg_1 columns 'bookings' 'total' date_agg_1 head
566	def decode_image filename label None image_size bits tf io read_file filename image tf image decode_jpeg bits channels image tf cast image tf float32 image tf image resize image image_size if label is None return image else return image label def data_augment image label None image tf image random_flip_left_right image image tf image random_flip_up_down image if label is None return image else return image label
196	sns set_style "whitegrid" func lambda df_grouped len df_grouped unique df_monthly df_train groupby pd TimeGrouper 'MS' agg 'item_nbr' func 'store_nbr' func ax df_monthly plot subplots True layout figsize legend False linewidth colormap cmap ax set_title ax set_ylabel ax set_title ax set_ylabel plt show
743	TARGET_MIN_COUNTING def get_num_of_repetition_for_class class_id counting label_counter class_id if counting TARGET_MIN_COUNTING return num_to_repeat TARGET_MIN_COUNTING counting return num_to_repeat numbers_of_repetition_for_classes class_id get_num_of_repetition_for_class class_id for class_id in range print "number of repetitions for each class (if > 1)" for in sorted numbers_of_repetition_for_classes items key lambda item item reverse True if
770	new_feats for col in family_size_features new_col_name 'new_{}_per_{}' format 'bedrooms' col new_feats append new_col_name df_train new_col_name df_train 'bedrooms' df_train col df_test new_col_name df_test 'bedrooms' df_test col for col in new_feats df_train col replace np inf np nan inplace True df_train col fillna inplace True df_test col replace np inf np nan inplace True df_test col fillna inplace True
232	fig ax plt subplots nrows ncols sns set_style "whitegrid" df_train df_train groupby mean plot ax ax title color 'r' figsize df_train df_train groupby mean plot ax ax title color 'r' figsize df_train df_train groupby mean plot ax ax title color 'r' figsize df_train df_train groupby mean plot ax ax title color 'r' figsize plt show
782	dtypes 'category' 'category' 'category' 'category' 'category' 'int8' 'float16' 'int8' 'float16' 'float32' 'float16' 'float16' 'int8' 'int16' 'float32' 'float16' 'float16' 'int8' 'category' 'category' 'category' 'int16' 'int16' 'category' 'category' 'category' 'float16' 'int8' 'category' 'float16' 'float16' 'category' 'float16' 'float32' 'category' 'category' 'float16' 'float32' 'float16' 'float16' 'float16' 'category' 'float32' 'category' 'float32' 'int8' 'float32' 'category' 'float16' 'float16' 'float16' 'category' 'category' 'float32' 'category' 'category' 'category' 'int16' 'int32' 'category' 'category' 'category' 'float16' 'int16' 'category' 'int8' 'category' 'category' 'float16' 'float16' 'category' 'float16' 'float16' 'float32' 'int8' 'float16' 'float16' 'int8' 'int8' 'float16' 'float16' 'float16' 'int8'
112	import numpy as np import pandas as pd import os for dirname filenames in os walk '/kaggle/input' for filename in filenames print os path join dirname filename import matplotlib pyplot as plt import featuretools as ft from featuretools primitives import from featuretools variable_types import Numeric from sklearn preprocessing import LabelEncoder MinMaxScaler from sklearn svm import LinearSVR from sklearn feature_selection import SelectFromModel import warnings warnings filterwarnings "ignore"
527	dataset_train TGSSaltDataset train_path tr_ids divide True dataset_train set_padding y_min_pad y_max_pad x_min_pad x_max_pad dataset_train return_padding_borders dataset_val TGSSaltDataset train_path valid_ids divide True dataset_val set_padding dataset_test TGSSaltDataset test_path test_ids is_test True divide True dataset_test set_padding train_loader data DataLoader dataset_train batch_size shuffle True num_workers pin_memory True valid_loader data DataLoader dataset_val batch_size shuffle False num_workers pin_memory True test_loader data DataLoader dataset_test batch_size shuffle False num_workers pin_memory True
268	def evaluate_threshold tpr fpr clf_threshold threshold print tpr clf_threshold threshold print fpr clf_threshold threshold
594	train pd read_json '/kaggle/input/stanford-covid-vaccine/train.json' lines True test pd read_json '/kaggle/input/stanford-covid-vaccine/test.json' lines True sample_df pd read_csv '/kaggle/input/stanford-covid-vaccine/sample_submission.csv'
63	sample_test test_df head sample_test head plt figure figsize for index row in sample_test iterrows filename row 'filename' category row 'category' img load_img "../input/test1/test1/" filename target_size IMAGE_SIZE plt subplot index plt imshow img plt xlabel filename format category plt tight_layout plt show
244	print for col in train columns if train col dtype object train col train col astype 'category' test col test col astype 'category' train drop 'target' axis y_train train 'target' values y_tr y_val train_test_split y_train test drop 'id' axis ids test 'id' values lgb_train lgb Dataset y_tr lgb_val lgb Dataset y_val print
595	trials_df pd DataFrame parse_trial_state for in tuner oracle trials values trials_df to_csv 'trials_table.csv' index False trials_df
681	df_winseeds df_seeds rename columns 'seed_int' df_lossseeds df_seeds rename columns 'seed_int' df_dummy pd merge left df_tour right df_winseeds how 'left' on df_concat pd merge left df_dummy right df_lossseeds on df_concat df_concat WSeed df_concat LSeed df_concat head
311	img2 cv2 bitwise_and image image mask total_mask astype np uint8 plt figure figsize total_mask total_mask plt title plt imshow img2 plt show
43	print "store_id" print "store_id unique value counts:{}" format len price "store_id" unique print price "store_id" unique print "item_id" print "item_id unique value counts:{}" format len price "item_id" unique print price "item_id" unique
133	def plot_word_cloud col corpus for in col str split for in corpus append plt figure figsize word_cloud WordCloud background_color 'black' max_font_size generate join corpus plt imshow word_cloud plt axis 'off' plt show return corpus
56	cat_dim int all_df col nunique for col in categorical cat_dim min for in cat_dim for el in cat_dim if el el el cat_dim
127	eps 1e-8 dense_game_features train_dense columns train_dense std eps dense_player_features train_dense columns train_dense std eps cat_game_features train_cat columns train_cat std eps cat_player_features train_cat columns train_cat std eps
30	plt figure ax df value_counts plot kind 'bar' ax set_title ax set_xlabel ax set_ylabel plt tight_layout plt show
881	train pd read_csv '/kaggle/input/3d-object-detection-for-autonomous-vehicles/train.csv' sub pd read_csv '/kaggle/input/3d-object-detection-for-autonomous-vehicles/sample_submission.csv' print train shape train head
784	df 'MA_7MA' df 'close' rolling window mean df 'MA_15MA' df 'close' rolling window mean df 'MA_30MA' df 'close' rolling window mean df 'MA_60MA' df 'close' rolling window mean
473	from featuretools import selection feature_matrix2 selection remove_low_information_features feature_matrix print feature_matrix shape feature_matrix2 shape
326	df_grouped_usa get_df_country_cases df_covid "US" df_usa_cases_by_day df_grouped_usa df_grouped_usa confirmed df_usa_cases_by_day df_usa_cases_by_day reset_index drop True df_usa_cases_by_day 'day' df_usa_cases_by_day date apply lambda df_usa_cases_by_day date min days reordered_columns 'date' 'day' 'confirmed' 'deaths' 'confirmed_marker' 'deaths_marker' df_usa_cases_by_day df_usa_cases_by_day reordered_columns df_usa_cases_by_day
74	IP df 'ip' value_counts plt figure figsize sns boxplot IP plt title fontsize
701	train_df shape x_train np empty imSize imSize dtype np uint8 for Patient in enumerate tqdm train_df x_train process_patient_images f'../input/osic-pulmonary-fibrosis-progression/train/{Patient}'
169	corr_matrix features corr abs upper corr_matrix where np triu np ones corr_matrix shape astype np bool threshold def highlight value if value threshold style 'background-color: pink' else style 'background-color: palegreen' return style collinear_features column for column in upper columns if any upper column threshold upper style applymap highlight
55	def split_dataset trainset valid_size batch_size num_train len trainset indices list range num_train np random shuffle indices split int np floor valid_size num_train valid_idx train_idx indices split indices split valid_sampler SubsetRandomSampler valid_idx train_sampler SubsetRandomSampler train_idx valid_loader DataLoader trainset batch_size batch_size sampler valid_sampler train_loader DataLoader trainset batch_size batch_size sampler train_sampler return train_loader valid_loader
353	date_agg_3 train_agg groupby level sum date_agg_3 columns 'bookings' 'total' date_agg_3 plot kind 'bar' stacked figsize
797	full_table full_table full_table full_table full_table full_table replace full_table full_table fillna full_table
588	train_dataset tf data Dataset from_tensor_slices x_train y_train repeat shuffle batch BATCH_SIZE prefetch AUTO valid_dataset tf data Dataset from_tensor_slices x_valid y_valid batch BATCH_SIZE cache prefetch AUTO test_dataset tf data Dataset from_tensor_slices x_test batch BATCH_SIZE
778	EMBEDDING_FILE def get_coefs word arr return word np asarray arr dtype 'float32' embeddings_index dict get_coefs split for in open EMBEDDING_FILE if len all_embs np stack embeddings_index values emb_mean emb_std all_embs mean all_embs std embed_size all_embs shape word_index tokenizer word_index nb_words min max_features len word_index embedding_matrix np random normal emb_mean emb_std nb_words embed_size for word in word_index items if max_features continue embedding_vector embeddings_index get word if embedding_vector is not None embedding_matrix embedding_vector
781	temp_col 'CNT_CREDIT_PROLONG' fig ax plt subplots figsize sns kdeplot application_train loc application_train 'TARGET' temp_col label 'repay(0)' color 'r' ax ax sns kdeplot application_train loc application_train 'TARGET' temp_col label 'not repay(1)' color 'b' ax ax plt title format temp_col sns kdeplot application_train loc application_train 'TARGET' application_train temp_col temp_col label 'repay(0)' color 'r' ax ax sns kdeplot application_train loc application_train 'TARGET' application_train temp_col temp_col label 'not repay(1)' color 'b' ax ax plt title format temp_col plt show
637	for task prediction solved in tqdm zip train_tasks train_predictions train_solved if solved for in range len task 'train' plot_sample task 'train' for in range len task 'test' plot_sample task 'test' prediction
634	fig axs plt subplots figsize axs flatten for err_col in enumerate err_cols errs np array train train signal_to_noise err_col values tolist for err in errs axs plot err color 'black' alpha zorder errs_avg errs mean axis errs_std errs std axis axs errorbar np arange errs_avg yerr errs_std color 'red' ecolor 'yellow' drawstyle 'steps-mid' axs set_ylim axs set_title err_col
191	ld os listdir TEST_DIR sizes np zeros len ld for in enumerate ld df pd read_csv os path join TEST_DIR sizes df shape print np mean sizes print np min sizes print np max sizes print 'ok'
539	for key value in dict items if key in pass else growth_rate_over_time exp value key
319	class FocalLoss nn Module def __init__ self gamma reduction 'mean' super __init__ self gamma gamma self reduction reduction def forward self inputs targets nn CrossEntropyLoss reduction 'none' inputs targets pt torch exp pt self gamma if self reduction 'sum' return sum elif self reduction 'mean' return mean
413	ind 'escolari/age' ind 'escolari' ind 'age' plt figure figsize sns violinplot 'escolari/age' data ind
848	def bestThresshold y_train train_preds tmp delta for tmp in tqdm np arange tmp f1_score y_train np array train_preds tmp if tmp tmp delta tmp tmp tmp print format delta tmp return delta delta bestThresshold y_train train_preds
161	from keras models import Sequential from keras layers import BatchNormalization Dense Dropout Flatten from keras optimizers import Adam from keras callbacks import ModelCheckpoint model Sequential model add filters kernel_size activation 'relu' input_shape num_rows num_cols model add pool_size model add activation 'relu' model add model add activation 'relu' model add model add activation 'relu' model add model add Flatten model add Dense activation 'relu' model add Dropout model add Dense activation 'linear' model summary
186	for gname in similar_cars _ids train_gb_year_make_model_trim1 get_group gname 'id' _trim2 train_gb_year_make_model_trim1 get_group gname 'trim2' plt figure figsize plt suptitle format gname len _ids for _id in enumerate _ids plt subplot plt title format _trim2 img get_image_data _id plt imshow img
645	leak_score0 leak_df pd read_pickle ucf_root 'site0.pkl' leak_df 'meter_reading' leak_df meter_reading_scraped leak_df drop 'meter_reading_original' 'meter_reading_scraped' axis inplace True leak_df fillna inplace True leak_df leak_df leak_df timestamp dt year leak_df loc leak_df meter_reading 'meter_reading' sample_submission loc sample_submission meter_reading 'meter_reading' for bid in leak_df building_id unique temp_df leak_df leak_df building_id bid for in temp_df meter unique v0 sample_submission loc test_df building_id bid test_df meter 'meter_reading' values v1 temp_df temp_df meter meter_reading values leak_score0 mean_squared_error np log1p v0 np log1p v1 len v0 sample_submission loc test_df building_id bid test_df meter 'meter_reading' temp_df temp_df meter meter_reading values leak_score0 len leak_df
329	has_to_plot_infection_peak True if has_to_run_sir crisis_day_sir np argmax if has_to_run_sird crisis_day_sird np argmax if has_to_run_seir crisis_day_seir np argmax if has_to_run_seird crisis_day_seird np argmax if has_to_run_seirdq crisis_day_seirdq np argmax
535	iloc shap_interaction_values shap TreeExplainer lgb_model shap_interaction_values
103	def get_couples structure opened idx for idx in enumerate structure if closed idx for idx in enumerate structure if assert len opened len closed assigned couples for close_idx in closed for open_idx in opened if open_idx close_idx if open_idx not in assigned candidate open_idx else break assigned append candidate couples append candidate close_idx assert len couples len opened return couples
7	plt figure figsize plt hist train 'wheezy-copper-turtle-magic' values bins plt title plt xlabel plt ylabel plt show
713	values reframed values n_train_days int len values train values n_train_days test values n_train_days train_X train_y train train test_X test_y test test train_X train_X reshape train_X shape train_X shape test_X test_X reshape test_X shape test_X shape print train_X shape train_y shape test_X shape test_y shape
446	train_set lgb Dataset train label train_labels hyperparameters dict random_results loc 'hyperparameters' del hyperparameters 'n_estimators' cv_results lgb cv hyperparameters train_set num_boost_round early_stopping_rounds metrics 'auc' nfold N_FOLDS print format cv_results 'auc-mean' cv_results 'auc-stdv' print format len cv_results 'auc-mean'
647	ucf_root Path '../input/ashrae-ucf-spider-and-eda-full-test-labels' leak0_df pd read_pickle ucf_root 'site0.pkl' leak0_df 'meter_reading' leak0_df meter_reading_scraped leak0_df drop 'meter_reading_original' 'meter_reading_scraped' axis inplace True leak0_df fillna inplace True leak0_df loc leak0_df meter_reading 'meter_reading' leak0_df leak0_df leak0_df timestamp dt year print len leak0_df
435	features list data columns for in 'pickup_datetime' 'fare_amount' 'fare-bin' 'color' features remove len features
877	xs pq read_table '../input/train.parquet' columns str for in range to_pandas print xs shape xs head
411	np array range np sin plot_corrs
517	gbm_params 'objective' 'binary' 'boosting_type' 'gbdt' 'nthread' 'learning_rate' 'num_leaves' 'colsample_bytree' 'subsample' 'subsample_freq' 'max_depth' 'reg_alpha' 'reg_lambda' 'min_split_gain' 'min_child_weight' 'seed' 'verbose' 'metric' 'auc' oof_train oof_test run_kfold_lgbm y_train gbm_params
345	def visualize_categories df kwargs row kwargs get 'row' None col kwargs get 'col' None hue kwargs get 'hue' None df_types 'train_' 'test_' y_val 'X0' 'X1' 'X2' 'X3' 'X4' 'X5' 'X6' 'X8' for df_type in df_types for val in y_val yval df_type val plt figure sns countplot yval data df color "c" plt show visualize_categories combined
120	world_population pd read_csv "/kaggle/input/population-by-country-2020/population_by_country_2020.csv" world_population world_population world_population columns world_population loc world_population 'US' world_population world_population str rstrip world_population loc world_population 'N.A.' int world_population loc world_population 'N.A.' mode world_population world_population astype 'int16' world_population loc world_population 'N.A.' int world_population loc world_population 'N.A.' mode world_population world_population astype 'int16' print display world_population print all_data all_data merge world_population left_on right_on how 'left' all_data all_data fillna display all_data print all_data drop inplace True axis all_data le fit_transform all_data number_c all_data countries le inverse_transform all_data country_dict dict zip countries number_c all_data le fit_transform all_data number_p all_data province le inverse_transform all_data province_dict dict zip province number_p display all_data
767	continuous_features col for col in df_train columns if col not in binary_cat_features continuous_features col for col in continuous_features if col not in features_object continuous_features col for col in continuous_features if col not in 'idhogar'
154	import matplotlib pyplot as plt acc history history 'categorical_accuracy' val_acc history history 'val_categorical_accuracy' loss history history 'loss' val_loss history history 'val_loss' epochs range len acc plt plot epochs loss 'bo' label plt plot epochs val_loss 'b' label plt title plt legend plt figure plt plot epochs acc 'bo' label plt plot epochs val_acc 'b' label plt title plt legend plt figure plt show
238	import numpy as np import pandas as pd from sklearn preprocessing import LabelEncoder from sklearn model_selection import train_test_split StratifiedKFold KFold from bayes_opt import BayesianOptimization from datetime import datetime from sklearn metrics import precision_score recall_score confusion_matrix accuracy_score roc_auc_score f1_score roc_curve auc precision_recall_curve from sklearn import metrics from sklearn import preprocessing import lightgbm as lgb import warnings warnings filterwarnings "ignore" import itertools from scipy import interp import seaborn as sns import matplotlib pyplot as plt from matplotlib import rcParams
531	loc DateAvSigVersion loc DateAvSigVersion print 'public test shape: {}' format shape print 'private test shape: {}' format shape print 'fraction of private test split: {:.3f}' format shape shape
215	vectorizer TfidfVectorizer min_df max_features tokenizer lambda split ngram_range vectorizer fit_transform 'question' vectorizer transform 'question'
818	pos_train df_train query 'sentiment=="positive"' neg_train df_train query 'sentiment=="negative"' neu_train df_train query 'sentiment=="neutral"' pos_val df_train query 'sentiment=="positive"' neg_val df_train query 'sentiment=="negative"' neu_val df_train query 'sentiment=="neutral"' pos_test df_test query 'sentiment=="positive"' neg_test df_test query 'sentiment=="negative"' neu_test df_test query 'sentiment=="neutral"'
711	train train sort_values 'visit_date' target_train np log1p train 'visitors' values col for in train if not in 'id' 'air_store_id' 'visitors' train train col train set_index 'visit_date' inplace True train head
385	model LogisticRegression max_iter model fit encoded_train raw_train target test_pred model predict_proba encoded_test
457	app app set_index 'SK_ID_CURR' app app merge bureau_info on 'SK_ID_CURR' how 'left' del bureau_info app shape
283	fig axes plt subplots nrows ncols fig set_size_inches sn boxplot data data "price" orient "v" ax axes sn boxplot data data "price" "interest_level" orient "v" ax axes sn boxplot data dataPriceLimited "price" orient "v" ax axes sn boxplot data dataPriceLimited "price" "interest_level" orient "v" ax axes
160	print df_train shape print df_val shape print df_test shape
34	print str count ' fake train samples' print str count ' real train samples' print str val_y count ' fake val samples' print str val_y count ' real val samples'
616	plt figure figsize for fold in range df new_result_df new_result_df 'fold' fold plt plot df Class values df values label 'fold_' str fold '_model_epoch_' str plt plot np arange np ones label 'baseline' 'r' plt plot np arange np ones label color 'c' plt legend plt xticks np arange plt show
132	all start end start_pred end_pred for in range input_ids shape np argmax preds_start_train np argmax preds_end_train start append np argmax start_tokens end append np argmax end_tokens if st train loc 'text' start_pred append end_pred append len st else text1 join train loc 'text' split enc tokenizer encode text1 st tokenizer decode enc ids start_pred append end_pred append all append st train 'start' start train 'end' end train 'start_pred' start_pred train 'end_pred' end_pred train 'selected_text_pred' all train sample
378	df_ df df 'timestamp' X2 df_ drop 'y' 'id' 'timestamp' axis y2 df_ 'y' rf4 RandomForestRegressor rf4 fit X2 y2 rf4 score X2 y2
613	df pd read_csv "../input/liverpool-ion-switching/train.csv" train df copy n_groups df shape df "group" for in range n_groups ids np arange df loc ids "group" for in range n_groups sub df df group signals sub signal values imax imin math floor np max signals math ceil np min signals signals signals np min signals np max signals np min signals signals signals imax imin df loc sub index "pred_open_channels" np array signals np int y_true df open_channels values y_pred df pred_open_channels values
567	with strategy scope model tf keras Sequential efn input_shape weights 'imagenet' include_top False Dense activation 'sigmoid' model compile optimizer 'adam' loss 'binary_crossentropy' metrics 'accuracy' model summary
152	base_dir 'base_dir' os mkdir base_dir train_dir os path join base_dir 'train_dir' os mkdir train_dir val_dir os path join base_dir 'val_dir' os mkdir val_dir a_0 os path join train_dir 'a_0' os mkdir a_0 b_1 os path join train_dir 'b_1' os mkdir b_1 a_0 os path join val_dir 'a_0' os mkdir a_0 b_1 os path join val_dir 'b_1' os mkdir b_1
764	DATA_PATH '../input/aptos2019-blindness-detection' TRAIN_IMG_PATH os path join DATA_PATH 'train_images' TEST_IMG_PATH os path join DATA_PATH 'test_images' TRAIN_LABEL_PATH os path join DATA_PATH 'train.csv' TEST_LABEL_PATH os path join DATA_PATH 'test.csv' train_df pd read_csv TRAIN_LABEL_PATH test_df pd read_csv TEST_LABEL_PATH train_df head
487	def kde_target var_name df corr df 'TARGET' corr df var_name avg_repaid df ix df 'TARGET' var_name median avg_not_repaid df ix df 'TARGET' var_name median plt figure figsize sns kdeplot df ix df 'TARGET' var_name label 'TARGET == 0' sns kdeplot df ix df 'TARGET' var_name label 'TARGET == 1' plt xlabel var_name plt ylabel plt title var_name plt legend print var_name corr print avg_not_repaid print avg_repaid
862	def sieve_eratosthenes primes False False True for in range while if primes True for in range primes False return primes
157	linear_svr LinearSVR linear_svr fit train target acc_model linear_svr train test
66	from sklearn import metrics fbeta_sklearn metrics fbeta_score valid_labels preds average 'samples' print fbeta_sklearn
177	img_1 get_image_data img_2 get_image_data img_3 get_image_data img_4 get_image_data img_5 get_image_data
483	import matplotlib pyplot as plt import seaborn as sns plt rcParams 'font.size' plt style use 'fivethirtyeight' bureau bureau drop columns 'DAYS_CREDIT' 'DAYS_CREDIT_ENDDATE' 'DAYS_ENDDATE_FACT' 'DAYS_CREDIT_UPDATE' plt figure figsize sns distplot bureau 'bureau_credit_end_date' bureau 'bureau_credit_application_date' dropna dt days plt xlabel size plt ylabel size plt title size
719	test_filenames sorted glob f"{data_dir}/Test/*.jpg" test_df pd DataFrame list test_filenames columns batch_size num_workers test_dataset test_df augmentations AUGMENTATIONS_TEST test True test_loader torch utils data DataLoader test_dataset batch_size batch_size num_workers num_workers shuffle False drop_last False
113	corr_matrix features corr abs upper corr_matrix where np triu np ones corr_matrix shape astype np bool threshold def highlight value if value threshold style 'background-color: pink' else style 'background-color: palegreen' return style collinear_features column for column in upper columns if any upper column threshold upper style applymap highlight
217	import numpy as np import pandas as pd from scipy import stats import os gc import matplotlib pyplot as plt import seaborn as sns sns set_style "whitegrid" import plotly offline as py from plotly offline import iplot init_notebook_mode import plotly graph_objs as go init_notebook_mode connected True from IPython display import Markdown def bold string display Markdown string
31	import tensorflow as tf detection_graph tf Graph with detection_graph as_default od_graph_def tf compat v1 GraphDef with tf io gfile GFile '../input/mobilenet-face/frozen_inference_graph_face.pb' 'rb' as fid serialized_graph fid read od_graph_def ParseFromString serialized_graph tf import_graph_def od_graph_def name config tf compat v1 ConfigProto config gpu_options allow_growth True sess tf compat v1 Session graph detection_graph config config image_tensor detection_graph get_tensor_by_name 'image_tensor:0' boxes_tensor detection_graph get_tensor_by_name 'detection_boxes:0' scores_tensor detection_graph get_tensor_by_name 'detection_scores:0' num_detections detection_graph get_tensor_by_name 'num_detections:0'
79	not_missing df df 'attributed_time' isna False not_missing 'gap' pd to_datetime not_missing 'attributed_time' sub pd to_datetime not_missing 'click_time' for in range print "{0:.0f}" format "quantile :" not_missing 'gap' quantile
663	import pandas as pd import numpy as np import matplotlib pylab as plt pd set_option 'display.max_rows' pd get_option "display.max_columns"
448	import pandas as pd import numpy as np import featuretools as ft import matplotlib pyplot as plt plt rcParams 'font.size' import seaborn as sns import warnings warnings filterwarnings 'ignore' import lightgbm as lgb from sklearn model_selection import train_test_split from sklearn model_selection import KFold from sklearn metrics import roc_auc_score from sklearn preprocessing import LabelEncoder import gc
598	with strategy scope model tf keras Sequential efn input_shape weights 'imagenet' include_top False Dense train_labels shape activation 'softmax' model compile optimizer 'adam' loss 'categorical_crossentropy' metrics 'categorical_accuracy' model summary
124	commits_df pd to_numeric commits_df commits_df 'max' commits_df loc commits_df idxmax 'max'
313	from keras callbacks import EarlyStopping ReduceLROnPlateau early EarlyStopping monitor 'val_loss' min_delta patience verbose mode 'auto' reduce ReduceLROnPlateau monitor 'val_loss' factor patience verbose mode 'auto' min_lr model fit_generator train_iterator steps_per_epoch int np ceil train_iterator batch_size epochs validation_data val_iterator validation_steps int np ceil val_iterator batch_size verbose callbacks early reduce
518	train pd read_csv "../input/application_train.csv" test pd read_csv "../input/application_test.csv" bureau pd read_csv "../input/bureau.csv" bureau_bal pd read_csv '../input/bureau_balance.csv'
828	hobbies_state train_sales loc train_sales 'cat_id' 'HOBBIES' groupby 'state_id' mean hobbies_state hobbies_state rename 'CA' 'HOBBIES_CA' 'TX' 'HOBBIES_TX' 'WI' 'HOBBIES_WI' axis household_state train_sales loc train_sales 'cat_id' 'HOUSEHOLD' groupby 'state_id' mean household_state household_state rename 'CA' 'HOUSEHOLD_CA' 'TX' 'HOUSEHOLD_TX' 'WI' 'HOUSEHOLD_WI' axis foods_state train_sales loc train_sales 'cat_id' 'FOODS' groupby 'state_id' mean foods_state foods_state rename 'CA' 'FOODS_CA' 'TX' 'FOODS_TX' 'WI' 'FOODS_WI' axis nine_example pd concat hobbies_state household_state foods_state axis nine_example nine_example drop 'total_sales'
621	import time blur_list blur_list_id start_time time time for image_id in enumerate tqdm train_df 'id_code' img preprocess_image f'../input/train_images/{image_id}.png' if not isClear img blur_list append blur_list_id append image_id train_df train_df drop blur_list print f'Cost: {time.time() - start_time}:.3% seconds'
246	from sklearn feature_extraction text import TfidfVectorizer text "it was the worst of times" "it was the age of wisdom" "it was the age of foolishness" vectorizer TfidfVectorizer vectorizer fit text print sorted vectorizer vocabulary_ vector vectorizer transform text
344	def initial_datatype_conversion df cols 'X0' 'X1' 'X2' 'X3' 'X4' 'X5' 'X6' 'X8' for col in cols df col df col astype 'category' return df ret_train_df initial_datatype_conversion train_df ret_test_df initial_datatype_conversion test_df train_df_cat ret_train_df loc 'X0' 'X1' 'X2' 'X3' 'X4' 'X5' 'X6' 'X8' test_df_cat ret_test_df loc 'X0' 'X1' 'X2' 'X3' 'X4' 'X5' 'X6' 'X8' train_df_cat train_df_cat add_prefix 'train_' test_df_cat test_df_cat add_prefix 'test_' combined train_df_cat append test_df_cat ignore_index True
83	df pd read_csv '../input/train.csv' skiprows nrows header pd read_csv '../input/train.csv' nrows df columns header columns df del header gc collect print df shape "rows."
576	with strategy scope enet efn input_shape weights 'imagenet' include_top False model tf keras Sequential enet tf keras layers tf keras layers Dense len CLASSES activation 'softmax' model compile optimizer tf keras optimizers Adam loss 'sparse_categorical_crossentropy' metrics 'sparse_categorical_accuracy' model summary
227	from sklearn preprocessing import LabelEncoder le LabelEncoder train 'primary_use' le fit_transform train 'primary_use' test 'primary_use' le fit_transform test 'primary_use'
394	sns jointplot particles vx particles vy size ax_joint cla plt sca ax_joint n_hits particles nhits unique for n_hit in n_hits particles particles nhits n_hit plt scatter vx vy label format n_hit plt xlabel plt ylabel plt legend plt show
497	def kde_target var_name df corr df 'TARGET' corr df var_name avg_repaid df ix df 'TARGET' var_name median avg_not_repaid df ix df 'TARGET' var_name median plt figure figsize sns kdeplot df ix df 'TARGET' var_name label 'TARGET == 0' sns kdeplot df ix df 'TARGET' var_name label 'TARGET == 1' plt xlabel var_name plt ylabel plt title var_name plt legend print var_name corr print avg_not_repaid print avg_repaid
550	if not SKIP_VALIDATION cmdataset_with_id get_validation_dataset_with_id ordered True ids_ds cmdataset_with_id map lambda image label idnum idnum unbatch ids next iter ids_ds batch NUM_VALIDATION_IMAGES numpy astype 'U' val_batch iter cmdataset unbatch batch noip sum cm_predictions cm_correct_labels print str noip str round noip NUM_VALIDATION_IMAGES for fi in range NUM_VALIDATION_IMAGES next val_batch if cm_predictions fi cm_correct_labels fi print ids fi display_batch_of_images np array cm_predictions fi figsize
290	TARGET_SR PP_NORMALIZE True MIN_SEC DEVICE 'cuda' BATCH_SIZE SIGMOID_THRESH MAX_BIRDS None
438	model n_estimators len cv_results 'auc-mean' model fit train_features train_labels preds model predict_proba test_features baseline_auc roc_auc_score test_labels preds print format baseline_auc
347	def perform_rfc df_X df_Y test_df_X test_Y rfr_clf RandomForestRegressor n_estimators oob_score True max_features "auto" rfr_clf fit df_X df_Y pred_Y rfr_clf predict test_df_X r2_score_rfc round r2_score test_Y pred_Y accuracy round rfr_clf score df_X df_Y returnval 'model' 'r2_score' r2_score_rfc return returnval
369	target df_train 'outliers' del df_train 'outliers' del df_train 'target'
444	fig axs plt subplots figsize for hyper in enumerate 'colsample_bytree' 'learning_rate' 'min_child_samples' 'num_leaves' sns regplot 'iteration' hyper data bayes_params ax axs axs scatter best_bayes_params 'iteration' best_bayes_params hyper marker 'k' axs set xlabel ylabel format hyper title format hyper plt tight_layout
671	def binary_focal_loss gamma alpha def binary_focal_loss_fixed y_true y_pred pt_1 tf where tf equal y_true y_pred tf ones_like y_pred pt_0 tf where tf equal y_true y_pred tf zeros_like y_pred epsilon epsilon pt_1 clip pt_1 epsilon epsilon pt_0 clip pt_0 epsilon epsilon return sum alpha pow pt_1 gamma log pt_1 sum alpha pow pt_0 gamma log pt_0 return binary_focal_loss_fixed
464	com for in param_grid values com len print format com
185	TRAIN_MASKS_CSV 'id' TRAIN_MASKS_CSV 'img' apply lambda len TRAIN_MASKS_CSV 'id' unique len TRAIN_MASKS_CSV 'id' unique
424	plt figure figsize sns distplot data 'fare_amount' plt title
364	def plot_forecast country train trainfc valid validfc validfclower validfcupper plottitle plt xticks rotation plt plot train label color 'C0' plt plot trainfc label color 'C0' ls plt plot valid label color 'C1' ls plt ylabel try plt fill_between validfclower index validfclower validfcupper color 'k' alpha except pass plt plot validfc label color 'C1' ls plt legend plt title str country " with " plottitle
259	val_p 'APARTMENTS_AVG' 'BASEMENTAREA_AVG' 'YEARS_BEGINEXPLUATATION_AVG' 'YEARS_BUILD_AVG' 'COMMONAREA_AVG' 'ELEVATORS_AVG' 'ENTRANCES_AVG' 'FLOORSMAX_AVG' 'FLOORSMIN_AVG' for in val_p plt figure figsize sns distplot application_train dropna kde True color 'g' plt title plt xticks rotation plt show
354	date_agg_4 train_agg groupby level sum date_agg_4 columns 'bookings' 'total' date_agg_4 reset_index inplace True date_agg_4 'dt' pd to_datetime date_agg_4 year date_agg_4 month date_agg_4 day format date_agg_4 head
808	temp train 'ip' value_counts reset_index name 'counts' temp columns 'ip' 'counts' temp
134	def plot_LSA test_data test_labels savepath plot True title None lsa TruncatedSVD n_components lsa fit test_data lsa_scores lsa transform test_data color_mapper label idx for idx label in enumerate set test_labels color_column color_mapper label for label in test_labels colors 'orange' 'blue' if plot plt title title plt scatter lsa_scores lsa_scores alpha test_labels cmap matplotlib colors ListedColormap colors orange_patch mpatches Patch color 'orange' label blue_patch mpatches Patch color 'blue' label plt legend handles orange_patch blue_patch prop 'size'
817	start_position_candidates end_position_candidates df_train 'select_length' df_train 'tokenized_selected_text' map len for in tqdm range len df_train start_position_candidate for tok in enumerate df_train 'tokenized_text' iloc if tok df_train 'tokenized_selected_text' iloc end_position_candidate for tok in enumerate df_train 'tokenized_text' iloc if tok df_train 'tokenized_selected_text' iloc start_position_candidate idx for idx in start_position_candidate if idx df_train 'select_length' iloc in end_position_candidate end_position_candidate idx for idx in end_position_candidate if idx df_train 'select_length' iloc in start_position_candidate start_position_candidates append start_position_candidate end_position_candidates append end_position_candidate
655	target_meter y_train create_X_y train_df target_meter target_meter y_valid_pred_total np zeros shape gc collect print 'target_meter' target_meter shape cat_features columns get_loc cat_col for cat_col in category_cols print 'cat_features' cat_features models0 for train_idx valid_idx in kf split y_train train_data iloc train_idx y_train train_idx valid_data iloc valid_idx y_train valid_idx print 'train' len train_idx 'valid' len valid_idx model y_pred_valid log fit_lgbm train_data valid_data cat_features category_cols num_rounds num_rounds lr bf y_valid_pred_total valid_idx y_pred_valid models0 append model gc collect if debug break sns distplot y_train sns distplot y_valid_pred_total oof0 mean_squared_error y_train y_valid_pred_total oof_total oof0 len y_train del y_train gc collect
114	lsvr LinearSVR max_iter fit dfe target_fe model SelectFromModel lsvr prefit True model transform dfe pd DataFrame columns dfe columns for in range len dfe columns if model get_support shape
325	df_grouped_iran get_df_country_cases df_covid df_iran_cases_by_day df_grouped_iran df_grouped_iran confirmed df_iran_cases_by_day df_iran_cases_by_day reset_index drop True df_iran_cases_by_day 'day' df_iran_cases_by_day date apply lambda df_iran_cases_by_day date min days reordered_columns 'date' 'day' 'confirmed' 'deaths' 'confirmed_marker' 'deaths_marker' df_iran_cases_by_day df_iran_cases_by_day reordered_columns df_iran_cases_by_day
346	cols ret_test_df filter like '_bb' columns train_X ret_train_df drop 'ID' 'y' axis train_Y ret_train_df 'y' train_Y train_Y values test_X ret_test_df drop 'ID' axis test_X test_X drop cols axis matching_cols train_X columns intersection test_X columns matching_cols_list matching_cols tolist test_X test_X matching_cols_list train_X train_X matching_cols_list y_train y_test train_test_split train_X train_Y test_size random_state print head print head print y_train print y_test
478	random_hyp 'set' opt_hyp 'set' hyp random_hyp append opt_hyp ignore_index True sort True hyp head
17	fig axs plt subplots font 'weight' 'normal' 'size' plt rc 'font' font rn ID np random randint len ID for in range len rn ax plt subplot ax plot train_data loc rn index train_data loc rn label 'ID={}' format rn plt legend if in ax set_xlabel if in range ax set_ylabel 'y'
425	def ecdf np sort len np arange return
477	fig axs plt subplots figsize for hyper in enumerate 'colsample_bytree' 'learning_rate' 'min_child_samples' 'num_leaves' opt_hyp hyper opt_hyp hyper astype float sns regplot 'iteration' hyper data opt_hyp ax axs axs scatter best_opt_hyp 'iteration' best_opt_hyp hyper marker 'k' axs set xlabel ylabel format hyper title format hyper plt tight_layout
600	def convert_to_rgb df split resize True new_size extension 'jpeg' df shape for in tqdm range code df 'id_code' experiment df 'experiment' plate df 'plate' well df 'well' for site in save_path f'{split}/{code}_s{site}.{extension}' im rio load_site_as_rgb split experiment plate well site base_path '../input/' im im astype np uint8 im Image fromarray im if resize im im resize new_size new_size resample Image BILINEAR im save save_path
36	import scipy print model_pred clip mean print scipy stats median_absolute_deviation model_pred clip
546	LR_START LR_MAX strategy num_replicas_in_sync LR_MIN LR_RAMPUP_EPOCHS LR_SUSTAIN_EPOCHS LR_EXP_DECAY def lrfn epoch if epoch LR_RAMPUP_EPOCHS lr LR_MAX LR_START LR_RAMPUP_EPOCHS epoch LR_START elif epoch LR_RAMPUP_EPOCHS LR_SUSTAIN_EPOCHS lr LR_MAX else lr LR_MAX LR_MIN LR_EXP_DECAY epoch LR_RAMPUP_EPOCHS LR_SUSTAIN_EPOCHS LR_MIN return lr lr_callback tf keras callbacks LearningRateScheduler lrfn verbose True rng for in range EPOCHS lrfn for in rng plt plot rng print format max
864	r_applications_bureau ft Relationship es 'applications' 'SK_ID_CURR' es 'bureau' 'SK_ID_CURR' es es add_relationship r_applications_bureau r_applications_installment ft Relationship es 'applications' 'SK_ID_CURR' es 'installments' 'SK_ID_CURR' es es add_relationship r_applications_installment r_bureau_bureaubalance ft Relationship es 'bureau' 'SK_ID_BUREAU' es 'bureau_balance' 'SK_ID_BUREAU' es es add_relationship r_bureau_bureaubalance r_applications_prev_apps ft Relationship es 'applications' 'SK_ID_CURR' es 'previous_application' 'SK_ID_CURR' es es add_relationship r_applications_prev_apps r_applications_cc_balance ft Relationship es 'applications' 'SK_ID_CURR' es 'cc_balance' 'SK_ID_CURR' es es add_relationship r_applications_cc_balance r_applications_pos_balance ft Relationship es 'applications' 'SK_ID_CURR' es 'pos_balance' 'SK_ID_CURR' es es add_relationship r_applications_pos_balance print es
149	def binary_target if return else return df_train 'binary_target' df_train 'diagnosis' apply binary_target
631	reduce_valid pd DataFrame for row in reduce_train_org groupby 'installation_id' sort False reduce_valid reduce_valid append row sample reduce_train reduce_train_org drop reduce_valid index
309	imid 'TCGA-G9-6362-01Z-00-DX1' image_path df df id imid path values image cv2 imread image_path image cv2 cvtColor image cv2 COLOR_BGR2RGB plt figure figsize plt imshow image plt show
8	path '../input/' train pd read_csv path 'train.csv' test pd read_csv path 'test.csv' print train shape print test shape
720	path_data '../input' device 'cuda' batch_size torch manual_seed
391	train_all pd read_csv '../input/avito-demand-prediction/train.csv' usecols 'param_1' 'param_2' 'param_3' 'price' 'deal_probability' param2v train_all train_all price train_all price groupby 'param_2' 'price' apply lambda np std np log np mean np log plt figure figsize sns set ax sns distplot dfd2 values color 'darkred' hist_kws 'alpha' ax sns distplot dffd2 values color 'darkgreen' hist_kws 'alpha' ax ax ax sns distplot param2v values color 'navy' hist_kws 'alpha' ax ax ax set_title ax set_xlabel ax legend 'image label' 'category_name' 'param_2' plt show
430	lr fit 'abs_lat_diff' 'abs_lon_diff' 'passenger_count' y_train print round lr intercept_ print 'abs_lat_diff coef: ' round lr coef_ '\tabs_lon_diff coef:' round lr coef_ '\tpassenger_count coef:' round lr coef_
87	from scipy import ndimage labels nlabels ndimage label mask label_arrays for label_num in range nlabels label_mask np where labels label_num label_arrays append label_mask print format nlabels
554	sample_idxs np random choice np arange len sample_submission for in sample_idxs sample_prep processor prepareSample test_root sample_submission iloc processor createMel CONFIG TRAINING_CONFIG test_mode True proc_mode 'resize' print sample_prep max sample_prep min print sample_prep shape labels shape NCOLS NROWS int np ceil sample_prep shape NCOLS fig ax plt subplots NCOLS NROWS figsize fig suptitle format ax imshow sample_prep cmap plt show
640	root Path '../input/ashrae-feather-format-for-fast-loading' train_df pd read_feather root 'train.feather' weather_train_df pd read_feather root 'weather_train.feather' weather_test_df pd read_feather root 'weather_test.feather' building_meta_df pd read_feather root 'building_metadata.feather'
693	print for in tqdm range len clean_ sentence clean_ for in range maxlen len sentence sentence append 'PAD' clean_ sentence print PAD np zeros word2vec_ 'guy' shape
604	def create_test_gen batch_size return ImageDataGenerator rescale flow_from_dataframe test_imgs directory '../input/severstal-steel-defect-detection/test_images' x_col class_mode None target_size batch_size batch_size shuffle False
700	train_df pd read_csv '../input/osic-pulmonary-fibrosis-progression/train.csv' test_df pd read_csv '../input/osic-pulmonary-fibrosis-progression/test.csv' sub_df pd read_csv '../input/osic-pulmonary-fibrosis-progression/sample_submission.csv' print train_df shape print test_df shape train_df head
746	oversampled_training_dataset get_training_dataset_with_oversample repeat_dataset False oversample True augumentation False label_counter_2 Counter for images labels in oversampled_training_dataset label_counter_2 update labels numpy del oversampled_training_dataset label_counting_sorted_2 label_counter_2 most_common NUM_TRAINING_IMAGES_OVERSAMPLED sum for in label_counting_sorted_2 print "number of examples in the oversampled training dataset: {}" format NUM_TRAINING_IMAGES_OVERSAMPLED print "labels in the oversampled training dataset, sorted by occurrence" label_counting_sorted_2
499	def missing_values_table df print_info False mis_val df isnull sum mis_val_percent df isnull sum len df mis_val_table pd concat mis_val mis_val_percent axis mis_val_table_ren_columns mis_val_table rename columns mis_val_table_ren_columns mis_val_table_ren_columns mis_val_table_ren_columns iloc sort_values ascending False round if print_info print str df shape " columns.\n" str mis_val_table_ren_columns shape " columns that have missing values." return mis_val_table_ren_columns
262	val_p 'AMT_ANNUITY' 'AMT_CREDIT' 'AMT_GOODS_PRICE' 'HOUR_APPR_PROCESS_START' for in val_p plt figure figsize sns distplot application_train dropna kde True color 'g' plt title plt xticks rotation plt show
212	from astropy import stats import multiprocessing as mp from functools import reduce def variable_to_bin var df_train bin_values stats bayesian_blocks df_train var fitness 'events' p0 labels for in enumerate bin_values labels append del labels df pd DataFrame index df_train index df df_train df 'new' var pd cut df_train var bins bin_values labels labels df set_index del bin_values labels return df
678	dow_ohe pd get_dummies dates_s dayofweek dow_array np expand_dims dow_ohe values axis dow_array np tile dow_array df shape month_ohe pd get_dummies dates_s month month_ohe np expand_dims month_ohe values axis month_ohe np tile month_ohe df shape dimension_df pd read_parquet DIMENSION_PATH columns "location" "department" "category" dimension_array pd get_dummies dimension_df values dimension_array np expand_dims dimension_array axis dimension_array np tile dimension_array dow_array shape year_array pd get_dummies dates_s year values year_array np expand_dims year_array axis year_array np tile year_array df shape exog_array np concatenate dow_array dimension_array axis
525	print train_df pd read_csv '{}train.csv' format data_src usecols index_col 'id' depths_df pd read_csv '{}depths.csv' format data_src index_col 'id' train_df train_df join depths_df test_df depths_df depths_df index isin train_df index
116	ensemble_final ensembles copy ensemble_final target_cols for ensemble in ensembles ensemble_final target_cols ensemble target_cols values len ensembles ensemble_final
260	def correlation_heatmap df ax plt subplots figsize colormap sns diverging_palette as_cmap True sns heatmap df corr cmap colormap square True plt title correlation_heatmap application_train
271	def plot_feat_interaction data None plt figure figsize ax plt subplot sns barplot 'sum' data data sort_values 'sum' ascending False ax ax ax set_title fontweight 'bold' fontsize ax plt subplot sns barplot 'count' data data sort_values 'sum' ascending False ax ax ax set_title fontweight 'bold' fontsize plt tight_layout plot_feat_interaction data
842	def seed_everything seed random seed seed os environ 'PYTHONHASHSEED' str seed np random seed seed torch manual_seed seed torch cuda manual_seed seed torch backends cudnn deterministic True seed_everything
528	random_index np random randint val_masks_stacked shape print format random_index fig ax plt subplots ax imshow val_masks_stacked random_index cmap 'seismic' ax imshow val_predictions_stacked random_index cmap 'seismic'
622	def display_blurry_samples df img_id_list columns rows fig plt figure figsize columns rows for in range columns rows img preprocess_image f'../input/train_images/{img_id_list[i]}.png' fig add_subplot rows columns plt title f'index:{i} isclear:{isClear(img)}' plt imshow img plt tight_layout display_blurry_samples train_df blur_list_id
139	base_dir 'base_dir' os mkdir base_dir train_dir os path join base_dir 'train_dir' os mkdir train_dir val_dir os path join base_dir 'val_dir' os mkdir val_dir no_tumor_tissue os path join train_dir 'a_no_tumor_tissue' os mkdir no_tumor_tissue has_tumor_tissue os path join train_dir 'b_has_tumor_tissue' os mkdir has_tumor_tissue no_tumor_tissue os path join val_dir 'a_no_tumor_tissue' os mkdir no_tumor_tissue has_tumor_tissue os path join val_dir 'b_has_tumor_tissue' os mkdir has_tumor_tissue
632	fig ax plt subplots nrows ncols figsize for in range for in range ids sns scatterplot 'var_' str ids shap_values ids ax ax
540	plot_curve_fit gaussian roc_by_date False plot_curve_fit gaussian china_by_date False plot_curve_fit gaussian skorea_by_date False plot_curve_fit gaussian italy_by_date False
493	def missing_values_table df mis_val df isnull sum mis_val_percent df isnull sum len df mis_val_table pd concat mis_val mis_val_percent axis mis_val_table_ren_columns mis_val_table rename columns mis_val_table_ren_columns mis_val_table_ren_columns mis_val_table_ren_columns iloc sort_values ascending False round print str df shape " columns.\n" str mis_val_table_ren_columns shape " columns that have missing values." return mis_val_table_ren_columns
789	y_log np log1p y_categorized pd cut y_log bins range include_lowest True right False labels range
608	model load_weights 'model.h5' y_test model predict_generator test_gen steps len test_gen verbose
377	test 'x' 'y' 'timestamp' time range for in range df_ df ix df 'timestamp' time test 'x' append df_ drop 'y' 'id' 'timestamp' axis test 'y' append df_ 'y' test 'timestamp' append time df_ df df 'timestamp' df_ drop 'y' 'id' 'timestamp' axis df_ 'y'
9	fig ax plt subplots figsize ax1 ax2 ax3 ax4 ax5 ax6 ax flatten sns countplot train 'toxic' palette 'magma' ax ax1 sns countplot train 'severe_toxic' palette 'viridis' ax ax2 sns countplot train 'obscene' palette ax ax3 sns countplot train 'threat' palette 'viridis' ax ax4 sns countplot train 'insult' palette 'magma' ax ax5 sns countplot train 'identity_hate' palette ax ax6
835	plt figure figsize plt subplot plt title draw parsed df plt subplot draw parsed df plt subplot draw parsed df plt subplot draw parsed df plt subplot plt title draw parsed df plt subplot draw parsed df plt subplot draw parsed df plt subplot draw parsed df
231	total len df_train plt figure figsize sns set_style "white" ax sns countplot data df_train palette ax set_title fontsize ax set_ylabel fontsize ax set_xlabel fontsize sizes for in ax patches height get_height sizes append height ax text get_x get_width height '{:1.2f}%' format height total ha "center" fontsize ax set_ylim max sizes plt show
67	model save_model "cbmodel.cbm" format "cbm" export_parameters None pool None
882	lidar_data image_data for record in data_json if record 'fileformat' 'jpeg' image_data append record else lidar_data append record
176	tile_size int np ceil len test_ids complete_test_image np zeros tile_size tile_size dtype np uint8 counter for in range ys tile_size ye ys tile_size for in range xs tile_size xe xs tile_size if counter len test_ids break image_id test_ids counter counter img get_image_data image_id img cv2 resize img dsize tile_size img cv2 putText img image_id img shape cv2 FONT_HERSHEY_SIMPLEX thickness complete_test_image ys ye xs xe img if counter len test_ids break
299	fig ax plt subplots fig set_size_inches sn boxplot "numberofstories" "logerror" data mergedFiltered ax ax color No Of Storeys ",title=" No Of Storeys Vs Log Error
703	sub_df shape x_sub np empty imSize imSize dtype np uint8 for Patient in enumerate tqdm sub_df x_sub process_patient_images f'../input/osic-pulmonary-fibrosis-progression/train/{Patient}'
799	stats for country in 'US' df get_time_series country print format country opt_display_model df stats
423	sub 'surface' le inverse_transform predicted argmax axis sub to_csv 'rand_sub_10.csv' index False sub head
773	for col1 in 'epared1' 'epared2' 'epared3' for col2 in 'etecho1' 'etecho2' 'etecho3' for col3 in 'eviv1' 'eviv2' 'eviv3' new_col_name 'new_{}_x_{}_x_{}' format col1 col2 col3 df_train new_col_name df_train col1 df_train col2 df_train col3 df_test new_col_name df_test col1 df_test col2 df_train col3
688	def make_folds df n_folds seed cls_counts Counter cls for classes in df 'attribute_ids' str split for cls in classes fold_cls_counts defaultdict int folds len df for item in df sample frac random_state seed itertuples cls min item attribute_ids split key lambda cls cls_counts cls fold_counts fold_cls_counts cls for in range n_folds min_count min count for count in fold_counts random seed item Index fold random choice for count in fold_counts if count min_count folds item Index fold for cls in item attribute_ids split fold_cls_counts fold cls df 'fold' folds return df
37	if blaze_bboxes print if mtcnn_bboxes print if mobilenet_bboxes print 'mobilenet is unable to detect face in this frame.' if yolo_bboxes print 'mobilenet is unable to detect face in this frame.'
408	corr_matrix heads corr upper corr_matrix where np triu np ones corr_matrix shape astype np bool to_drop column for column in upper columns if any abs upper column to_drop
500	def aggregate_client df group_vars df_names df_agg agg_numeric df parent_var group_vars df_name df_names if any df dtypes 'category' df_counts agg_categorical df parent_var group_vars df_name df_names df_by_loan df_counts merge df_agg on group_vars how 'outer' gc enable del df_agg df_counts gc collect df_by_loan df_by_loan merge df group_vars group_vars on group_vars how 'left' df_by_loan df_by_loan drop columns group_vars df_by_client agg_numeric df_by_loan parent_var group_vars df_name df_names else df_by_loan df_agg merge df group_vars group_vars on group_vars how 'left' gc enable del df_agg gc collect df_by_loan df_by_loan drop columns group_vars df_by_client agg_numeric df_by_loan parent_var group_vars df_name df_names gc enable del df df_by_loan gc collect return df_by_client
362	dftrainall dftrain join pop on dftrainall dftrainlockdown dftrainall dftrainall join flights on dftrainall dftrainall dftrainall dftrainall dftrainall dftrainall dftrainall dftrainall dftrainall dftrainall tail
280	productsCountReordered orderProductsTrain orderProductsTrain "reordered" "product_id" value_counts to_frame productsCountReordered "reordered_count" productsCountReordered product_id productsCountReordered "product_id" productsCountReordered index productCountReorderedMerged pd merge productsCount productsCountReordered how "left" on "product_id" sort_values by "count" ascending False productCountReorderedMerged "reordered_ratio" productCountReorderedMerged "reordered_count" productCountReorderedMerged "count" productCountReorderedMerged sort_values by "reordered_ratio" ascending False inplace True productMerged pd merge productCountReorderedMerged products how "left" on "product_id" fig ax plt subplots fig set_size_inches sn barplot data productMerged productMerged "count" head "product_name" "reordered_ratio" color Count ",title=" Top Reordered Products ax set_ylim plt xticks rotation productMerged head
768	for col in new_feats df_train col replace np inf np nan inplace True df_train col fillna inplace True df_test col replace np inf np nan inplace True df_test col fillna inplace True
128	def plot_cm y_true y_pred title figsize y_pred y_pred astype int cm confusion_matrix y_true y_pred labels np unique y_true cm_sum np sum cm axis keepdims True cm_perc cm cm_sum astype float annot np empty_like cm astype str nrows ncols cm shape for in range nrows for in range ncols cm cm_perc if cm_sum annot '%.1f%%\n%d/%d' elif annot else annot '%.1f%%\n%d' cm pd DataFrame cm index np unique y_true columns np unique y_true cm index name cm columns name fig ax plt subplots figsize figsize plt title title sns heatmap cm cmap annot annot fmt ax ax
607	def load_img code base resize True path f'{base}/{code}' img cv2 imread path img cv2 cvtColor img cv2 COLOR_BGR2RGB if resize img cv2 resize img return img def validate_path path if not os path exists path os makedirs path
505	train_imgs val_imgs train_test_split selected_imgs test_size stratify selected_imgs 'has_ship' random_state train_fnames train_imgs values val_fnames val_imgs values
432	sns lmplot 'fare_amount' hue palette palette size scatter_kws 'alpha' markers fit_reg False data data sample random_state RSEED plt title
573	if not os path isdir save_dir os makedirs save_dir model_path os path join save_dir model_name model save model_path print model_path
167	def my_generator while True for in range yield infinity_gen my_generator
845	x_train np load "x_train.npy" x_test np load "x_test.npy" y_train np load "y_train.npy" features np load "features.npy" test_features np load "test_features.npy" word_index np load "word_index.npy" item
168	import numpy as np import pandas as pd import os for dirname filenames in os walk '/kaggle/input' for filename in filenames print os path join dirname filename import matplotlib pyplot as plt import featuretools as ft from featuretools primitives import from featuretools variable_types import Numeric from sklearn preprocessing import LabelEncoder MinMaxScaler from sklearn svm import LinearSVR from sklearn feature_selection import SelectFromModel from sklearn ensemble import RandomForestRegressor import warnings warnings filterwarnings "ignore"
418	model_results cv_model train_set train_labels RandomForestClassifier random_state 'RF' model_results
702	test_df shape x_test np empty imSize imSize dtype np uint8 for Patient in enumerate tqdm test_df x_test process_patient_images f'../input/osic-pulmonary-fibrosis-progression/train/{Patient}'
390	print dfl dff merge all_image_labels left_on 'image' right_index True how 'left' dfd dfl groupby 'image_label' 'price' apply lambda np std np mean sort_values ascending False dfd head
516	y_pred_valid model predict y_pred_test model predict del gc collect
2	plt figure figsize plt hist train target values bins plt title plt xlabel plt ylabel plt show
