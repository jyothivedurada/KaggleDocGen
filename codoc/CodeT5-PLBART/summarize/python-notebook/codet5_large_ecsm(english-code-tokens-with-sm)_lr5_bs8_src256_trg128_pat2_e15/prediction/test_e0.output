796	Load the data
451	Check correlation matrix
119	Trends the data
7	Lets look at the data
92	Plotting the data
826	Feature Importances by Feature Importances
596	Save best hyperparameters
35	Create a random sample
687	Count the number of attributes
709	Create a look back dataset
85	Memory usage before opti
100	Lets look at the number of items
784	Mahalanobis Mean Mean Pressure
363	Total cases and deaths per day
242	Importing the libraries
17	Plotting the training data
31	Loading the data
807	Plotting the mean values
16	Prepare data for training
354	Total bookings by year month day
663	Importing the libraries
638	Plotting the predictions
495	Aggregate numeric features
630	Extract video IDs from training set
474	Train and Test
152	Create the necessary directories
93	Lets look at the prices of each brand
187	We will now look at the most similar cars
730	Define the pretrained model
117	Fourier Transformations
14	Exploring the target
515	Create a RLE string
498	Converting the data types
255	Plotting missing values
66	Fbeta score metric
683	Predict with Clipping
554	Prepare the submission
477	Hypotheses and Best Opt Hypotheses
70	How do the histogram look like
615	Lets look at the number of tasks
691	Importing the libraries
91	Plotting categorical features
527	Train and Validation
592	Load the data
47	Plotting the FVC
276	Order of Day of Week
569	Create a fake directory
64	Training the model
660	Add lag features
309	Visualization of the image
492	Bureau balance by loans
871	Acoustic Data and Time to Failure
272	Convert list to ordered dict
851	Create a set of png images
671	Binary Focal Loss
204	Evaluation of the confusion matrix
464	Plotting the parameters
542	Plotting random images
681	Combine the winning and loss seeds
19	Number of rows and columns
520	Loading the data
72	Number of unique values
5	Check for outliers
341	Define the kernel size
147	Train the model
727	Exploring the data
484	Exploring credit and cash data
673	Create a dense added model
386	Plotting the network
171	Random Forest Regressor
55	Split dataset into train and validation set
78	Plotting the clicker type of each IP
601	Create a new dataframe
508	Plotting the income distribution
167	Create a generator
77	Plotting is_attributed
570	Load the data
220	SUNDAYS HAVE LOWEST READINGS
820	Reading the cities file
27	Training the model
865	Create a feature matrix
789	Categorize the data
113	Correlations between collinear features
827	Plotting the total sales
144	Plot the classification report
686	We will now look at the number of not in train labels
312	Training the model
465	Importing the altair
40	Prepare the data for the training set
426	Zoom to NYC
283	Price and Interest Level
678	Dow of week , month and year
41	Train the model
181	Train the model
278	Order Count for each user
158	Train the model
307	Images with masks
803	Hospital Death vs Weight
475	Generate random scores
42	Load the data
576	Training the model
395	Classify the image
782	Exploring the data types
357	Heatmaps with short names
507	Exploring the application
349	Feature Accuracies Model
878	Remove NaNs from train and test data
479	Plotting best best best best best best best best
487	KDE Target Analysis
46	LGBM Prediction
482	Lets look at the number of unique app types
609	Dice loss and score
174	Check if the data is valid
450	Remove columns with missing values
751	Generate date features
531	Checking the shape of the test data
448	Importing the libraries
302	Load the data
281	Top Reordered Products
126	Confusion matrix plot
190	Load the training data
795	Importing the libraries
446	Training the model
122	Fitting the model
801	Province stats
105	Load the data
496	Categorical Data Analysis
385	Logistic Regression
672	Define the basic model
261	Merge train and test set
656	Leak Data Station
196	Plotting monthly data
353	Total bookings by date
110	Lets look at the columns of the data
719	Load the test data
716	Add categorical features to train set
160	Shape of the data
594	Load the data
275	Order Count Across Hour of Day
787	One hot encode the data
737	Define the pretrained model
331	Generate Word Cloud
457	Merge bureau info
744	Number of repetitions for each example
823	Importing the necessary packages
80	Plotting the mean distribution
404	Load the data
219	ELECTRICITY OF METER TYPE
48	Plotting the FVC
293	Training the model
38	Pickle BZ files
224	Meter reading by primary use
518	Load the data
89	Analyzing the images
749	Random Forest Classifier
324	How many cases are spain
798	Province stats
471	Create a feature matrix
67	Save the model
599	Create folder structure
263	Define the data directories
74	Exploring IP values
705	Fitting the full data
436	Predict with random forest
206	Convert tensor to image
103	Get the couples of the structure
406	Check if all values are equal
199	Train the model
470	Define the default features
512	Create feature vectors for each word
241	Split the data into train and test
369	Remove outliers and target data
210	Randomly select train and validation set
842	Seed the model
431	Evaluate the learning rate
178	Plotting the complete images
598	Training the model
208	Train the model
835	Augmentation of the data
61	Load the test data
360	Transpose the data
547	Loading the training dataset
156	Create submission file
511	Convert text to words
562	Lets look at the data
483	Distribution of Bureau credit end date
821	Importing the sol file
142	Calculate ROC AUC score
134	LSA on test data
49	Count the words in each sentence
639	Plotting the predictions
169	Correlations between collinear features
148	Create submission file
559	Distribution of clean features
71	Load the training data
333	Top most common positive words
175	Duplication of target
1	Get the test transforms
684	Define the columns
62	Train the test set
653	Set local time for each zone
731	Train the model
151	Prepare data for training and validation
222	Meter reading by month
884	Market Data Analysis
443	Plotting the best hyperparameters
400	Get the path to the file
332	Train the model
212	Bayesian Bayesian Blocks
390	Merge all images into one
286	Bedrooms by interest level
550	Run the validation on the training set
647	Leak reading by site
311	Masking the image
432	Fare amount of fare amount
326	Let us group the cases by day
591	Submission and Prediction
155	Splitting data into training and testing set
545	Loading the data
95	Price of zero category
266	Print hit rate stats
284	Interest Level by Price
420	Create a Random ForestClassifier
409	Plotting categoricals for each wall
578	Create Title Mode
794	Logistic Regression
538	Plot of daily rates
116	Create final ensemble
384	Let us look at the data
280	Top Reordered Products
741	Data augmentation layer
304	Create full text features
812	We can see that there are multiple channels with different features
407	Households with no head
53	Load the data
781	CNT CRDIT PROLONG
883	Display a sample of the images
238	Import required libraries
502	Balance of credit card
693	Clean the sentence
389	Image Labels for training and testing
315	Create submission file
2	Exploring the data
75	Is Attributed Counts by IP
491	Balance by loan and client
738	Create a list of training variables
305	AUC and PDA
439	Distribution of the number of leaves
640	Load the feather data
764	Load the data
410	How to use Capita
489	Aggregate numeric columns
748	Plotting the results
288	Bathrooms vs Interest Level
605	Predict on test set
378	Train Random Forest
614	LWK and Qwk score
804	Looking at the h1 columns
211	Train the model
173	Evaluation , prediction , and analysis
769	Create new features
581	Predict the submission
468	Random Hypotheses
485	Lets look at the length of each repetition
28	Training the model
777	Load the data
106	Plotting the marching cubes
805	Stratify the data
375	Preparing the data
776	Create categorical features
850	Leak and Log LB
143	Confusion matrix plot
602	Resizing the images
339	Load the data
649	Add lag features
296	Bedroom Count Log Error
863	We will now look at the values of the following variables
597	Decoding the image
338	Importing the necessary libraries
872	Save the data
300	Gaussian Target Noise
861	Plotting the counts of the training set
717	Data Analysis for Alaska
521	Merge breed features
285	Bathrooms by interest level
723	Batch Mixup
546	Learning Rate Scheduler
707	Train and Test Size
347	Random Forest Model
522	Check the types of the columns
342	Train the model
328	Check if we can run the model
469	Load the data
273	Training the model
86	Plot the shape of the image
539	Growth rate over time
561	How do the cylinder look like
761	Plotting the submission
251	Create a keras model
724	Mask the images
380	Import the necessary libraries
140	Create training and validation set
29	Load the training data
694	Count the number of links and nodes
734	Predict on test set
45	Evaluation , prediction , and analysis
213	Importing the libraries
745	Create training dataset
320	Replace country with covid
528	Create a random index
833	Patient ID and patient class
444	Plotting best bayes parameters
711	Preparing the training set
846	GloVe embeddings
728	Pre Trained Model
267	Convert to grayscale
497	KDE Target Analysis
733	Predict the validation set
356	Distribution of heterogeneity
516	Predict for Test and Validation
84	Converting data type to uint
18	Load the data
611	Load the test data
235	Preparing the data set
166	Lets create a generator
633	Exploring the errors
701	Preparing the training data
613	Reading the data
666	Change the address
69	Import the required libraries
149	Binary Target
544	Plotting the data
249	Training the model
168	Import the necessary libraries
732	Train the validation set
517	Run the LGBM model
402	Process the results
334	Top most common negative words
132	Train the model
742	Load the training dataset
792	There are no missing values
584	Training and Validation
571	Create Densenet model
377	Time Series Test
418	Training the model
579	XGBoost model
740	Looking in the directory
321	Plotting the country cases for each country
233	We will now try to decode the data
202	Random Forest Classifier
627	Train a Linear Regression Model
533	Test public and test private
388	Distribution of price
504	Load the model
650	Create train and validation set
30	Plotting the value counts
458	Load the previous application
82	Clicks per minute
604	Create test data generator
721	Evaluate the model
348	Train the PCA model
682	Logistic Regression Model
568	Looking at the original fake paths
247	Feature extraction with sklearn
529	Binary prediction for each test
365	Landmark Retrieval
543	Plotting a random image
424	Distribution of fare amount
875	Visualization of all words
76	Exploring the data
563	Create submission file
217	Importing the libraries
201	Evaluation of the confusion matrix
800	How do the country look like
256	Distribution of target
758	Now , let us look at the data
726	Box plot of age
345	Visualize categories
466	Distribution of boosting type
130	Splitting the data
689	TPU Distributions and Strategy
817	Start and End Position Candidates
25	Create submission file
480	Prepare training and testing data
467	Plotting the best random hyperparameters
788	Gini score
239	Split the data into train and test
185	Number of masks in training set
306	Extract masks from training data
373	Number of missing values
635	Mean and Standard Deviation
806	We can see the number of unique values
203	Evaluation of the confusion matrix
607	Load the image
398	Lets draw some test data
188	We will now look at the most similar cars
882	Create Lidar Data
146	Create a test set
4	Number of numeric columns
460	Load the data
632	Scatter plot of the data
298	Room Count Log Error
136	Load train and test data
722	Batch Cutmixing
790	Get the mask type
499	Missing Values Table
514	Predict on test data
442	Load the training data
111	Feature score vs preprocessing
668	Train the model
292	Combine birds and probabilities
303	Convert categorical features to categorical features
189	Prepare data and test directories
746	Oversampled training dataset
94	Number of Items by brand name
164	Predicting the test set
848	Find best thresshold
595	Create a dataframe of the trials
429	Stratify the data
139	Create the necessary directories
364	Forecast for country
355	Sum the products by short name
329	Check if we have to plot the infection peak
90	Distribution of mean price
536	Importance by Shap
590	Load the test data
768	Replace NaNs in train and test set
876	Lemma Count Vectorizer
501	Load the data
566	Decoding the image
209	Preparing the data types
587	Load the data
98	There are no items with no description
227	Train the model
797	Create a new table
763	Number of columns in test data
573	Save the model
372	Create a RLE string
849	Leak and Log Leak
791	Plotting coverage for each class
379	Classify the model
526	Load train and test data
416	Import the necessary libraries
433	Fare amount vs Fare amount
454	Categorical Data Analysis
271	Plotting Feature Interactions
248	Preprocessing for Keras
816	Plotting the score of each event
509	Load the data
679	Compute the rolling mean per store
246	Feature extraction with TfidfVectorizer
423	Plotting a random subset of the data
245	Transform the data
585	Training the model
648	Set local time for each zone
370	Splitting the labels
862	Sieve Eraatosthenes
411	Plotting the data
376	Distribution of high and low quantile
494	Load the test data
316	Plotting train and test data
52	Train the model
519	Balance of credit card
780	Lets look at the temperature of the target
270	XGBGBDT xgb XGBClassifier
205	Transform the data
773	Create new columns
65	Train the model
54	Label Encoding and Transforming
401	Plotting the results
240	Importing the libraries
552	Create Mel and MFCC files
695	Count the number of links in the dataset
279	Plotting Best Selling Products
600	Convert to RGB
811	Merging is_attributed by device
394	Plotting the number of hits
131	Train the model
453	Aggregate numeric features
610	Train and Validation
36	Plotting the mean and median absolute deviation
815	Compute precision and recall
200	Evaluation of the confusion matrix
150	Prepare data for training
828	Hobbies Households and Foods
838	Lift the results
445	Load the data
207	Define the neural network
655	Create train and validation set
96	Exploring the data
310	Masks by imid
870	Plotting the data
421	Visualization of the surface
392	Looking at the hits
756	Fitting the model
163	Train the model on test data
226	Prepare the data for training and testing
268	Evaluation of threshold
814	Extracting test data
839	Evaluate the program
237	Importing the libraries
43	Unique store id and item id
580	Plotting random indicies
101	Lets plot the length of price
461	Load the credit card data
830	Households and Foods
403	Create TTA transforms
88	RLE encoding
193	Plotting test data
771	Create new features
463	Train the model
102	Info about the data
135	Load the data
15	How many columns can be used
739	Train the model
606	Interest Level based on geography
161	Define Keras model
308	Plotting bounding boxes
51	Clean up the text
23	Define the transform functions
620	Predict for each model
778	Load the embeddings
133	Visualization of Word Cloud
513	Train the model
165	Training the model
772	Create new features
157	Fitting the model
473	Remove low information features
879	Train the model
295	Number of stories in each year
524	Training the model
874	Load the training data
192	Load the data
535	Exploring the Interactions
486	Feature Analysis
692	Extracting the sentences
608	Load the model
799	Time series for each country
145	Cleaning the base directory
162	Plot loss and validation loss
808	Lets look at the counts of each IP
127	Training the model
79	Check for missing values
99	Lets create a WordCloud
344	Convert initial datatypes to categorical
231	Plotting the total number of features
408	Correlations between head and upper columns
430	Fitting LR model
836	Here is the patient class of the patient
510	Length of comment text
172	Load the data
399	Splitting data into train and test set
137	Plotting category images
455	Aggregation of the parent variable
548	Training the model
708	Create a dataset
294	Distribution of Dependent Variable
252	Recurrent Neural Network
368	Check for categorical features
765	Looking at missing values
845	Load the data
506	Visualization of face locations
83	Load the training data
712	Converting series to supervised variables
323	China cases by day
869	Predict with LGBM
488	Correlation between target and training set
374	Plotting the data
427	Haversine distance between two points
490	Count categorical features
456	Aggregating the parent variable
759	Convert DCM to PNG
867	Check missing data
337	Spoiler submission
12	Plotting the AUC curve
766	Fill missing values with missing values
397	Distribution of train and test
877	Load the data
32	Create a random sample
623	Create submission file
125	Exploring tourney results
195	Plotting the test image
438	Train the model
194	Compute the histogram
121	Plotting all the data
154	Categorical Accuracy and loss
262	Exploring the data
810	Property Downloaded by OS
265	Reducing target 0 sample data
540	Plotting the Gaussian curves
700	Load the data
525	Load the data
667	Create GeoDataFrame
13	Define the embeddings
335	Top most common stopwords
880	Model loss and validation loss
73	Is Attributed Values
641	Leak reading by site
352	Plotting the total number of bookings
654	Add lag features
503	Create training and validation masks
662	Leak score metric
760	Split data into train and test set
299	Plotting the number of stories
736	Training the model
250	Define Keras model
757	Applying Label Encoder to test data
629	Importing the necessary libraries
68	Clear the output
774	Create a new column
340	Embeddings and Dropout
714	Apply transform to test data
697	Preparing the data
669	Create a DataFrame
752	Correlation between columns
33	Evaluation , prediction , and analysis
567	Define the model
855	Import the necessary libraries
532	Calculate fraction of train and whole test sets
343	Check missing values
34	Number of fake and real samples
819	What is the test set
747	Learning Rate Scheduler
583	Load the data
725	Number of codpers
715	Lets look at the number of rooms
476	Plotting best scores
428	Fare amount by correlation
260	Correlations between images
108	Load the data
87	Number of labels in each image
500	Aggregate the client variables
625	Create TFAutoModel
577	Compute game time stats for each installation
313	Train the model
327	Load the data
0	Extracting meta data
462	Evaluation , prediction , and analysis
244	LGB dataset with categorical features
541	Loading the data
225	Distribution of square feet
396	Counting the number of zero features
841	Build the model
57	Features for categorical features
215	Tfidf Vectorizer
141	Plotting the accuracy and loss
350	Preprocess the data
675	Get the graph of the molecule
387	Exploring the data
289	Distribution of correlation between bedrooms and matt
440	How to train the model
112	Import the necessary libraries
60	Create an example generator
359	Load the data
405	Lets look at the number of labels
642	Set local time for each zone
618	Split data into train and test
831	Generate random seed
317	Correlations between features
107	Import the necessary libraries
564	Calculate the padding width
560	Define the named colors
622	Display the blurry samples
652	Load the feather data
63	Plotting test data
449	Merge Bureau features
415	Create a new column
197	Plotting the silhouette score
493	Missing Values Table
612	Compute test text and questions
184	Create masks for each image
558	Check missing data
124	Max number of commits
813	Calculate extra data
120	Let us look at the world population
523	Remove features from training and test set
754	XGBoost Model
822	Plotting the mask
290	Prepare the data for training
565	TPU Distributions and Strategy
346	Split data into train and test
868	Prepare for training and testing
115	Create a dataframe of the best commits
729	Create TFExample from jsonl files
301	Create a GaussianTargetNoise
685	Count the number of classes
381	Plotting training and test data
434	Stratify the data
530	Time stamps
10	Create Tfidf Vectorizer
770	Create new features
873	Importing required libraries
793	Exploring the data
549	Predictions on validation set
589	Training the model
44	Create unique values
702	Plotting the test set
478	Random Hypothesis
214	Tag to count map
856	Dark Grid
383	Number of nominal columns
58	Load the data
866	Process the data
651	Leak score for each meter
97	How do the data look like
8	Load the data
735	Pre Trained Model
314	Test set of audio files
703	Plotting the images for each patient
128	Confusion matrix plot
881	Load the data
670	Importing the libraries
505	Train and Validation
371	Load the previous model
282	Price of limited prices
221	READINGS HIGHEST DURING THE MIDDLE OF THE DAY
636	Plotting the error bars
11	Predict for Identity Hate
191	Load the test data
123	Train the model
593	MCRMSE
631	Reduce training and validation set
775	Create a list of only one value columns
59	Pick a random image
159	Load train and test data
574	Cropping with cv2
216	OneVsRest Classifier
277	We can see that there are no missing values
287	Hourly Interest Levels
414	Calculate the range of the data
114	Fitting the model
624	Load the test data
472	Sample features
661	Create train and validation set
553	Prepare the sample
228	Predict the test set
699	Create Data Generator
362	Training the data
229	Importing the necessary libraries
720	Load the data
322	Brazil cases by day
441	Subsample the data
840	Is a solution of the task
179	Get the image data from PIL
626	Clear the model
664	Lets look at the start date
551	Create Mel and MFCC
575	Resizing the images
218	We will now look at the training and test data
258	Exploring the test data
459	Installments and Payments
644	Create train and validation set
24	Train the model
20	Passenger count and store and forward flag
361	Lockdown by country
659	Leak reading by meter
9	Lets look at the number of toxic and viridis
104	Render the image using Neato
435	Lets look at the features
56	How many columns are categorical
234	Directions for North East West
422	Train the model
366	Lets look at the number of landmarks
291	Pretrained ResNet block layers
690	Define the model
351	Aggregate the bookings by date
628	Create submission file
785	Looking for missing values
336	Load the data
844	Save the data
118	Prepare data for training and testing
177	Get the data of the images
645	Leak score for each meter
657	L1P scoring
706	Finding best confidence values
713	Split the data into train and test
50	Clean special characters
297	Bathroom Count Log Error
680	Fitting the model
762	Shape of the data
417	Training Random Forest Classifier
182	Run the build process
81	Now lets look at the most recent click times
688	Create folds
572	Training the model
634	Error bars for each column
153	Create training and validation set
588	Training and Validation
755	Train and Test
481	Load the data
269	Distribution of categorical features
198	Plotting best n clusters
852	Create a video
809	Distribution of the number of clicks in each app
786	Extracting the categorical features
783	There are no missing values
556	Preparing the data
425	Create an EDF
138	Sample the data
318	Evaluation , prediction , and analysis
223	Meter reading by month
617	Importing the libraries
325	Iran cases grouped by day
864	Bureau and cc balance relationships
170	Fitting the model
22	Seed the model
586	Create pretrained tokenizer
367	Compute real and fold Kappas
264	Create target dataframes
837	Importing the necessary libraries
829	Hobbies by event date
718	Define the model
39	Pickle BZ
696	Lets read the DICOM file
186	We will now look at the most similar cars
555	Preparing the data
603	Focal Loss
447	Evaluation , prediction , and analysis
176	Create a test image
834	Patient ID and patient class
109	Visualizing the dataset
382	Plotting the number of bins
413	Escolari age distribution
537	Plotting death rates by country
843	Load train and test data
860	Count the number of samples in the training set
753	Imputer and Transformer
825	Train the model
619	Display the effect of the augmented image
658	Load the feather data
779	Check for Null Values
437	Train the model
802	Hospital Death by age
743	Number of repetitions for each class
676	We can now sort the data by date
183	Categories count by category
637	Plotting train and test
646	Load the feather data
582	Load the data
232	Plotting the mean of each group
698	Looking at the files and folders
254	Feature Type Analysis
847	Create a new dataset
710	Predict on test data
21	Evaluation , prediction , and analysis
452	Drop unused columns
621	Apply blur to each image
412	Exploring the correlation matrix
6	Exploring the data
243	Training the model
180	Fitting the model
853	Load the data
674	Plotting augmented images
37	Detect face in this frame
616	Plotting the result of each fold
704	Apply lambda to train and test
665	Change the address
3	Sum of the missing values
818	What is the sentiment of the data
253	Load the data
857	Visualization of the images
557	Importing required libraries
26	Load Pneumonia locations
257	Groups the data
230	Preparing the data set
319	Define Focal Loss Module
358	Load train and test data
259	Distribution of Apartments and Basements
750	Breakdown Topic
859	Load the data
643	Add lag features
391	Plotting the training data
767	Remove features that are not continuous
534	Date AvSig Version by Months
274	Load the data
677	Distribution of var_91 for each date
832	Loading the data
236	Plotting the win and lost camp values
419	Train the model
330	Importing the libraries
824	Drop features for being useless
858	Train the model
129	Training the model
854	Predict with Keras
393	Lets look at the distribution of the particles
