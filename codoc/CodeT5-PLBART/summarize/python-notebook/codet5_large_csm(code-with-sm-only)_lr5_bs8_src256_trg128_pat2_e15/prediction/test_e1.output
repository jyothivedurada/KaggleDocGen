438	Fast data loading
181	Applicatoin train data merge
540	Hospital Deaths
140	Lets check the confusion matrix
308	Bayes and Random Search
96	Remove the base directory
500	Get the list of decay variables
553	Set the seed for generating random numbers
343	Read Cash Balance File
136	Decision Tree Classifier
273	Combinations of TTA
441	Leak Data Analysis
483	Extract categorical features from train data
285	Random Forest Classifier
323	Lets check the learning rate of the grid
171	Feature extraction with TfidfVectorizer
67	Is shipping depend of prices
449	Diff V319 V320 V321
235	Build the model
452	Extract date features from training data
255	Lets encode the image with RLE
68	There are many items with no description
583	Visualizing Quaketime and Signal
159	Apply model on test data
280	Lets plot some of the correlated points
148	Importing the Libraries
403	Visualizing Training History
223	Load the data
205	Gaussian Target Noise
534	Importing the Libraries
149	Preview of Data
217	Looking at the country cases by italy
350	Load the Data
423	Preparing the submission file
1	Check for missing values
530	Categorize the data
354	Run LGBM on the training data
195	Bathrooms by interest level
229	Most common positive words in train set
16	Ensure determinism in the results
18	Freezing the model
371	Visualizing validation mismatched images
450	Importing the Libraries
242	Total bookings per year
11	Lets plot a histogram of all train counts
424	Test Miltilingual Data
432	Scatter plot of SN filter
508	Spearman correlation with macro features
431	Scatterplot of SHAP values
339	Categorical Data Analysis
558	Importing the Libraries
573	Predicting for each sample
496	Validate the validation dataset
312	Importing the Libraries
480	Apply model on test data
17	Set the size of the image
20	Reading the training text file
299	Train the model and evaluate the model
126	Model with Linear SVR
463	Importing the Libraries
250	Mortality , Fatalities , Land Area
404	Load Train and Test Data
429	Train the model
214	Masks over image
43	Create a generator for training and validation
582	Prepare Training and Test Data
401	Apply the detector on the test data
114	A generator function to generate random numbers
422	Lets plot some of the blurry samples
182	Lets plot some of the missing values
178	Lets try to group the data by two columns
74	Lets get the dummies of the data
377	Lets plot some of the images
174	Tokenize the text using keras tokenizer
575	Distribution of winPlacePerc
64	Mean price by category distribution
389	GAME TIME STATISTICS
33	Pulmonary Condition Progression by Sex
130	Set the Data and Test directories
274	Loading the Data
513	Convert the DICOM files
29	Train the model
353	Apply model on validation and validation data
260	Importing the Libraries
30	Compile and fit the model
409	Build Training and Test Data
590	Fitting the model with sklearn
373	Importing the Libraries
265	Load the Data
9	Embedding of Train Text
467	Lets plot some of the links
23	How many samples are there in train and validation set
210	Lets check the number of masks per image
484	Loading the data
246	Distribution of Demanda Uni Equil Sum
15	Lets try fastai vision score
362	Visualizing Validation Masks
386	Save model to file
147	One Vs SGD Classifier
574	Importing the Data
93	Prepare Training and Validation Set
118	Embeded Random Forest
436	Fast data loading
318	Load previous application data
533	Logistic Regression with sklearn
294	Function to calculate the EDF
31	Load the Data
457	Lets plot some of the training data
150	ELECTRICITY OF METER TYPE
124	Lets plot some of the training images
228	Lets check the sentiment of the training data
234	Load Train and Test Data
89	Lets plot some of the words
134	Visualize Test Image
82	Model with Linear SVR
213	Lets look at the masks of the image
329	Get the feature matrix and feature names
379	Detect TPUs
570	Create a video file
267	Lets plot some of the hits
486	Load Test Data
4	Histogram of target values
466	Link count and node count
563	Load Train and Test Data
427	AUC Score of Toxic
335	Extract target variable from train and test data
166	Merge Train and Test Dataframes
321	Exploratory Data Analysis
304	Distribution of Validation Fares
105	Model with Linear SVR
94	Calculate ROC AUC score
358	extract different column types
554	Load the Data
334	Random Search and Bayesian
157	Convert year to uint8
322	How many estimators in train set
378	Accuracy group distribution
310	Cross validation on the full training dataset
542	Split the data into Training and Test
504	Number of Repetitions for each class
562	Set the seed for generating random numbers
83	Model for Voting Regressor
222	Grabbing most of the cases by day
331	Remove high information features
173	Lets check the vocab size and calculate the hash function
317	Merge Bureau Info
146	Vectorize Train and Test Data
445	Time Series Analysis
48	Fbeta score with sklearn
40	Most of the categorical columns
426	Clear model and session
295	Lets plot some of the images
375	Visualize Bkg Color
543	Lets look at the counts for each ip
291	Imputing Missing Values
578	Birds and LBds
270	Convert ID to Subtype
497	Predict on test data
589	Remove inf values from train and test data
19	Submit to Kaggle
337	Get the feature matrix and feature names
410	Resizing Training and Test Images
209	Full text of each feature
226	Importing the Libraries
268	Number of binary features
493	Generator for training and validation
207	Load the Data
54	Number of different values
284	Rearrange the columns for aggregation
264	Cheatmap of prices
169	Importing the Libraries
333	Get the best score for each set
300	Fare Amount versus Time since Start of Records
505	Oversampled training dataset
514	Number of data per diagnosis
97	Load test data
468	Lets read the DICOM file
420	Split data into Training and Test Data
51	Importing the libraries
202	Bathroom Count Vs Log Error
45	Create test generator
162	Lets define the direction of interest
356	Apply feature aggregator on credit card balance
262	Exploratory Data Analysis
518	Prepare Data for Modeling
326	Boosting Type for Random Search
37	A function to clean up text with all processes
328	Get the feature names of the app entity
477	Splitting the data into Training and Test
560	Evaluate the program on the input image
552	Visualizing Train Sales
314	Check correlation between train and test set
499	Load the pretrained model
539	Province and State
394	Load the Data
39	Apply LabelEncoder on all the features
32	Lets look at the store and item ids
435	Visualizing the test data
230	Find most common negative words in train set
591	Plot of training and validation loss
5	Histogram of Muggy Muggy Copper Turtle Magic
180	Pearson Correlation of Features
586	Load Train Data
303	Remove unnecessary features
399	Build dataset objects
110	Apply model on test data
55	Number of click by IP
340	Bureau Data Analysis
581	Check for Missing Values
462	Build the model
282	Distribution of escolari vs age
91	Load Train and Test Data
293	Distribution of Fare
21	Class Distribution Over Entries
584	Save the data as numpy arrays
257	Icr curve curve curve curve curve curve
344	Read the credit card balance file
296	Correlation with Fare Amount
204	No of Storeys Vs logerror
158	Apply LabelEncoder on the primary data
376	Lets draw a cylinder
448	LGBM Classifier with pdp
461	Detect TPUs
544	Number of clicks and proportion of downloads by devices
381	Get the original fake paths
405	Lets plot some of the trials
172	Vectorize text using HashingVectorizer
277	Check correlation between heads
175	Build Keras Model
108	Lets check the shape of the data
44	Load test data
416	Compute test text and questions sequences
587	Lemma Count Vectorizer
50	Clear output and wait for it to finish
153	MONTHLY READINGS AVERAGING
8	Hate Classification Report
34	Pulmonary Condition Progression by Sex
529	One Hot Encoding
14	Checking for Missing Values
152	Distribution of meter readings by hour
580	Apply LabelEncoder on categorical features
517	Continous Features
176	Loading the Data
316	Aggregate numeric and categorical dataframes
348	Target and CNTs
458	Lets look at the number of classes per attribute
220	Spain cases by day
352	Lets encode the image with RLE
454	A function to compute the rolling mean per store
200	How many stories in year built
233	Importing the Libraries
363	Split the test data into public and private
111	Prepare Prediction Data
444	Importing the Libraries
523	Loading the data
551	Importing the necessary Packages
593	Lidar Data Analysis
392	Lets plot some random images
198	Setting the parameters for the model
592	Load Train and Submission Data
446	Lets change the Europe
498	Loading the pretrained models
66	Top 10 categories with a price of 0
572	Visualizing the data
395	Build dataset objects
183	Set Train Data Path
546	Lets check the score of each track
49	Save model to CNN file
487	Load the data
476	Lets check the square of the training and validation data
439	Leak Data Analysis
81	We define the functions to define the functions to use
567	The method for training is borrowed from
561	Build the model for the training data
576	Distribution of DBNOs
286	Train Random Forest
402	Loading the data
252	Extract target from outliers
306	Run the baseline model on the test data
42	Lets plot some of the images
473	Process Train Data
451	Visualizing augmented images
184	Lets look at the target data
345	Split into Training and Validation
215	Get the test audio files
161	Broad Encoding and Drive Encoding
98	Apply model on test images
366	Calculate Shap importance for each column
84	LB Score
488	Run the model on the training data
117	Apply Linear SVR on the data
216	We replace Mainland China with China
87	Loading Train Data
221	Iran cases by day
455	Fitting the model with logreg
71	VS price vs description length
194	How many orders per user
256	Lets check the missing values in each column
243	How many bookings per year
465	Add PAD to each sequence
197	Check correlation between bedrooms and bathrooms
156	Distribution after log tranformation
579	Get the feature matrix and feature defs
141	Lets check the confusion matrix
132	Lets look at the test data
73	Importing the Libraries
406	Save best model to HDF file
577	Sieve eratosthenes
133	Lets compute the histogram of the image
475	Process the images in each Patient
127	Model for Voting Regressor
151	Lets plot the log of meter reading
85	Prepare Training Data
79	Best LB score
585	Importing the Libraries
512	Calculate the base FVC for each patient
511	Lets encode the year , month and year
440	Fast data loading
188	Set the Data Types
25	Lets plot some of the model predictions
370	Visualizing the data
472	Load the Data
259	Save model to HDF5
434	Lets plot some of the predictions
101	Extract binary features from training data
292	Create Submission File
418	A random task is selected
442	Fast data loading
417	Cohen Kappa Score
144	Train the model
396	Building the model
196	Bedrooms by interest level
212	Lets plot some of the images
139	Random Forest Classifier
385	Training the model
28	Lets plot some of the data
433	Visualizing Training Predictions
131	Load Train Data
99	Submit to Kaggle
414	Create Training and Validation Sets
550	Load the data
247	Load Train and Test Data
80	Ensembling the final ensemble
24	Lets look at the real and fake paths
103	Prepare Training and Validation Set
425	Build model with pretrained model
428	Exploratory Data Analysis
320	Load Cash Balance Data
109	Plot training and validation loss
75	Lets plot some of the features
536	Hong Kong , Hubei
501	Lets check the contents of the directory
241	Aggregate the data for each date
104	Prepare Data for Modeling
367	Growth Rate over time
72	Lets render the image using Neato
65	First level of categories
524	Check for missing values
155	Scatter plot of meter readings
411	Create test generator
116	Check for collinear features
145	Word Cloud for each tag
382	Create fake save directory
415	Build test and submission file
515	Load Train and Test Data
351	Number of comments per sentence
421	Apply blur filter on training data
46	Split the data into Training and Validation
332	Prepare Training and Test Data
588	Load Train Data
232	Perfect Submission and Target
279	Add capita features
470	Lets check the number of files and folders
263	Train the model
478	Create X , Y Data
199	Birds of each row
516	Check for Missing Values
60	Lets check the memory usage of the dataframe
224	Lets check if we have to run the SIR or Sird
77	Check for collinear features
95	CNN for binary classification
464	Total Training and Test Sentences
519	Lets multiply each column with each other
237	Check for Missing Values
57	There is a gap between attributed and click time
494	Load the pretrained model
142	Convert Tensor to Image
113	A generator function to generate random numbers
251	Remove outliers from training data
532	Scatter plot of type
325	Importing the altair library
160	Visualizing Train and Test Data
190	Load the Data
372	Preparing the test data
311	Cross validation on the full dataset
143	Setting the Data Types
327	Load Train and Test Data
413	Apply model on test data
249	Transpose the Data
115	Importing the Libraries
338	Correlation of target variable
70	Coms length
297	Split into Training and Validation
502	Build the model
521	Lets check the number of values in each column
315	Dropping unwanted columns
346	Load model from file
125	Function to read image data from PIL
170	Vectorize text using vectorizer
271	Get the file path for the given image id
12	Load Train Data
355	Load the Data
163	Lets display some of the training and test data
276	Households without head
443	Leak Data Analysis
474	Process Test Data
453	Lets plot some of the training and test variables
261	Lets plot some of the nominal features
374	Add one to train and test data
568	Compile Train Leak
391	Submit to Kaggle
525	Missing Data in training data set
398	Load the Data
522	Create categorical features
219	Reorder china cases by day
185	Reducing the samples of the target
430	Reducing Train Data
520	Lugar and Instance Levels
137	Lets check the confusion matrix
341	Bureau Balances by loans
120	Train the fold importance model
13	Load train and test data
61	Convert to grayscale
495	Get the validation predictions
503	Lets load the training dataset and sort the labels
122	Number of duplicate clicks with different target values in train data
100	Set the binary target variable
489	Cutmix with batch_cutmix
541	Lets calculate the difference between the two columns
412	Lets load the image using cv2
278	Lets plot some of the walls
531	Missing Data in training data set
407	Building the model
177	Lets check the categorical and numerical features
203	Room Count Vs Log Error
460	Lets look at the most frequent attributes
564	Save the data as numpy arrays
26	How many images are there in this frame
491	Apply batch grid mask on each image
393	Load the Data
537	Time Series Prediction
52	Lets plot the distribution of the Fraud flag
357	Breed , colors and states
565	Loading the data
309	Load Train and Test Data
253	Split the label string into a list of labels
364	Month of year
244	Total bookings per year
92	Splitting the data into two datasets
526	Lets look at the mean values of each class
58	Download rate evolution over the day
471	Create the Data Generator
507	Lets try to breakdown the topics
287	Model with Random Forest
469	Lets look at the data
76	Importing the Libraries
102	Split the data into Training and Validation
490	mixup with batch_mixup
47	Train the model
281	Lets check the correlation between all columns
535	Deaths and Confirmed
63	RLE Encoding for the current mask
527	Missing data in training data set
313	Merge Training and Test
397	Create fast tokenizer
556	Lung Opacity Sample Patients
301	Fare Amount by Day of Week
380	Building the model
201	Bedroom Count Vs Log Error
211	Lets check if there are any images with masks
336	Lets look at the boolean variables
2	Lets check if the data is numeric
548	Lets replace neutral sentiment with selected text
492	Loading the pretrained models
482	Lets plot the mean price of each room
266	Coefficient of variation
138	Lets check the confusion matrix
189	Training the model
78	Apply Linear SVR on the data
167	Importing the Libraries
275	Households where the family members do not have the same target
571	Importing the Data
225	Lets try to plot the infection peak
387	Lets read the image and resize it
10	Apply log transform on target variable
283	Hogar of the target
305	Train the model and evaluate it
383	Lets take a look at the results
349	Distribution of income for each target
53	Read Train Data
193	Hour of the year
154	Distribution of meter readings by month
90	Lets look at the data
41	Load Train Data
538	Time Series Predictions
360	Load Train and Test Data
290	Visualizing the label surface
347	Split train images into Training and Validation
164	Importing the Libraries
239	Feature Augmentation
0	Histogram of target values
129	Lets plot some of the masks
3	Outliers of target
506	Random Forest Classifier
258	Regressors with Random Forest
123	Lets try different types of images
238	Random Forest Regressor
298	Fitting the model
384	Build the model
168	Merge Train and Test Dataframes
324	How many parameters are in param grid
121	Lets check the results of the function
186	Convert to grayscale
240	Preprocess the test data
62	Lets check for separate components and objects
361	Load Train and Test Data
7	Vectorize the data
208	Lets factorize the categorical features
112	Submit to Keras
569	Prepare Test Leak Data
269	Lets plot some of our test images
557	Pleural Effusion vs Normal
481	Filter Train Data
119	Load the Data
35	Count the number of words in each sentence
307	Sample from the input space
236	Prepare the model for model training
289	Random Forest Classifier
437	Leak Data Analysis
106	Model for Voting Regressor
88	Splitting the data into Training and Validation
400	Building the model
272	Process the results of the detector
368	Lets plot some of the curves
128	Run the build process
248	Lets read the global data
319	Exploratory Data Analysis
187	Sensitivity and specificity
179	Lets plot some of the values
192	Day of the week
27	Pickling with bz2
509	Split into Training and Test
479	Create Train and Test Dataset
107	Load train and test data
359	Remove unnecessary features
447	Lets change the value of an address
390	Create a function to create the title mode
566	The mean of the two is used as the final embedding matrix
135	Find best clusters for test data
59	Read Train Data
555	Sample Patient 1 - Normal Image
86	Dense Game and Cat Player Features
206	Augmentation with Gaug
36	Clean special characters in text
369	Breed , colors and states
510	BanglaLekha Mean Square Error
56	Quantiles by IP
547	Split the data into positive , negative and neutral
227	Lets generate a wordcloud
545	Extract extra data from time series
419	Importing the Libraries
288	Feature Selection with Random Forest
388	Resizing Training and Test Images
191	Hour of the day
408	Create train and test folders
559	Lifted functions
342	Load the test data
302	Split into Training and Validation
330	Splitting the data into Training and Test
459	Which attributes are not in train data set
218	Brazil cases by day
528	Exploring the Data
456	Apply the model on the test data
38	Load Train Data
485	CNN Model for training
69	Word Cloud for each item
254	Load the model
165	Importing the Libraries
22	Lets take a look at the real and fake data
245	Hoy Venta Death Venta Proxima
549	Lets plot some of the cities
365	Apply SHAP on the importance data
6	Loading the Data
231	Find most common words in selected text
